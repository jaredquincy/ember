{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diversity Testbench\n",
    "\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ember Package Testing (WIP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Dependencies"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 10,
=======
   "execution_count": 33,
>>>>>>> feb7b31 (added embedding model)
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging, sys, os\n",
    "from typing import Dict, Any, List\n",
    "\n",
    "logging.basicConfig(level=logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
=======
   "execution_count": 34,
>>>>>>> feb7b31 (added embedding model)
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "/Users/kathleenge/Desktop/NON/ember-v2\n"
=======
      "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\n"
     ]
    }
   ],
   "source": [
    "openai_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "print(openai_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/ember/connor/ember-v2\n"
>>>>>>> feb7b31 (added embedding model)
     ]
    }
   ],
   "source": [
    "# fixing dependencies if current path is <root>/src/ember/examples/diversity_testbench.ipynb\n",
    "target_dir = 'src/ember/examples'\n",
    "if os.getcwd()[-18:] == target_dir:\n",
    "    os.chdir('../../..')\n",
    "print(os.getcwd())\n",
    "\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"../../..\"))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 14,
=======
   "execution_count": 36,
>>>>>>> feb7b31 (added embedding model)
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "/Users/kathleenge/desktop/non/ember-v2\r\n"
=======
      "/root/ember/connor/ember-v2\n"
>>>>>>> feb7b31 (added embedding model)
     ]
    }
   ],
   "source": [
    "!echo $PWD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: things below this are to install required dependencies (only do this the venv)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 15,
=======
   "execution_count": 37,
>>>>>>> feb7b31 (added embedding model)
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install -q -e .\n",
    "# %pip install -q google-generativeai==0.7.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ember Repo Loads (WIP)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 16,
=======
   "execution_count": 38,
>>>>>>> feb7b31 (added embedding model)
   "metadata": {},
   "outputs": [],
   "source": [
    "# from ember.core.registry.model.model_module.lm import LMModule, LMModuleConfig\n",
    "from ember.core.registry.model.config.settings import initialize_ember\n",
    "from ember.core.registry.model.base.services.model_service import ModelService\n",
    "from ember.core.registry.model.base.schemas.model_info import ModelInfo\n",
    "from ember.core.registry.model.base.schemas.cost import ModelCost, RateLimit\n",
    "from ember.core.registry.model.base.schemas.provider_info import ProviderInfo\n",
    "\n",
    "from ember.core.registry.model import load_model, ChatResponse\n",
    "from ember.core.registry.model.base.services.model_service import ModelService"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "4 validation errors for EmberSettings\nregistry.models.3.api_key\n  Value error, No API key provided or defaulted. [type=value_error, input_value=None, input_type=NoneType]\n    For further information visit https://errors.pydantic.dev/2.10/v/value_error\nregistry.models.4.api_key\n  Value error, No API key provided or defaulted. [type=value_error, input_value=None, input_type=NoneType]\n    For further information visit https://errors.pydantic.dev/2.10/v/value_error\nregistry.models.5.api_key\n  Value error, No API key provided or defaulted. [type=value_error, input_value=None, input_type=NoneType]\n    For further information visit https://errors.pydantic.dev/2.10/v/value_error\nregistry.models.6.api_key\n  Value error, No API key provided or defaulted. [type=value_error, input_value=None, input_type=NoneType]\n    For further information visit https://errors.pydantic.dev/2.10/v/value_error",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model_registry \u001b[38;5;241m=\u001b[39m initialize_ember()\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(model_registry\u001b[38;5;241m.\u001b[39mlist_models())\n\u001b[1;32m      3\u001b[0m llm \u001b[38;5;241m=\u001b[39m ModelService(registry\u001b[38;5;241m=\u001b[39mmodel_registry)\n",
      "File \u001b[0;32m~/Desktop/NON/ember-v2/src/ember/core/registry/model/config/settings.py:252\u001b[0m, in \u001b[0;36minitialize_ember\u001b[0;34m(config_path, auto_register, auto_discover)\u001b[0m\n\u001b[1;32m    249\u001b[0m settings_obj\u001b[38;5;241m.\u001b[39mregistry\u001b[38;5;241m.\u001b[39mauto_register \u001b[38;5;241m=\u001b[39m auto_register\n\u001b[1;32m    250\u001b[0m settings_obj\u001b[38;5;241m.\u001b[39mregistry\u001b[38;5;241m.\u001b[39mauto_discover \u001b[38;5;241m=\u001b[39m auto_discover\n\u001b[0;32m--> 252\u001b[0m registry_instance: ModelRegistry \u001b[38;5;241m=\u001b[39m _initialize_model_registry(settings\u001b[38;5;241m=\u001b[39msettings_obj)\n\u001b[1;32m    253\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m registry_instance\n",
      "File \u001b[0;32m~/Desktop/NON/ember-v2/src/ember/core/registry/model/config/settings.py:184\u001b[0m, in \u001b[0;36m_initialize_model_registry\u001b[0;34m(settings)\u001b[0m\n\u001b[1;32m    181\u001b[0m merged_config \u001b[38;5;241m=\u001b[39m resolve_env_vars(data\u001b[38;5;241m=\u001b[39mmerged_config)\n\u001b[1;32m    182\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFinal merged config keys: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mlist\u001b[39m(merged_config\u001b[38;5;241m.\u001b[39mkeys()))\n\u001b[0;32m--> 184\u001b[0m final_settings: EmberSettings \u001b[38;5;241m=\u001b[39m EmberSettings(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmerged_config)\n\u001b[1;32m    185\u001b[0m registry: ModelRegistry \u001b[38;5;241m=\u001b[39m ModelRegistry(logger\u001b[38;5;241m=\u001b[39mlogger)\n\u001b[1;32m    187\u001b[0m discovered_models: Dict[\u001b[38;5;28mstr\u001b[39m, ModelInfo] \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pydantic_settings/main.py:176\u001b[0m, in \u001b[0;36mBaseSettings.__init__\u001b[0;34m(__pydantic_self__, _case_sensitive, _nested_model_default_partial_update, _env_prefix, _env_file, _env_file_encoding, _env_ignore_empty, _env_nested_delimiter, _env_nested_max_split, _env_parse_none_str, _env_parse_enums, _cli_prog_name, _cli_parse_args, _cli_settings_source, _cli_parse_none_str, _cli_hide_none_type, _cli_avoid_json, _cli_enforce_required, _cli_use_class_docs_for_groups, _cli_exit_on_error, _cli_prefix, _cli_flag_prefix_char, _cli_implicit_flags, _cli_ignore_unknown_args, _cli_kebab_case, _secrets_dir, **values)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    148\u001b[0m     __pydantic_self__,\n\u001b[1;32m    149\u001b[0m     _case_sensitive: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mvalues: Any,\n\u001b[1;32m    175\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 176\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    177\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m__pydantic_self__\u001b[38;5;241m.\u001b[39m_settings_build_values(\n\u001b[1;32m    178\u001b[0m             values,\n\u001b[1;32m    179\u001b[0m             _case_sensitive\u001b[38;5;241m=\u001b[39m_case_sensitive,\n\u001b[1;32m    180\u001b[0m             _nested_model_default_partial_update\u001b[38;5;241m=\u001b[39m_nested_model_default_partial_update,\n\u001b[1;32m    181\u001b[0m             _env_prefix\u001b[38;5;241m=\u001b[39m_env_prefix,\n\u001b[1;32m    182\u001b[0m             _env_file\u001b[38;5;241m=\u001b[39m_env_file,\n\u001b[1;32m    183\u001b[0m             _env_file_encoding\u001b[38;5;241m=\u001b[39m_env_file_encoding,\n\u001b[1;32m    184\u001b[0m             _env_ignore_empty\u001b[38;5;241m=\u001b[39m_env_ignore_empty,\n\u001b[1;32m    185\u001b[0m             _env_nested_delimiter\u001b[38;5;241m=\u001b[39m_env_nested_delimiter,\n\u001b[1;32m    186\u001b[0m             _env_nested_max_split\u001b[38;5;241m=\u001b[39m_env_nested_max_split,\n\u001b[1;32m    187\u001b[0m             _env_parse_none_str\u001b[38;5;241m=\u001b[39m_env_parse_none_str,\n\u001b[1;32m    188\u001b[0m             _env_parse_enums\u001b[38;5;241m=\u001b[39m_env_parse_enums,\n\u001b[1;32m    189\u001b[0m             _cli_prog_name\u001b[38;5;241m=\u001b[39m_cli_prog_name,\n\u001b[1;32m    190\u001b[0m             _cli_parse_args\u001b[38;5;241m=\u001b[39m_cli_parse_args,\n\u001b[1;32m    191\u001b[0m             _cli_settings_source\u001b[38;5;241m=\u001b[39m_cli_settings_source,\n\u001b[1;32m    192\u001b[0m             _cli_parse_none_str\u001b[38;5;241m=\u001b[39m_cli_parse_none_str,\n\u001b[1;32m    193\u001b[0m             _cli_hide_none_type\u001b[38;5;241m=\u001b[39m_cli_hide_none_type,\n\u001b[1;32m    194\u001b[0m             _cli_avoid_json\u001b[38;5;241m=\u001b[39m_cli_avoid_json,\n\u001b[1;32m    195\u001b[0m             _cli_enforce_required\u001b[38;5;241m=\u001b[39m_cli_enforce_required,\n\u001b[1;32m    196\u001b[0m             _cli_use_class_docs_for_groups\u001b[38;5;241m=\u001b[39m_cli_use_class_docs_for_groups,\n\u001b[1;32m    197\u001b[0m             _cli_exit_on_error\u001b[38;5;241m=\u001b[39m_cli_exit_on_error,\n\u001b[1;32m    198\u001b[0m             _cli_prefix\u001b[38;5;241m=\u001b[39m_cli_prefix,\n\u001b[1;32m    199\u001b[0m             _cli_flag_prefix_char\u001b[38;5;241m=\u001b[39m_cli_flag_prefix_char,\n\u001b[1;32m    200\u001b[0m             _cli_implicit_flags\u001b[38;5;241m=\u001b[39m_cli_implicit_flags,\n\u001b[1;32m    201\u001b[0m             _cli_ignore_unknown_args\u001b[38;5;241m=\u001b[39m_cli_ignore_unknown_args,\n\u001b[1;32m    202\u001b[0m             _cli_kebab_case\u001b[38;5;241m=\u001b[39m_cli_kebab_case,\n\u001b[1;32m    203\u001b[0m             _secrets_dir\u001b[38;5;241m=\u001b[39m_secrets_dir,\n\u001b[1;32m    204\u001b[0m         )\n\u001b[1;32m    205\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pydantic/main.py:214\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[0;34m(self, **data)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;66;03m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[39;00m\n\u001b[1;32m    213\u001b[0m __tracebackhide__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 214\u001b[0m validated_self \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__pydantic_validator__\u001b[38;5;241m.\u001b[39mvalidate_python(data, self_instance\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m validated_self:\n\u001b[1;32m    216\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    217\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA custom validator is returning a value other than `self`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    218\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReturning anything other than `self` from a top level model validator isn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt supported when validating via `__init__`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    219\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSee the `model_validator` docs (https://docs.pydantic.dev/latest/concepts/validators/#model-validators) for more details.\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    220\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m    221\u001b[0m     )\n",
      "\u001b[0;31mValidationError\u001b[0m: 4 validation errors for EmberSettings\nregistry.models.3.api_key\n  Value error, No API key provided or defaulted. [type=value_error, input_value=None, input_type=NoneType]\n    For further information visit https://errors.pydantic.dev/2.10/v/value_error\nregistry.models.4.api_key\n  Value error, No API key provided or defaulted. [type=value_error, input_value=None, input_type=NoneType]\n    For further information visit https://errors.pydantic.dev/2.10/v/value_error\nregistry.models.5.api_key\n  Value error, No API key provided or defaulted. [type=value_error, input_value=None, input_type=NoneType]\n    For further information visit https://errors.pydantic.dev/2.10/v/value_error\nregistry.models.6.api_key\n  Value error, No API key provided or defaulted. [type=value_error, input_value=None, input_type=NoneType]\n    For further information visit https://errors.pydantic.dev/2.10/v/value_error"
=======
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_374013/1570386974.py:1: DeprecationWarning: initialize_ember() is deprecated. Use initialize_registry() from ember.core.registry.model.initialization instead.\n",
      "  model_registry = initialize_ember()\n",
      "2025-03-21 00:23:33,902 [DEBUG] ConfigManager: Loading configuration...\n",
      "2025-03-21 00:23:33,915 [DEBUG] ConfigManager: Configuration loaded successfully\n",
      "2025-03-21 00:23:33,923 [INFO] ember.core.registry.model.initialization: Execute model discovery (timeout: 30 seconds per provider, running in parallel)\n",
      "2025-03-21 00:23:33,939 [DEBUG] httpx: load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "2025-03-21 00:23:33,964 [DEBUG] httpx: load_verify_locations cafile='/root/anaconda3/envs/ember_upgrade/lib/python3.11/site-packages/certifi/cacert.pem'\n",
      "2025-03-21 00:23:34,021 [DEBUG] ember.core.registry.model.base.registry.discovery: OPENAI_API_KEY found, initialized OpenAIDiscovery successfully\n",
      "2025-03-21 00:23:34,026 [DEBUG] httpx: load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "2025-03-21 00:23:34,031 [DEBUG] httpx: load_verify_locations cafile='/root/anaconda3/envs/ember_upgrade/lib/python3.11/site-packages/certifi/cacert.pem'\n",
      "2025-03-21 00:23:34,073 [DEBUG] ember.core.registry.model.base.registry.discovery: ANTHROPIC_API_KEY found, initialized AnthropicDiscovery successfully\n",
      "2025-03-21 00:23:34,076 [DEBUG] ember.core.registry.model.base.registry.discovery: GOOGLE_API_KEY found, initialized DeepmindDiscovery successfully\n",
      "2025-03-21 00:23:34,077 [INFO] ember.core.registry.model.initialization: Initiating model discovery via ModelDiscoveryService\n",
      "2025-03-21 00:23:34,094 [INFO] ember.core.registry.model.providers.anthropic.anthropic_discovery: Starting Anthropic model fetch via REST API...\n",
      "2025-03-21 00:23:34,107 [INFO] ember.core.registry.model.providers.anthropic.anthropic_discovery: Calling Anthropic REST API: https://api.anthropic.com/v1/models with timeout=(2,5)\n",
      "2025-03-21 00:23:34,218 [DEBUG] openai._base_client: Request options: {'method': 'get', 'url': '/models', 'post_parser': <function SyncAPIClient._request_api_list.<locals>._parser at 0x7f16ab00f4c0>, 'json_data': None}\n",
      "2025-03-21 00:23:34,253 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): api.anthropic.com:443\n",
      "2025-03-21 00:23:34,256 [DEBUG] openai._base_client: Sending HTTP Request: GET https://api.openai.com/v1/models\n",
      "2025-03-21 00:23:34,272 [DEBUG] httpcore.connection: connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None\n",
      "2025-03-21 00:23:34,333 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f16edee99d0>\n",
      "2025-03-21 00:23:34,335 [DEBUG] httpcore.connection: start_tls.started ssl_context=<ssl.SSLContext object at 0x7f1603a12f90> server_hostname='api.openai.com' timeout=5.0\n",
      "2025-03-21 00:23:34,359 [DEBUG] httpcore.connection: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f16edef0c10>\n",
      "2025-03-21 00:23:34,362 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>\n",
      "2025-03-21 00:23:34,374 [DEBUG] httpcore.http11: send_request_headers.complete\n",
      "2025-03-21 00:23:34,377 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>\n",
      "2025-03-21 00:23:34,380 [DEBUG] httpcore.http11: send_request_body.complete\n",
      "2025-03-21 00:23:34,383 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>\n",
      "2025-03-21 00:23:34,499 [DEBUG] urllib3.connectionpool: https://api.anthropic.com:443 \"GET /v1/models HTTP/1.1\" 401 86\n",
      "2025-03-21 00:23:34,506 [ERROR] ember.core.registry.model.providers.anthropic.anthropic_discovery: Error fetching Anthropic models via REST API: 401 Client Error: Unauthorized for url: https://api.anthropic.com/v1/models\n",
      "2025-03-21 00:23:34,512 [INFO] ember.core.registry.model.providers.anthropic.anthropic_discovery: Using fallback models due to API request error\n",
      "2025-03-21 00:23:34,544 [INFO] ember.core.registry.model.base.registry.discovery: Provider DeepmindDiscovery completed in 0.43s\n",
      "2025-03-21 00:23:34,546 [INFO] ember.core.registry.model.base.registry.discovery: Provider AnthropicDiscovery completed in 0.45s\n",
      "2025-03-21 00:23:34,664 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 21 Mar 2025 07:23:35 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-version', b'2020-10-01'), (b'x-request-id', b'047be343f630a078753ab850368c8104'), (b'openai-processing-ms', b'213'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=lQoQY2KyrWGyGIl5tZm.yBfn5JGOSCA.AqZNb5sDQZ4-1742541815-1.0.1.1-jkeEwlGMhqCzRiPce_S94AqxyEmbQh2B4RQosPoE7.eFMwL5UwmspCv.OEN88cyk98iKiq0wLvcEGKQdTKIjJrKLMq4kGA32abjIo.do_WM; path=/; expires=Fri, 21-Mar-25 07:53:35 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=E2ZuBrVws6lg65OWU8SjS7lE_GkfGfdTWJ17B8epbyU-1742541815014-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'923bb4661860d03d-SJC'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2025-03-21 00:23:34,674 [INFO] httpx: HTTP Request: GET https://api.openai.com/v1/models \"HTTP/1.1 200 OK\"\n",
      "2025-03-21 00:23:34,677 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>\n",
      "2025-03-21 00:23:34,684 [DEBUG] httpcore.http11: receive_response_body.complete\n",
      "2025-03-21 00:23:34,689 [DEBUG] httpcore.http11: response_closed.started\n",
      "2025-03-21 00:23:34,694 [DEBUG] httpcore.http11: response_closed.complete\n",
      "2025-03-21 00:23:34,698 [DEBUG] openai._base_client: HTTP Response: GET https://api.openai.com/v1/models \"200 OK\" Headers([('date', 'Fri, 21 Mar 2025 07:23:35 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('openai-version', '2020-10-01'), ('x-request-id', '047be343f630a078753ab850368c8104'), ('openai-processing-ms', '213'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=lQoQY2KyrWGyGIl5tZm.yBfn5JGOSCA.AqZNb5sDQZ4-1742541815-1.0.1.1-jkeEwlGMhqCzRiPce_S94AqxyEmbQh2B4RQosPoE7.eFMwL5UwmspCv.OEN88cyk98iKiq0wLvcEGKQdTKIjJrKLMq4kGA32abjIo.do_WM; path=/; expires=Fri, 21-Mar-25 07:53:35 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=E2ZuBrVws6lg65OWU8SjS7lE_GkfGfdTWJ17B8epbyU-1742541815014-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '923bb4661860d03d-SJC'), ('content-encoding', 'br'), ('alt-svc', 'h3=\":443\"; ma=86400')])\n",
      "2025-03-21 00:23:34,702 [DEBUG] openai._base_client: request_id: 047be343f630a078753ab850368c8104\n",
      "2025-03-21 00:23:34,722 [DEBUG] ember.core.registry.model.providers.openai.openai_discovery: Fetched 65 models from OpenAI API\n",
      "2025-03-21 00:23:34,724 [DEBUG] ember.core.registry.model.providers.openai.openai_discovery: Filtered to 43 relevant models\n",
      "2025-03-21 00:23:34,729 [INFO] ember.core.registry.model.base.registry.discovery: Provider OpenAIDiscovery completed in 0.65s\n",
      "2025-03-21 00:23:34,732 [INFO] ember.core.registry.model.base.registry.discovery: Successfully received 43 models from OpenAIDiscovery\n",
      "2025-03-21 00:23:34,735 [INFO] ember.core.registry.model.base.registry.discovery: Successfully received 5 models from AnthropicDiscovery\n",
      "2025-03-21 00:23:34,737 [INFO] ember.core.registry.model.base.registry.discovery: Successfully received 32 models from DeepmindDiscovery\n",
      "2025-03-21 00:23:34,741 [INFO] ember.core.registry.model.base.registry.discovery: Discovered 80 models: ['openai:gpt-4o-mini-transcribe', 'openai:gpt-4o-audio-preview-2024-12-17', 'openai:dall-e-3', 'openai:dall-e-2', 'openai:gpt-4o-audio-preview-2024-10-01', 'openai:gpt-4o-realtime-preview-2024-10-01', 'openai:gpt-4o-audio-preview', 'openai:text-embedding-3-large', 'openai:gpt-4', 'openai:gpt-4o-2024-05-13', 'openai:gpt-4o-realtime-preview', 'openai:gpt-4o-mini-audio-preview', 'openai:gpt-3.5-turbo-instruct-0914', 'openai:gpt-4o-mini-search-preview', 'openai:gpt-3.5-turbo-1106', 'openai:gpt-4o-search-preview', 'openai:gpt-4-turbo', 'openai:gpt-4o-realtime-preview-2024-12-17', 'openai:gpt-3.5-turbo-instruct', 'openai:gpt-3.5-turbo', 'openai:gpt-4-turbo-preview', 'openai:gpt-4o-mini-search-preview-2025-03-11', 'openai:gpt-4o-mini-realtime-preview', 'openai:gpt-3.5-turbo-0125', 'openai:gpt-4o-2024-08-06', 'openai:gpt-4-turbo-2024-04-09', 'openai:gpt-3.5-turbo-16k', 'openai:gpt-4o', 'openai:gpt-4o-mini-realtime-preview-2024-12-17', 'openai:gpt-4-1106-preview', 'openai:text-embedding-ada-002', 'openai:gpt-4-0613', 'openai:gpt-4.5-preview', 'openai:gpt-4.5-preview-2025-02-27', 'openai:gpt-4o-search-preview-2025-03-11', 'openai:gpt-4o-2024-11-20', 'openai:gpt-4o-mini-2024-07-18', 'openai:gpt-4o-mini-tts', 'openai:gpt-4o-mini', 'openai:gpt-4-0125-preview', 'openai:gpt-4o-transcribe', 'openai:text-embedding-3-small', 'openai:gpt-4o-mini-audio-preview-2024-12-17', 'anthropic:claude-3-sonnet', 'anthropic:claude-3-opus', 'anthropic:claude-3-haiku', 'anthropic:claude-3.5-sonnet', 'anthropic:claude-3.7-sonnet', 'google:models/gemini-1.0-pro-vision-latest', 'google:models/gemini-pro-vision', 'google:models/gemini-1.5-pro-latest', 'google:models/gemini-1.5-pro-001', 'google:models/gemini-1.5-pro-002', 'google:models/gemini-1.5-pro', 'google:models/gemini-1.5-flash-latest', 'google:models/gemini-1.5-flash-001', 'google:models/gemini-1.5-flash-001-tuning', 'google:models/gemini-1.5-flash', 'google:models/gemini-1.5-flash-002', 'google:models/gemini-1.5-flash-8b', 'google:models/gemini-1.5-flash-8b-001', 'google:models/gemini-1.5-flash-8b-latest', 'google:models/gemini-1.5-flash-8b-exp-0827', 'google:models/gemini-1.5-flash-8b-exp-0924', 'google:models/gemini-2.0-flash-exp', 'google:models/gemini-2.0-flash', 'google:models/gemini-2.0-flash-001', 'google:models/gemini-2.0-flash-exp-image-generation', 'google:models/gemini-2.0-flash-lite-001', 'google:models/gemini-2.0-flash-lite', 'google:models/gemini-2.0-flash-lite-preview-02-05', 'google:models/gemini-2.0-flash-lite-preview', 'google:models/gemini-2.0-pro-exp', 'google:models/gemini-2.0-pro-exp-02-05', 'google:models/gemini-exp-1206', 'google:models/gemini-2.0-flash-thinking-exp-01-21', 'google:models/gemini-2.0-flash-thinking-exp', 'google:models/gemini-2.0-flash-thinking-exp-1219', 'google:models/learnlm-1.5-pro-experimental', 'google:models/gemma-3-27b-it']\n",
      "2025-03-21 00:23:34,745 [DEBUG] ember.core.registry.model.initialization: Raw discovery found 80 models: ['openai:gpt-4o-mini-transcribe', 'openai:gpt-4o-audio-preview-2024-12-17', 'openai:dall-e-3', 'openai:dall-e-2', 'openai:gpt-4o-audio-preview-2024-10-01', 'openai:gpt-4o-realtime-preview-2024-10-01', 'openai:gpt-4o-audio-preview', 'openai:text-embedding-3-large', 'openai:gpt-4', 'openai:gpt-4o-2024-05-13', 'openai:gpt-4o-realtime-preview', 'openai:gpt-4o-mini-audio-preview', 'openai:gpt-3.5-turbo-instruct-0914', 'openai:gpt-4o-mini-search-preview', 'openai:gpt-3.5-turbo-1106', 'openai:gpt-4o-search-preview', 'openai:gpt-4-turbo', 'openai:gpt-4o-realtime-preview-2024-12-17', 'openai:gpt-3.5-turbo-instruct', 'openai:gpt-3.5-turbo', 'openai:gpt-4-turbo-preview', 'openai:gpt-4o-mini-search-preview-2025-03-11', 'openai:gpt-4o-mini-realtime-preview', 'openai:gpt-3.5-turbo-0125', 'openai:gpt-4o-2024-08-06', 'openai:gpt-4-turbo-2024-04-09', 'openai:gpt-3.5-turbo-16k', 'openai:gpt-4o', 'openai:gpt-4o-mini-realtime-preview-2024-12-17', 'openai:gpt-4-1106-preview', 'openai:text-embedding-ada-002', 'openai:gpt-4-0613', 'openai:gpt-4.5-preview', 'openai:gpt-4.5-preview-2025-02-27', 'openai:gpt-4o-search-preview-2025-03-11', 'openai:gpt-4o-2024-11-20', 'openai:gpt-4o-mini-2024-07-18', 'openai:gpt-4o-mini-tts', 'openai:gpt-4o-mini', 'openai:gpt-4-0125-preview', 'openai:gpt-4o-transcribe', 'openai:text-embedding-3-small', 'openai:gpt-4o-mini-audio-preview-2024-12-17', 'anthropic:claude-3-sonnet', 'anthropic:claude-3-opus', 'anthropic:claude-3-haiku', 'anthropic:claude-3.5-sonnet', 'anthropic:claude-3.7-sonnet', 'google:models/gemini-1.0-pro-vision-latest', 'google:models/gemini-pro-vision', 'google:models/gemini-1.5-pro-latest', 'google:models/gemini-1.5-pro-001', 'google:models/gemini-1.5-pro-002', 'google:models/gemini-1.5-pro', 'google:models/gemini-1.5-flash-latest', 'google:models/gemini-1.5-flash-001', 'google:models/gemini-1.5-flash-001-tuning', 'google:models/gemini-1.5-flash', 'google:models/gemini-1.5-flash-002', 'google:models/gemini-1.5-flash-8b', 'google:models/gemini-1.5-flash-8b-001', 'google:models/gemini-1.5-flash-8b-latest', 'google:models/gemini-1.5-flash-8b-exp-0827', 'google:models/gemini-1.5-flash-8b-exp-0924', 'google:models/gemini-2.0-flash-exp', 'google:models/gemini-2.0-flash', 'google:models/gemini-2.0-flash-001', 'google:models/gemini-2.0-flash-exp-image-generation', 'google:models/gemini-2.0-flash-lite-001', 'google:models/gemini-2.0-flash-lite', 'google:models/gemini-2.0-flash-lite-preview-02-05', 'google:models/gemini-2.0-flash-lite-preview', 'google:models/gemini-2.0-pro-exp', 'google:models/gemini-2.0-pro-exp-02-05', 'google:models/gemini-exp-1206', 'google:models/gemini-2.0-flash-thinking-exp-01-21', 'google:models/gemini-2.0-flash-thinking-exp', 'google:models/gemini-2.0-flash-thinking-exp-1219', 'google:models/learnlm-1.5-pro-experimental', 'google:models/gemma-3-27b-it']\n",
      "2025-03-21 00:23:34,752 [WARNING] ember.core.registry.model.base.registry.discovery: Model openai:gpt-4o-mini-transcribe discovered via API but not in local config; using defaults with environment API key.\n",
      "2025-03-21 00:23:34,757 [DEBUG] ember.core.registry.model.base.registry.discovery: Successfully merged model info for openai:gpt-4o-mini-transcribe\n",
      "2025-03-21 00:23:34,760 [WARNING] ember.core.registry.model.base.registry.discovery: Model openai:gpt-4o-audio-preview-2024-12-17 discovered via API but not in local config; using defaults with environment API key.\n",
      "2025-03-21 00:23:34,763 [DEBUG] ember.core.registry.model.base.registry.discovery: Successfully merged model info for openai:gpt-4o-audio-preview-2024-12-17\n",
      "2025-03-21 00:23:34,764 [WARNING] ember.core.registry.model.base.registry.discovery: Model openai:dall-e-3 discovered via API but not in local config; using defaults with environment API key.\n",
      "2025-03-21 00:23:34,765 [DEBUG] ember.core.registry.model.base.registry.discovery: Successfully merged model info for openai:dall-e-3\n",
      "2025-03-21 00:23:34,767 [WARNING] ember.core.registry.model.base.registry.discovery: Model openai:dall-e-2 discovered via API but not in local config; using defaults with environment API key.\n",
      "2025-03-21 00:23:34,770 [DEBUG] ember.core.registry.model.base.registry.discovery: Successfully merged model info for openai:dall-e-2\n",
      "2025-03-21 00:23:34,772 [WARNING] ember.core.registry.model.base.registry.discovery: Model openai:gpt-4o-audio-preview-2024-10-01 discovered via API but not in local config; using defaults with environment API key.\n",
      "2025-03-21 00:23:34,775 [DEBUG] ember.core.registry.model.base.registry.discovery: Successfully merged model info for openai:gpt-4o-audio-preview-2024-10-01\n",
      "2025-03-21 00:23:34,776 [WARNING] ember.core.registry.model.base.registry.discovery: Model openai:gpt-4o-realtime-preview-2024-10-01 discovered via API but not in local config; using defaults with environment API key.\n",
      "2025-03-21 00:23:34,778 [DEBUG] ember.core.registry.model.base.registry.discovery: Successfully merged model info for openai:gpt-4o-realtime-preview-2024-10-01\n",
      "2025-03-21 00:23:34,780 [WARNING] ember.core.registry.model.base.registry.discovery: Model openai:gpt-4o-audio-preview discovered via API but not in local config; using defaults with environment API key.\n",
      "2025-03-21 00:23:34,782 [DEBUG] ember.core.registry.model.base.registry.discovery: Successfully merged model info for openai:gpt-4o-audio-preview\n",
      "2025-03-21 00:23:34,783 [WARNING] ember.core.registry.model.base.registry.discovery: Model openai:text-embedding-3-large discovered via API but not in local config; using defaults with environment API key.\n",
      "2025-03-21 00:23:34,784 [DEBUG] ember.core.registry.model.base.registry.discovery: Successfully merged model info for openai:text-embedding-3-large\n",
      "2025-03-21 00:23:34,785 [WARNING] ember.core.registry.model.base.registry.discovery: Model openai:gpt-4 discovered via API but not in local config; using defaults with environment API key.\n",
      "2025-03-21 00:23:34,786 [DEBUG] ember.core.registry.model.base.registry.discovery: Successfully merged model info for openai:gpt-4\n",
      "2025-03-21 00:23:34,789 [WARNING] ember.core.registry.model.base.registry.discovery: Model openai:gpt-4o-2024-05-13 discovered via API but not in local config; using defaults with environment API key.\n",
      "2025-03-21 00:23:34,791 [DEBUG] ember.core.registry.model.base.registry.discovery: Successfully merged model info for openai:gpt-4o-2024-05-13\n",
      "2025-03-21 00:23:34,792 [WARNING] ember.core.registry.model.base.registry.discovery: Model openai:gpt-4o-realtime-preview discovered via API but not in local config; using defaults with environment API key.\n",
      "2025-03-21 00:23:34,794 [DEBUG] ember.core.registry.model.base.registry.discovery: Successfully merged model info for openai:gpt-4o-realtime-preview\n",
      "2025-03-21 00:23:34,797 [WARNING] ember.core.registry.model.base.registry.discovery: Model openai:gpt-4o-mini-audio-preview discovered via API but not in local config; using defaults with environment API key.\n",
      "2025-03-21 00:23:34,800 [DEBUG] ember.core.registry.model.base.registry.discovery: Successfully merged model info for openai:gpt-4o-mini-audio-preview\n",
      "2025-03-21 00:23:34,803 [WARNING] ember.core.registry.model.base.registry.discovery: Model openai:gpt-3.5-turbo-instruct-0914 discovered via API but not in local config; using defaults with environment API key.\n",
      "2025-03-21 00:23:34,807 [DEBUG] ember.core.registry.model.base.registry.discovery: Successfully merged model info for openai:gpt-3.5-turbo-instruct-0914\n",
      "2025-03-21 00:23:34,809 [WARNING] ember.core.registry.model.base.registry.discovery: Model openai:gpt-4o-mini-search-preview discovered via API but not in local config; using defaults with environment API key.\n",
      "2025-03-21 00:23:34,811 [DEBUG] ember.core.registry.model.base.registry.discovery: Successfully merged model info for openai:gpt-4o-mini-search-preview\n",
      "2025-03-21 00:23:34,812 [WARNING] ember.core.registry.model.base.registry.discovery: Model openai:gpt-3.5-turbo-1106 discovered via API but not in local config; using defaults with environment API key.\n",
      "2025-03-21 00:23:34,814 [DEBUG] ember.core.registry.model.base.registry.discovery: Successfully merged model info for openai:gpt-3.5-turbo-1106\n",
      "2025-03-21 00:23:34,815 [WARNING] ember.core.registry.model.base.registry.discovery: Model openai:gpt-4o-search-preview discovered via API but not in local config; using defaults with environment API key.\n",
      "2025-03-21 00:23:34,815 [DEBUG] ember.core.registry.model.base.registry.discovery: Successfully merged model info for openai:gpt-4o-search-preview\n",
      "2025-03-21 00:23:34,817 [WARNING] ember.core.registry.model.base.registry.discovery: Model openai:gpt-4-turbo discovered via API but not in local config; using defaults with environment API key.\n",
      "2025-03-21 00:23:34,818 [DEBUG] ember.core.registry.model.base.registry.discovery: Successfully merged model info for openai:gpt-4-turbo\n",
      "2025-03-21 00:23:34,820 [WARNING] ember.core.registry.model.base.registry.discovery: Model openai:gpt-4o-realtime-preview-2024-12-17 discovered via API but not in local config; using defaults with environment API key.\n",
      "2025-03-21 00:23:34,823 [DEBUG] ember.core.registry.model.base.registry.discovery: Successfully merged model info for openai:gpt-4o-realtime-preview-2024-12-17\n",
      "2025-03-21 00:23:34,825 [WARNING] ember.core.registry.model.base.registry.discovery: Model openai:gpt-3.5-turbo-instruct discovered via API but not in local config; using defaults with environment API key.\n",
      "2025-03-21 00:23:34,828 [DEBUG] ember.core.registry.model.base.registry.discovery: Successfully merged model info for openai:gpt-3.5-turbo-instruct\n",
      "2025-03-21 00:23:34,832 [WARNING] ember.core.registry.model.base.registry.discovery: Model openai:gpt-3.5-turbo discovered via API but not in local config; using defaults with environment API key.\n",
      "2025-03-21 00:23:34,836 [DEBUG] ember.core.registry.model.base.registry.discovery: Successfully merged model info for openai:gpt-3.5-turbo\n",
      "2025-03-21 00:23:34,842 [WARNING] ember.core.registry.model.base.registry.discovery: Model openai:gpt-4-turbo-preview discovered via API but not in local config; using defaults with environment API key.\n",
      "2025-03-21 00:23:34,846 [DEBUG] ember.core.registry.model.base.registry.discovery: Successfully merged model info for openai:gpt-4-turbo-preview\n",
      "2025-03-21 00:23:34,848 [WARNING] ember.core.registry.model.base.registry.discovery: Model openai:gpt-4o-mini-search-preview-2025-03-11 discovered via API but not in local config; using defaults with environment API key.\n",
      "2025-03-21 00:23:34,852 [DEBUG] ember.core.registry.model.base.registry.discovery: Successfully merged model info for openai:gpt-4o-mini-search-preview-2025-03-11\n",
      "2025-03-21 00:23:34,856 [WARNING] ember.core.registry.model.base.registry.discovery: Model openai:gpt-4o-mini-realtime-preview discovered via API but not in local config; using defaults with environment API key.\n",
      "2025-03-21 00:23:34,859 [DEBUG] ember.core.registry.model.base.registry.discovery: Successfully merged model info for openai:gpt-4o-mini-realtime-preview\n",
      "2025-03-21 00:23:34,862 [WARNING] ember.core.registry.model.base.registry.discovery: Model openai:gpt-3.5-turbo-0125 discovered via API but not in local config; using defaults with environment API key.\n",
      "2025-03-21 00:23:34,863 [DEBUG] ember.core.registry.model.base.registry.discovery: Successfully merged model info for openai:gpt-3.5-turbo-0125\n",
      "2025-03-21 00:23:34,867 [WARNING] ember.core.registry.model.base.registry.discovery: Model openai:gpt-4o-2024-08-06 discovered via API but not in local config; using defaults with environment API key.\n",
      "2025-03-21 00:23:34,868 [DEBUG] ember.core.registry.model.base.registry.discovery: Successfully merged model info for openai:gpt-4o-2024-08-06\n",
      "2025-03-21 00:23:34,870 [WARNING] ember.core.registry.model.base.registry.discovery: Model openai:gpt-4-turbo-2024-04-09 discovered via API but not in local config; using defaults with environment API key.\n",
      "2025-03-21 00:23:34,872 [DEBUG] ember.core.registry.model.base.registry.discovery: Successfully merged model info for openai:gpt-4-turbo-2024-04-09\n",
      "2025-03-21 00:23:34,873 [WARNING] ember.core.registry.model.base.registry.discovery: Model openai:gpt-3.5-turbo-16k discovered via API but not in local config; using defaults with environment API key.\n",
      "2025-03-21 00:23:34,874 [DEBUG] ember.core.registry.model.base.registry.discovery: Successfully merged model info for openai:gpt-3.5-turbo-16k\n",
      "2025-03-21 00:23:34,875 [WARNING] ember.core.registry.model.base.registry.discovery: Model openai:gpt-4o discovered via API but not in local config; using defaults with environment API key.\n",
      "2025-03-21 00:23:34,876 [DEBUG] ember.core.registry.model.base.registry.discovery: Successfully merged model info for openai:gpt-4o\n",
      "2025-03-21 00:23:34,877 [WARNING] ember.core.registry.model.base.registry.discovery: Model openai:gpt-4o-mini-realtime-preview-2024-12-17 discovered via API but not in local config; using defaults with environment API key.\n",
      "2025-03-21 00:23:34,878 [DEBUG] ember.core.registry.model.base.registry.discovery: Successfully merged model info for openai:gpt-4o-mini-realtime-preview-2024-12-17\n",
      "2025-03-21 00:23:34,881 [WARNING] ember.core.registry.model.base.registry.discovery: Model openai:gpt-4-1106-preview discovered via API but not in local config; using defaults with environment API key.\n",
      "2025-03-21 00:23:34,883 [DEBUG] ember.core.registry.model.base.registry.discovery: Successfully merged model info for openai:gpt-4-1106-preview\n",
      "2025-03-21 00:23:34,884 [WARNING] ember.core.registry.model.base.registry.discovery: Model openai:text-embedding-ada-002 discovered via API but not in local config; using defaults with environment API key.\n",
      "2025-03-21 00:23:34,885 [DEBUG] ember.core.registry.model.base.registry.discovery: Successfully merged model info for openai:text-embedding-ada-002\n",
      "2025-03-21 00:23:34,889 [WARNING] ember.core.registry.model.base.registry.discovery: Model openai:gpt-4-0613 discovered via API but not in local config; using defaults with environment API key.\n",
      "2025-03-21 00:23:34,891 [DEBUG] ember.core.registry.model.base.registry.discovery: Successfully merged model info for openai:gpt-4-0613\n",
      "2025-03-21 00:23:34,894 [WARNING] ember.core.registry.model.base.registry.discovery: Model openai:gpt-4.5-preview discovered via API but not in local config; using defaults with environment API key.\n",
      "2025-03-21 00:23:34,897 [DEBUG] ember.core.registry.model.base.registry.discovery: Successfully merged model info for openai:gpt-4.5-preview\n",
      "2025-03-21 00:23:34,899 [WARNING] ember.core.registry.model.base.registry.discovery: Model openai:gpt-4.5-preview-2025-02-27 discovered via API but not in local config; using defaults with environment API key.\n",
      "2025-03-21 00:23:34,900 [DEBUG] ember.core.registry.model.base.registry.discovery: Successfully merged model info for openai:gpt-4.5-preview-2025-02-27\n",
      "2025-03-21 00:23:34,901 [WARNING] ember.core.registry.model.base.registry.discovery: Model openai:gpt-4o-search-preview-2025-03-11 discovered via API but not in local config; using defaults with environment API key.\n",
      "2025-03-21 00:23:34,902 [DEBUG] ember.core.registry.model.base.registry.discovery: Successfully merged model info for openai:gpt-4o-search-preview-2025-03-11\n",
      "2025-03-21 00:23:34,903 [WARNING] ember.core.registry.model.base.registry.discovery: Model openai:gpt-4o-2024-11-20 discovered via API but not in local config; using defaults with environment API key.\n",
      "2025-03-21 00:23:34,904 [DEBUG] ember.core.registry.model.base.registry.discovery: Successfully merged model info for openai:gpt-4o-2024-11-20\n",
      "2025-03-21 00:23:34,905 [WARNING] ember.core.registry.model.base.registry.discovery: Model openai:gpt-4o-mini-2024-07-18 discovered via API but not in local config; using defaults with environment API key.\n",
      "2025-03-21 00:23:34,905 [DEBUG] ember.core.registry.model.base.registry.discovery: Successfully merged model info for openai:gpt-4o-mini-2024-07-18\n",
      "2025-03-21 00:23:34,906 [WARNING] ember.core.registry.model.base.registry.discovery: Model openai:gpt-4o-mini-tts discovered via API but not in local config; using defaults with environment API key.\n",
      "2025-03-21 00:23:34,907 [DEBUG] ember.core.registry.model.base.registry.discovery: Successfully merged model info for openai:gpt-4o-mini-tts\n",
      "2025-03-21 00:23:34,907 [WARNING] ember.core.registry.model.base.registry.discovery: Model openai:gpt-4o-mini discovered via API but not in local config; using defaults with environment API key.\n",
      "2025-03-21 00:23:34,908 [DEBUG] ember.core.registry.model.base.registry.discovery: Successfully merged model info for openai:gpt-4o-mini\n",
      "2025-03-21 00:23:34,909 [WARNING] ember.core.registry.model.base.registry.discovery: Model openai:gpt-4-0125-preview discovered via API but not in local config; using defaults with environment API key.\n",
      "2025-03-21 00:23:34,912 [DEBUG] ember.core.registry.model.base.registry.discovery: Successfully merged model info for openai:gpt-4-0125-preview\n",
      "2025-03-21 00:23:34,913 [WARNING] ember.core.registry.model.base.registry.discovery: Model openai:gpt-4o-transcribe discovered via API but not in local config; using defaults with environment API key.\n",
      "2025-03-21 00:23:34,915 [DEBUG] ember.core.registry.model.base.registry.discovery: Successfully merged model info for openai:gpt-4o-transcribe\n",
      "2025-03-21 00:23:34,916 [WARNING] ember.core.registry.model.base.registry.discovery: Model openai:text-embedding-3-small discovered via API but not in local config; using defaults with environment API key.\n",
      "2025-03-21 00:23:34,917 [DEBUG] ember.core.registry.model.base.registry.discovery: Successfully merged model info for openai:text-embedding-3-small\n",
      "2025-03-21 00:23:34,917 [WARNING] ember.core.registry.model.base.registry.discovery: Model openai:gpt-4o-mini-audio-preview-2024-12-17 discovered via API but not in local config; using defaults with environment API key.\n",
      "2025-03-21 00:23:34,918 [DEBUG] ember.core.registry.model.base.registry.discovery: Successfully merged model info for openai:gpt-4o-mini-audio-preview-2024-12-17\n",
      "2025-03-21 00:23:34,919 [WARNING] ember.core.registry.model.base.registry.discovery: Model anthropic:claude-3-sonnet discovered via API but not in local config; using defaults with environment API key.\n",
      "2025-03-21 00:23:34,920 [DEBUG] ember.core.registry.model.base.registry.discovery: Successfully merged model info for anthropic:claude-3-sonnet\n",
      "2025-03-21 00:23:34,921 [WARNING] ember.core.registry.model.base.registry.discovery: Model anthropic:claude-3-opus discovered via API but not in local config; using defaults with environment API key.\n",
      "2025-03-21 00:23:34,922 [DEBUG] ember.core.registry.model.base.registry.discovery: Successfully merged model info for anthropic:claude-3-opus\n",
      "2025-03-21 00:23:34,925 [WARNING] ember.core.registry.model.base.registry.discovery: Model anthropic:claude-3-haiku discovered via API but not in local config; using defaults with environment API key.\n",
      "2025-03-21 00:23:34,927 [DEBUG] ember.core.registry.model.base.registry.discovery: Successfully merged model info for anthropic:claude-3-haiku\n",
      "2025-03-21 00:23:34,928 [WARNING] ember.core.registry.model.base.registry.discovery: Model anthropic:claude-3.5-sonnet discovered via API but not in local config; using defaults with environment API key.\n",
      "2025-03-21 00:23:34,929 [DEBUG] ember.core.registry.model.base.registry.discovery: Successfully merged model info for anthropic:claude-3.5-sonnet\n",
      "2025-03-21 00:23:34,931 [WARNING] ember.core.registry.model.base.registry.discovery: Model anthropic:claude-3.7-sonnet discovered via API but not in local config; using defaults with environment API key.\n",
      "2025-03-21 00:23:34,932 [DEBUG] ember.core.registry.model.base.registry.discovery: Successfully merged model info for anthropic:claude-3.7-sonnet\n",
      "2025-03-21 00:23:34,934 [WARNING] ember.core.registry.model.base.registry.discovery: Model google:models/gemini-1.0-pro-vision-latest discovered via API but not in local config; using defaults with environment API key.\n",
      "2025-03-21 00:23:34,935 [DEBUG] ember.core.registry.model.base.registry.discovery: Successfully merged model info for google:models/gemini-1.0-pro-vision-latest\n",
      "2025-03-21 00:23:34,936 [WARNING] ember.core.registry.model.base.registry.discovery: Model google:models/gemini-pro-vision discovered via API but not in local config; using defaults with environment API key.\n",
      "2025-03-21 00:23:34,937 [DEBUG] ember.core.registry.model.base.registry.discovery: Successfully merged model info for google:models/gemini-pro-vision\n",
      "2025-03-21 00:23:34,938 [WARNING] ember.core.registry.model.base.registry.discovery: Model google:models/gemini-1.5-pro-latest discovered via API but not in local config; using defaults with environment API key.\n",
      "2025-03-21 00:23:34,940 [DEBUG] ember.core.registry.model.base.registry.discovery: Successfully merged model info for google:models/gemini-1.5-pro-latest\n",
      "2025-03-21 00:23:34,940 [WARNING] ember.core.registry.model.base.registry.discovery: Model google:models/gemini-1.5-pro-001 discovered via API but not in local config; using defaults with environment API key.\n",
      "2025-03-21 00:23:34,941 [DEBUG] ember.core.registry.model.base.registry.discovery: Successfully merged model info for google:models/gemini-1.5-pro-001\n",
      "2025-03-21 00:23:34,942 [WARNING] ember.core.registry.model.base.registry.discovery: Model google:models/gemini-1.5-pro-002 discovered via API but not in local config; using defaults with environment API key.\n",
      "2025-03-21 00:23:34,943 [DEBUG] ember.core.registry.model.base.registry.discovery: Successfully merged model info for google:models/gemini-1.5-pro-002\n",
      "2025-03-21 00:23:34,944 [WARNING] ember.core.registry.model.base.registry.discovery: Model google:models/gemini-1.5-pro discovered via API but not in local config; using defaults with environment API key.\n",
      "2025-03-21 00:23:34,946 [DEBUG] ember.core.registry.model.base.registry.discovery: Successfully merged model info for google:models/gemini-1.5-pro\n",
      "2025-03-21 00:23:34,947 [WARNING] ember.core.registry.model.base.registry.discovery: Model google:models/gemini-1.5-flash-latest discovered via API but not in local config; using defaults with environment API key.\n",
      "2025-03-21 00:23:34,947 [DEBUG] ember.core.registry.model.base.registry.discovery: Successfully merged model info for google:models/gemini-1.5-flash-latest\n",
      "2025-03-21 00:23:34,949 [WARNING] ember.core.registry.model.base.registry.discovery: Model google:models/gemini-1.5-flash-001 discovered via API but not in local config; using defaults with environment API key.\n",
      "2025-03-21 00:23:34,951 [DEBUG] ember.core.registry.model.base.registry.discovery: Successfully merged model info for google:models/gemini-1.5-flash-001\n",
      "2025-03-21 00:23:34,952 [WARNING] ember.core.registry.model.base.registry.discovery: Model google:models/gemini-1.5-flash-001-tuning discovered via API but not in local config; using defaults with environment API key.\n",
      "2025-03-21 00:23:34,953 [DEBUG] ember.core.registry.model.base.registry.discovery: Successfully merged model info for google:models/gemini-1.5-flash-001-tuning\n",
      "2025-03-21 00:23:34,955 [WARNING] ember.core.registry.model.base.registry.discovery: Model google:models/gemini-1.5-flash discovered via API but not in local config; using defaults with environment API key.\n",
      "2025-03-21 00:23:34,956 [DEBUG] ember.core.registry.model.base.registry.discovery: Successfully merged model info for google:models/gemini-1.5-flash\n",
      "2025-03-21 00:23:34,957 [WARNING] ember.core.registry.model.base.registry.discovery: Model google:models/gemini-1.5-flash-002 discovered via API but not in local config; using defaults with environment API key.\n",
      "2025-03-21 00:23:34,958 [DEBUG] ember.core.registry.model.base.registry.discovery: Successfully merged model info for google:models/gemini-1.5-flash-002\n",
      "2025-03-21 00:23:34,959 [WARNING] ember.core.registry.model.base.registry.discovery: Model google:models/gemini-1.5-flash-8b discovered via API but not in local config; using defaults with environment API key.\n",
      "2025-03-21 00:23:34,960 [DEBUG] ember.core.registry.model.base.registry.discovery: Successfully merged model info for google:models/gemini-1.5-flash-8b\n",
      "2025-03-21 00:23:34,961 [WARNING] ember.core.registry.model.base.registry.discovery: Model google:models/gemini-1.5-flash-8b-001 discovered via API but not in local config; using defaults with environment API key.\n",
      "2025-03-21 00:23:34,965 [DEBUG] ember.core.registry.model.base.registry.discovery: Successfully merged model info for google:models/gemini-1.5-flash-8b-001\n",
      "2025-03-21 00:23:34,966 [WARNING] ember.core.registry.model.base.registry.discovery: Model google:models/gemini-1.5-flash-8b-latest discovered via API but not in local config; using defaults with environment API key.\n",
      "2025-03-21 00:23:34,967 [DEBUG] ember.core.registry.model.base.registry.discovery: Successfully merged model info for google:models/gemini-1.5-flash-8b-latest\n",
      "2025-03-21 00:23:34,969 [WARNING] ember.core.registry.model.base.registry.discovery: Model google:models/gemini-1.5-flash-8b-exp-0827 discovered via API but not in local config; using defaults with environment API key.\n",
      "2025-03-21 00:23:34,970 [DEBUG] ember.core.registry.model.base.registry.discovery: Successfully merged model info for google:models/gemini-1.5-flash-8b-exp-0827\n",
      "2025-03-21 00:23:34,970 [WARNING] ember.core.registry.model.base.registry.discovery: Model google:models/gemini-1.5-flash-8b-exp-0924 discovered via API but not in local config; using defaults with environment API key.\n",
      "2025-03-21 00:23:34,971 [DEBUG] ember.core.registry.model.base.registry.discovery: Successfully merged model info for google:models/gemini-1.5-flash-8b-exp-0924\n",
      "2025-03-21 00:23:34,973 [WARNING] ember.core.registry.model.base.registry.discovery: Model google:models/gemini-2.0-flash-exp discovered via API but not in local config; using defaults with environment API key.\n",
      "2025-03-21 00:23:34,975 [DEBUG] ember.core.registry.model.base.registry.discovery: Successfully merged model info for google:models/gemini-2.0-flash-exp\n",
      "2025-03-21 00:23:34,976 [WARNING] ember.core.registry.model.base.registry.discovery: Model google:models/gemini-2.0-flash discovered via API but not in local config; using defaults with environment API key.\n",
      "2025-03-21 00:23:34,977 [DEBUG] ember.core.registry.model.base.registry.discovery: Successfully merged model info for google:models/gemini-2.0-flash\n",
      "2025-03-21 00:23:34,978 [WARNING] ember.core.registry.model.base.registry.discovery: Model google:models/gemini-2.0-flash-001 discovered via API but not in local config; using defaults with environment API key.\n",
      "2025-03-21 00:23:34,980 [DEBUG] ember.core.registry.model.base.registry.discovery: Successfully merged model info for google:models/gemini-2.0-flash-001\n",
      "2025-03-21 00:23:34,982 [WARNING] ember.core.registry.model.base.registry.discovery: Model google:models/gemini-2.0-flash-exp-image-generation discovered via API but not in local config; using defaults with environment API key.\n",
      "2025-03-21 00:23:34,983 [DEBUG] ember.core.registry.model.base.registry.discovery: Successfully merged model info for google:models/gemini-2.0-flash-exp-image-generation\n",
      "2025-03-21 00:23:34,985 [WARNING] ember.core.registry.model.base.registry.discovery: Model google:models/gemini-2.0-flash-lite-001 discovered via API but not in local config; using defaults with environment API key.\n",
      "2025-03-21 00:23:34,986 [DEBUG] ember.core.registry.model.base.registry.discovery: Successfully merged model info for google:models/gemini-2.0-flash-lite-001\n",
      "2025-03-21 00:23:34,987 [WARNING] ember.core.registry.model.base.registry.discovery: Model google:models/gemini-2.0-flash-lite discovered via API but not in local config; using defaults with environment API key.\n",
      "2025-03-21 00:23:34,987 [DEBUG] ember.core.registry.model.base.registry.discovery: Successfully merged model info for google:models/gemini-2.0-flash-lite\n",
      "2025-03-21 00:23:34,989 [WARNING] ember.core.registry.model.base.registry.discovery: Model google:models/gemini-2.0-flash-lite-preview-02-05 discovered via API but not in local config; using defaults with environment API key.\n",
      "2025-03-21 00:23:34,989 [DEBUG] ember.core.registry.model.base.registry.discovery: Successfully merged model info for google:models/gemini-2.0-flash-lite-preview-02-05\n",
      "2025-03-21 00:23:34,990 [WARNING] ember.core.registry.model.base.registry.discovery: Model google:models/gemini-2.0-flash-lite-preview discovered via API but not in local config; using defaults with environment API key.\n",
      "2025-03-21 00:23:34,991 [DEBUG] ember.core.registry.model.base.registry.discovery: Successfully merged model info for google:models/gemini-2.0-flash-lite-preview\n",
      "2025-03-21 00:23:34,993 [WARNING] ember.core.registry.model.base.registry.discovery: Model google:models/gemini-2.0-pro-exp discovered via API but not in local config; using defaults with environment API key.\n",
      "2025-03-21 00:23:34,994 [DEBUG] ember.core.registry.model.base.registry.discovery: Successfully merged model info for google:models/gemini-2.0-pro-exp\n",
      "2025-03-21 00:23:34,997 [WARNING] ember.core.registry.model.base.registry.discovery: Model google:models/gemini-2.0-pro-exp-02-05 discovered via API but not in local config; using defaults with environment API key.\n",
      "2025-03-21 00:23:34,998 [DEBUG] ember.core.registry.model.base.registry.discovery: Successfully merged model info for google:models/gemini-2.0-pro-exp-02-05\n",
      "2025-03-21 00:23:35,000 [WARNING] ember.core.registry.model.base.registry.discovery: Model google:models/gemini-exp-1206 discovered via API but not in local config; using defaults with environment API key.\n",
      "2025-03-21 00:23:35,001 [DEBUG] ember.core.registry.model.base.registry.discovery: Successfully merged model info for google:models/gemini-exp-1206\n",
      "2025-03-21 00:23:35,003 [WARNING] ember.core.registry.model.base.registry.discovery: Model google:models/gemini-2.0-flash-thinking-exp-01-21 discovered via API but not in local config; using defaults with environment API key.\n",
      "2025-03-21 00:23:35,004 [DEBUG] ember.core.registry.model.base.registry.discovery: Successfully merged model info for google:models/gemini-2.0-flash-thinking-exp-01-21\n",
      "2025-03-21 00:23:35,004 [WARNING] ember.core.registry.model.base.registry.discovery: Model google:models/gemini-2.0-flash-thinking-exp discovered via API but not in local config; using defaults with environment API key.\n",
      "2025-03-21 00:23:35,005 [DEBUG] ember.core.registry.model.base.registry.discovery: Successfully merged model info for google:models/gemini-2.0-flash-thinking-exp\n",
      "2025-03-21 00:23:35,006 [WARNING] ember.core.registry.model.base.registry.discovery: Model google:models/gemini-2.0-flash-thinking-exp-1219 discovered via API but not in local config; using defaults with environment API key.\n",
      "2025-03-21 00:23:35,008 [DEBUG] ember.core.registry.model.base.registry.discovery: Successfully merged model info for google:models/gemini-2.0-flash-thinking-exp-1219\n",
      "2025-03-21 00:23:35,011 [WARNING] ember.core.registry.model.base.registry.discovery: Model google:models/learnlm-1.5-pro-experimental discovered via API but not in local config; using defaults with environment API key.\n",
      "2025-03-21 00:23:35,013 [DEBUG] ember.core.registry.model.base.registry.discovery: Successfully merged model info for google:models/learnlm-1.5-pro-experimental\n",
      "2025-03-21 00:23:35,014 [WARNING] ember.core.registry.model.base.registry.discovery: Model google:models/gemma-3-27b-it discovered via API but not in local config; using defaults with environment API key.\n",
      "2025-03-21 00:23:35,015 [DEBUG] ember.core.registry.model.base.registry.discovery: Successfully merged model info for google:models/gemma-3-27b-it\n",
      "2025-03-21 00:23:35,017 [DEBUG] ember.core.registry.model.initialization: Merged discovery found 80 models: ['openai:gpt-4o-mini-transcribe', 'openai:gpt-4o-audio-preview-2024-12-17', 'openai:dall-e-3', 'openai:dall-e-2', 'openai:gpt-4o-audio-preview-2024-10-01', 'openai:gpt-4o-realtime-preview-2024-10-01', 'openai:gpt-4o-audio-preview', 'openai:text-embedding-3-large', 'openai:gpt-4', 'openai:gpt-4o-2024-05-13', 'openai:gpt-4o-realtime-preview', 'openai:gpt-4o-mini-audio-preview', 'openai:gpt-3.5-turbo-instruct-0914', 'openai:gpt-4o-mini-search-preview', 'openai:gpt-3.5-turbo-1106', 'openai:gpt-4o-search-preview', 'openai:gpt-4-turbo', 'openai:gpt-4o-realtime-preview-2024-12-17', 'openai:gpt-3.5-turbo-instruct', 'openai:gpt-3.5-turbo', 'openai:gpt-4-turbo-preview', 'openai:gpt-4o-mini-search-preview-2025-03-11', 'openai:gpt-4o-mini-realtime-preview', 'openai:gpt-3.5-turbo-0125', 'openai:gpt-4o-2024-08-06', 'openai:gpt-4-turbo-2024-04-09', 'openai:gpt-3.5-turbo-16k', 'openai:gpt-4o', 'openai:gpt-4o-mini-realtime-preview-2024-12-17', 'openai:gpt-4-1106-preview', 'openai:text-embedding-ada-002', 'openai:gpt-4-0613', 'openai:gpt-4.5-preview', 'openai:gpt-4.5-preview-2025-02-27', 'openai:gpt-4o-search-preview-2025-03-11', 'openai:gpt-4o-2024-11-20', 'openai:gpt-4o-mini-2024-07-18', 'openai:gpt-4o-mini-tts', 'openai:gpt-4o-mini', 'openai:gpt-4-0125-preview', 'openai:gpt-4o-transcribe', 'openai:text-embedding-3-small', 'openai:gpt-4o-mini-audio-preview-2024-12-17', 'anthropic:claude-3-sonnet', 'anthropic:claude-3-opus', 'anthropic:claude-3-haiku', 'anthropic:claude-3.5-sonnet', 'anthropic:claude-3.7-sonnet', 'google:models/gemini-1.0-pro-vision-latest', 'google:models/gemini-pro-vision', 'google:models/gemini-1.5-pro-latest', 'google:models/gemini-1.5-pro-001', 'google:models/gemini-1.5-pro-002', 'google:models/gemini-1.5-pro', 'google:models/gemini-1.5-flash-latest', 'google:models/gemini-1.5-flash-001', 'google:models/gemini-1.5-flash-001-tuning', 'google:models/gemini-1.5-flash', 'google:models/gemini-1.5-flash-002', 'google:models/gemini-1.5-flash-8b', 'google:models/gemini-1.5-flash-8b-001', 'google:models/gemini-1.5-flash-8b-latest', 'google:models/gemini-1.5-flash-8b-exp-0827', 'google:models/gemini-1.5-flash-8b-exp-0924', 'google:models/gemini-2.0-flash-exp', 'google:models/gemini-2.0-flash', 'google:models/gemini-2.0-flash-001', 'google:models/gemini-2.0-flash-exp-image-generation', 'google:models/gemini-2.0-flash-lite-001', 'google:models/gemini-2.0-flash-lite', 'google:models/gemini-2.0-flash-lite-preview-02-05', 'google:models/gemini-2.0-flash-lite-preview', 'google:models/gemini-2.0-pro-exp', 'google:models/gemini-2.0-pro-exp-02-05', 'google:models/gemini-exp-1206', 'google:models/gemini-2.0-flash-thinking-exp-01-21', 'google:models/gemini-2.0-flash-thinking-exp', 'google:models/gemini-2.0-flash-thinking-exp-1219', 'google:models/learnlm-1.5-pro-experimental', 'google:models/gemma-3-27b-it']\n",
      "2025-03-21 00:23:35,018 [INFO] ember.core.registry.model.initialization: Registering 80 models from discovery\n",
      "2025-03-21 00:23:35,022 [DEBUG] ember.core.registry.model.initialization: Attempting to register discovered model: openai:gpt-4o-mini-transcribe (provider: Openai)\n",
      "2025-03-21 00:23:35,025 [INFO] ember.core.registry.model.initialization: Successfully registered model: openai:gpt-4o-mini-transcribe with provider Openai\n",
      "2025-03-21 00:23:35,027 [INFO] ember.core.registry.model.initialization: Successfully registered model: openai:gpt-4o-mini-transcribe with provider Openai\n",
      "2025-03-21 00:23:35,031 [DEBUG] ember.core.registry.model.initialization: Attempting to register discovered model: openai:gpt-4o-audio-preview-2024-12-17 (provider: Openai)\n",
      "2025-03-21 00:23:35,032 [INFO] ember.core.registry.model.initialization: Successfully registered model: openai:gpt-4o-audio-preview-2024-12-17 with provider Openai\n",
      "2025-03-21 00:23:35,035 [INFO] ember.core.registry.model.initialization: Successfully registered model: openai:gpt-4o-audio-preview-2024-12-17 with provider Openai\n",
      "2025-03-21 00:23:35,037 [DEBUG] ember.core.registry.model.initialization: Attempting to register discovered model: openai:dall-e-3 (provider: Openai)\n",
      "2025-03-21 00:23:35,038 [INFO] ember.core.registry.model.initialization: Successfully registered model: openai:dall-e-3 with provider Openai\n",
      "2025-03-21 00:23:35,039 [INFO] ember.core.registry.model.initialization: Successfully registered model: openai:dall-e-3 with provider Openai\n",
      "2025-03-21 00:23:35,040 [DEBUG] ember.core.registry.model.initialization: Attempting to register discovered model: openai:dall-e-2 (provider: Openai)\n",
      "2025-03-21 00:23:35,041 [INFO] ember.core.registry.model.initialization: Successfully registered model: openai:dall-e-2 with provider Openai\n",
      "2025-03-21 00:23:35,042 [INFO] ember.core.registry.model.initialization: Successfully registered model: openai:dall-e-2 with provider Openai\n",
      "2025-03-21 00:23:35,043 [DEBUG] ember.core.registry.model.initialization: Attempting to register discovered model: openai:gpt-4o-audio-preview-2024-10-01 (provider: Openai)\n",
      "2025-03-21 00:23:35,044 [INFO] ember.core.registry.model.initialization: Successfully registered model: openai:gpt-4o-audio-preview-2024-10-01 with provider Openai\n",
      "2025-03-21 00:23:35,045 [INFO] ember.core.registry.model.initialization: Successfully registered model: openai:gpt-4o-audio-preview-2024-10-01 with provider Openai\n",
      "2025-03-21 00:23:35,047 [DEBUG] ember.core.registry.model.initialization: Attempting to register discovered model: openai:gpt-4o-realtime-preview-2024-10-01 (provider: Openai)\n",
      "2025-03-21 00:23:35,048 [INFO] ember.core.registry.model.initialization: Successfully registered model: openai:gpt-4o-realtime-preview-2024-10-01 with provider Openai\n",
      "2025-03-21 00:23:35,050 [INFO] ember.core.registry.model.initialization: Successfully registered model: openai:gpt-4o-realtime-preview-2024-10-01 with provider Openai\n",
      "2025-03-21 00:23:35,051 [DEBUG] ember.core.registry.model.initialization: Attempting to register discovered model: openai:gpt-4o-audio-preview (provider: Openai)\n",
      "2025-03-21 00:23:35,056 [INFO] ember.core.registry.model.initialization: Successfully registered model: openai:gpt-4o-audio-preview with provider Openai\n",
      "2025-03-21 00:23:35,057 [INFO] ember.core.registry.model.initialization: Successfully registered model: openai:gpt-4o-audio-preview with provider Openai\n",
      "2025-03-21 00:23:35,059 [DEBUG] ember.core.registry.model.initialization: Attempting to register discovered model: openai:text-embedding-3-large (provider: Openai)\n",
      "2025-03-21 00:23:35,063 [INFO] ember.core.registry.model.initialization: Successfully registered model: openai:text-embedding-3-large with provider Openai\n",
      "2025-03-21 00:23:35,064 [INFO] ember.core.registry.model.initialization: Successfully registered model: openai:text-embedding-3-large with provider Openai\n",
      "2025-03-21 00:23:35,066 [DEBUG] ember.core.registry.model.initialization: Attempting to register discovered model: openai:gpt-4 (provider: Openai)\n",
      "2025-03-21 00:23:35,067 [INFO] ember.core.registry.model.initialization: Successfully registered model: openai:gpt-4 with provider Openai\n",
      "2025-03-21 00:23:35,068 [INFO] ember.core.registry.model.initialization: Successfully registered model: openai:gpt-4 with provider Openai\n",
      "2025-03-21 00:23:35,069 [DEBUG] ember.core.registry.model.initialization: Attempting to register discovered model: openai:gpt-4o-2024-05-13 (provider: Openai)\n",
      "2025-03-21 00:23:35,073 [INFO] ember.core.registry.model.initialization: Successfully registered model: openai:gpt-4o-2024-05-13 with provider Openai\n",
      "2025-03-21 00:23:35,075 [INFO] ember.core.registry.model.initialization: Successfully registered model: openai:gpt-4o-2024-05-13 with provider Openai\n",
      "2025-03-21 00:23:35,076 [DEBUG] ember.core.registry.model.initialization: Attempting to register discovered model: openai:gpt-4o-realtime-preview (provider: Openai)\n",
      "2025-03-21 00:23:35,077 [INFO] ember.core.registry.model.initialization: Successfully registered model: openai:gpt-4o-realtime-preview with provider Openai\n",
      "2025-03-21 00:23:35,078 [INFO] ember.core.registry.model.initialization: Successfully registered model: openai:gpt-4o-realtime-preview with provider Openai\n",
      "2025-03-21 00:23:35,079 [DEBUG] ember.core.registry.model.initialization: Attempting to register discovered model: openai:gpt-4o-mini-audio-preview (provider: Openai)\n",
      "2025-03-21 00:23:35,080 [INFO] ember.core.registry.model.initialization: Successfully registered model: openai:gpt-4o-mini-audio-preview with provider Openai\n",
      "2025-03-21 00:23:35,081 [INFO] ember.core.registry.model.initialization: Successfully registered model: openai:gpt-4o-mini-audio-preview with provider Openai\n",
      "2025-03-21 00:23:35,083 [DEBUG] ember.core.registry.model.initialization: Attempting to register discovered model: openai:gpt-3.5-turbo-instruct-0914 (provider: Openai)\n",
      "2025-03-21 00:23:35,083 [INFO] ember.core.registry.model.initialization: Successfully registered model: openai:gpt-3.5-turbo-instruct-0914 with provider Openai\n",
      "2025-03-21 00:23:35,088 [INFO] ember.core.registry.model.initialization: Successfully registered model: openai:gpt-3.5-turbo-instruct-0914 with provider Openai\n",
      "2025-03-21 00:23:35,090 [DEBUG] ember.core.registry.model.initialization: Attempting to register discovered model: openai:gpt-4o-mini-search-preview (provider: Openai)\n",
      "2025-03-21 00:23:35,091 [INFO] ember.core.registry.model.initialization: Successfully registered model: openai:gpt-4o-mini-search-preview with provider Openai\n",
      "2025-03-21 00:23:35,092 [INFO] ember.core.registry.model.initialization: Successfully registered model: openai:gpt-4o-mini-search-preview with provider Openai\n",
      "2025-03-21 00:23:35,093 [DEBUG] ember.core.registry.model.initialization: Attempting to register discovered model: openai:gpt-3.5-turbo-1106 (provider: Openai)\n",
      "2025-03-21 00:23:35,096 [INFO] ember.core.registry.model.initialization: Successfully registered model: openai:gpt-3.5-turbo-1106 with provider Openai\n",
      "2025-03-21 00:23:35,097 [INFO] ember.core.registry.model.initialization: Successfully registered model: openai:gpt-3.5-turbo-1106 with provider Openai\n",
      "2025-03-21 00:23:35,098 [DEBUG] ember.core.registry.model.initialization: Attempting to register discovered model: openai:gpt-4o-search-preview (provider: Openai)\n",
      "2025-03-21 00:23:35,098 [INFO] ember.core.registry.model.initialization: Successfully registered model: openai:gpt-4o-search-preview with provider Openai\n",
      "2025-03-21 00:23:35,099 [INFO] ember.core.registry.model.initialization: Successfully registered model: openai:gpt-4o-search-preview with provider Openai\n",
      "2025-03-21 00:23:35,101 [DEBUG] ember.core.registry.model.initialization: Attempting to register discovered model: openai:gpt-4-turbo (provider: Openai)\n",
      "2025-03-21 00:23:35,102 [INFO] ember.core.registry.model.initialization: Successfully registered model: openai:gpt-4-turbo with provider Openai\n",
      "2025-03-21 00:23:35,104 [INFO] ember.core.registry.model.initialization: Successfully registered model: openai:gpt-4-turbo with provider Openai\n",
      "2025-03-21 00:23:35,108 [DEBUG] ember.core.registry.model.initialization: Attempting to register discovered model: openai:gpt-4o-realtime-preview-2024-12-17 (provider: Openai)\n",
      "2025-03-21 00:23:35,109 [INFO] ember.core.registry.model.initialization: Successfully registered model: openai:gpt-4o-realtime-preview-2024-12-17 with provider Openai\n",
      "2025-03-21 00:23:35,111 [INFO] ember.core.registry.model.initialization: Successfully registered model: openai:gpt-4o-realtime-preview-2024-12-17 with provider Openai\n",
      "2025-03-21 00:23:35,114 [DEBUG] ember.core.registry.model.initialization: Attempting to register discovered model: openai:gpt-3.5-turbo-instruct (provider: Openai)\n",
      "2025-03-21 00:23:35,115 [INFO] ember.core.registry.model.initialization: Successfully registered model: openai:gpt-3.5-turbo-instruct with provider Openai\n",
      "2025-03-21 00:23:35,116 [INFO] ember.core.registry.model.initialization: Successfully registered model: openai:gpt-3.5-turbo-instruct with provider Openai\n",
      "2025-03-21 00:23:35,118 [DEBUG] ember.core.registry.model.initialization: Attempting to register discovered model: openai:gpt-3.5-turbo (provider: Openai)\n",
      "2025-03-21 00:23:35,119 [INFO] ember.core.registry.model.initialization: Successfully registered model: openai:gpt-3.5-turbo with provider Openai\n",
      "2025-03-21 00:23:35,120 [INFO] ember.core.registry.model.initialization: Successfully registered model: openai:gpt-3.5-turbo with provider Openai\n",
      "2025-03-21 00:23:35,121 [DEBUG] ember.core.registry.model.initialization: Attempting to register discovered model: openai:gpt-4-turbo-preview (provider: Openai)\n",
      "2025-03-21 00:23:35,122 [INFO] ember.core.registry.model.initialization: Successfully registered model: openai:gpt-4-turbo-preview with provider Openai\n",
      "2025-03-21 00:23:35,123 [INFO] ember.core.registry.model.initialization: Successfully registered model: openai:gpt-4-turbo-preview with provider Openai\n",
      "2025-03-21 00:23:35,124 [DEBUG] ember.core.registry.model.initialization: Attempting to register discovered model: openai:gpt-4o-mini-search-preview-2025-03-11 (provider: Openai)\n",
      "2025-03-21 00:23:35,126 [INFO] ember.core.registry.model.initialization: Successfully registered model: openai:gpt-4o-mini-search-preview-2025-03-11 with provider Openai\n",
      "2025-03-21 00:23:35,127 [INFO] ember.core.registry.model.initialization: Successfully registered model: openai:gpt-4o-mini-search-preview-2025-03-11 with provider Openai\n",
      "2025-03-21 00:23:35,128 [DEBUG] ember.core.registry.model.initialization: Attempting to register discovered model: openai:gpt-4o-mini-realtime-preview (provider: Openai)\n",
      "2025-03-21 00:23:35,130 [INFO] ember.core.registry.model.initialization: Successfully registered model: openai:gpt-4o-mini-realtime-preview with provider Openai\n",
      "2025-03-21 00:23:35,131 [INFO] ember.core.registry.model.initialization: Successfully registered model: openai:gpt-4o-mini-realtime-preview with provider Openai\n",
      "2025-03-21 00:23:35,132 [DEBUG] ember.core.registry.model.initialization: Attempting to register discovered model: openai:gpt-3.5-turbo-0125 (provider: Openai)\n",
      "2025-03-21 00:23:35,132 [INFO] ember.core.registry.model.initialization: Successfully registered model: openai:gpt-3.5-turbo-0125 with provider Openai\n",
      "2025-03-21 00:23:35,133 [INFO] ember.core.registry.model.initialization: Successfully registered model: openai:gpt-3.5-turbo-0125 with provider Openai\n",
      "2025-03-21 00:23:35,135 [DEBUG] ember.core.registry.model.initialization: Attempting to register discovered model: openai:gpt-4o-2024-08-06 (provider: Openai)\n",
      "2025-03-21 00:23:35,136 [INFO] ember.core.registry.model.initialization: Successfully registered model: openai:gpt-4o-2024-08-06 with provider Openai\n",
      "2025-03-21 00:23:35,136 [INFO] ember.core.registry.model.initialization: Successfully registered model: openai:gpt-4o-2024-08-06 with provider Openai\n",
      "2025-03-21 00:23:35,137 [DEBUG] ember.core.registry.model.initialization: Attempting to register discovered model: openai:gpt-4-turbo-2024-04-09 (provider: Openai)\n",
      "2025-03-21 00:23:35,143 [INFO] ember.core.registry.model.initialization: Successfully registered model: openai:gpt-4-turbo-2024-04-09 with provider Openai\n",
      "2025-03-21 00:23:35,144 [INFO] ember.core.registry.model.initialization: Successfully registered model: openai:gpt-4-turbo-2024-04-09 with provider Openai\n",
      "2025-03-21 00:23:35,145 [DEBUG] ember.core.registry.model.initialization: Attempting to register discovered model: openai:gpt-3.5-turbo-16k (provider: Openai)\n",
      "2025-03-21 00:23:35,147 [INFO] ember.core.registry.model.initialization: Successfully registered model: openai:gpt-3.5-turbo-16k with provider Openai\n",
      "2025-03-21 00:23:35,148 [INFO] ember.core.registry.model.initialization: Successfully registered model: openai:gpt-3.5-turbo-16k with provider Openai\n",
      "2025-03-21 00:23:35,148 [DEBUG] ember.core.registry.model.initialization: Attempting to register discovered model: openai:gpt-4o (provider: Openai)\n",
      "2025-03-21 00:23:35,149 [INFO] ember.core.registry.model.initialization: Successfully registered model: openai:gpt-4o with provider Openai\n",
      "2025-03-21 00:23:35,150 [INFO] ember.core.registry.model.initialization: Successfully registered model: openai:gpt-4o with provider Openai\n",
      "2025-03-21 00:23:35,151 [DEBUG] ember.core.registry.model.initialization: Attempting to register discovered model: openai:gpt-4o-mini-realtime-preview-2024-12-17 (provider: Openai)\n",
      "2025-03-21 00:23:35,152 [INFO] ember.core.registry.model.initialization: Successfully registered model: openai:gpt-4o-mini-realtime-preview-2024-12-17 with provider Openai\n",
      "2025-03-21 00:23:35,155 [INFO] ember.core.registry.model.initialization: Successfully registered model: openai:gpt-4o-mini-realtime-preview-2024-12-17 with provider Openai\n",
      "2025-03-21 00:23:35,157 [DEBUG] ember.core.registry.model.initialization: Attempting to register discovered model: openai:gpt-4-1106-preview (provider: Openai)\n",
      "2025-03-21 00:23:35,159 [INFO] ember.core.registry.model.initialization: Successfully registered model: openai:gpt-4-1106-preview with provider Openai\n",
      "2025-03-21 00:23:35,160 [INFO] ember.core.registry.model.initialization: Successfully registered model: openai:gpt-4-1106-preview with provider Openai\n",
      "2025-03-21 00:23:35,163 [DEBUG] ember.core.registry.model.initialization: Attempting to register discovered model: openai:text-embedding-ada-002 (provider: Openai)\n",
      "2025-03-21 00:23:35,168 [INFO] ember.core.registry.model.initialization: Successfully registered model: openai:text-embedding-ada-002 with provider Openai\n",
      "2025-03-21 00:23:35,170 [INFO] ember.core.registry.model.initialization: Successfully registered model: openai:text-embedding-ada-002 with provider Openai\n",
      "2025-03-21 00:23:35,172 [DEBUG] ember.core.registry.model.initialization: Attempting to register discovered model: openai:gpt-4-0613 (provider: Openai)\n",
      "2025-03-21 00:23:35,173 [INFO] ember.core.registry.model.initialization: Successfully registered model: openai:gpt-4-0613 with provider Openai\n",
      "2025-03-21 00:23:35,174 [INFO] ember.core.registry.model.initialization: Successfully registered model: openai:gpt-4-0613 with provider Openai\n",
      "2025-03-21 00:23:35,174 [DEBUG] ember.core.registry.model.initialization: Attempting to register discovered model: openai:gpt-4.5-preview (provider: Openai)\n",
      "2025-03-21 00:23:35,176 [INFO] ember.core.registry.model.initialization: Successfully registered model: openai:gpt-4.5-preview with provider Openai\n",
      "2025-03-21 00:23:35,177 [INFO] ember.core.registry.model.initialization: Successfully registered model: openai:gpt-4.5-preview with provider Openai\n",
      "2025-03-21 00:23:35,178 [DEBUG] ember.core.registry.model.initialization: Attempting to register discovered model: openai:gpt-4.5-preview-2025-02-27 (provider: Openai)\n",
      "2025-03-21 00:23:35,179 [INFO] ember.core.registry.model.initialization: Successfully registered model: openai:gpt-4.5-preview-2025-02-27 with provider Openai\n",
      "2025-03-21 00:23:35,183 [INFO] ember.core.registry.model.initialization: Successfully registered model: openai:gpt-4.5-preview-2025-02-27 with provider Openai\n",
      "2025-03-21 00:23:35,184 [DEBUG] ember.core.registry.model.initialization: Attempting to register discovered model: openai:gpt-4o-search-preview-2025-03-11 (provider: Openai)\n",
      "2025-03-21 00:23:35,185 [INFO] ember.core.registry.model.initialization: Successfully registered model: openai:gpt-4o-search-preview-2025-03-11 with provider Openai\n",
      "2025-03-21 00:23:35,187 [INFO] ember.core.registry.model.initialization: Successfully registered model: openai:gpt-4o-search-preview-2025-03-11 with provider Openai\n",
      "2025-03-21 00:23:35,189 [DEBUG] ember.core.registry.model.initialization: Attempting to register discovered model: openai:gpt-4o-2024-11-20 (provider: Openai)\n",
      "2025-03-21 00:23:35,190 [INFO] ember.core.registry.model.initialization: Successfully registered model: openai:gpt-4o-2024-11-20 with provider Openai\n",
      "2025-03-21 00:23:35,192 [INFO] ember.core.registry.model.initialization: Successfully registered model: openai:gpt-4o-2024-11-20 with provider Openai\n",
      "2025-03-21 00:23:35,193 [DEBUG] ember.core.registry.model.initialization: Attempting to register discovered model: openai:gpt-4o-mini-2024-07-18 (provider: Openai)\n",
      "2025-03-21 00:23:35,194 [INFO] ember.core.registry.model.initialization: Successfully registered model: openai:gpt-4o-mini-2024-07-18 with provider Openai\n",
      "2025-03-21 00:23:35,196 [INFO] ember.core.registry.model.initialization: Successfully registered model: openai:gpt-4o-mini-2024-07-18 with provider Openai\n",
      "2025-03-21 00:23:35,197 [DEBUG] ember.core.registry.model.initialization: Attempting to register discovered model: openai:gpt-4o-mini-tts (provider: Openai)\n",
      "2025-03-21 00:23:35,200 [INFO] ember.core.registry.model.initialization: Successfully registered model: openai:gpt-4o-mini-tts with provider Openai\n",
      "2025-03-21 00:23:35,202 [INFO] ember.core.registry.model.initialization: Successfully registered model: openai:gpt-4o-mini-tts with provider Openai\n",
      "2025-03-21 00:23:35,203 [DEBUG] ember.core.registry.model.initialization: Attempting to register discovered model: openai:gpt-4o-mini (provider: Openai)\n",
      "2025-03-21 00:23:35,204 [INFO] ember.core.registry.model.initialization: Successfully registered model: openai:gpt-4o-mini with provider Openai\n",
      "2025-03-21 00:23:35,205 [INFO] ember.core.registry.model.initialization: Successfully registered model: openai:gpt-4o-mini with provider Openai\n",
      "2025-03-21 00:23:35,208 [DEBUG] ember.core.registry.model.initialization: Attempting to register discovered model: openai:gpt-4-0125-preview (provider: Openai)\n",
      "2025-03-21 00:23:35,209 [INFO] ember.core.registry.model.initialization: Successfully registered model: openai:gpt-4-0125-preview with provider Openai\n",
      "2025-03-21 00:23:35,210 [INFO] ember.core.registry.model.initialization: Successfully registered model: openai:gpt-4-0125-preview with provider Openai\n",
      "2025-03-21 00:23:35,212 [DEBUG] ember.core.registry.model.initialization: Attempting to register discovered model: openai:gpt-4o-transcribe (provider: Openai)\n",
      "2025-03-21 00:23:35,213 [INFO] ember.core.registry.model.initialization: Successfully registered model: openai:gpt-4o-transcribe with provider Openai\n",
      "2025-03-21 00:23:35,215 [INFO] ember.core.registry.model.initialization: Successfully registered model: openai:gpt-4o-transcribe with provider Openai\n",
      "2025-03-21 00:23:35,217 [DEBUG] ember.core.registry.model.initialization: Attempting to register discovered model: openai:text-embedding-3-small (provider: Openai)\n",
      "2025-03-21 00:23:35,220 [INFO] ember.core.registry.model.initialization: Successfully registered model: openai:text-embedding-3-small with provider Openai\n",
      "2025-03-21 00:23:35,222 [INFO] ember.core.registry.model.initialization: Successfully registered model: openai:text-embedding-3-small with provider Openai\n",
      "2025-03-21 00:23:35,224 [DEBUG] ember.core.registry.model.initialization: Attempting to register discovered model: openai:gpt-4o-mini-audio-preview-2024-12-17 (provider: Openai)\n",
      "2025-03-21 00:23:35,226 [INFO] ember.core.registry.model.initialization: Successfully registered model: openai:gpt-4o-mini-audio-preview-2024-12-17 with provider Openai\n",
      "2025-03-21 00:23:35,228 [INFO] ember.core.registry.model.initialization: Successfully registered model: openai:gpt-4o-mini-audio-preview-2024-12-17 with provider Openai\n",
      "2025-03-21 00:23:35,230 [DEBUG] ember.core.registry.model.initialization: Attempting to register discovered model: anthropic:claude-3-sonnet (provider: Anthropic)\n",
      "2025-03-21 00:23:35,232 [INFO] ember.core.registry.model.initialization: Successfully registered model: anthropic:claude-3-sonnet with provider Anthropic\n",
      "2025-03-21 00:23:35,233 [INFO] ember.core.registry.model.initialization: Successfully registered model: anthropic:claude-3-sonnet with provider Anthropic\n",
      "2025-03-21 00:23:35,235 [DEBUG] ember.core.registry.model.initialization: Attempting to register discovered model: anthropic:claude-3-opus (provider: Anthropic)\n",
      "2025-03-21 00:23:35,237 [INFO] ember.core.registry.model.initialization: Successfully registered model: anthropic:claude-3-opus with provider Anthropic\n",
      "2025-03-21 00:23:35,239 [INFO] ember.core.registry.model.initialization: Successfully registered model: anthropic:claude-3-opus with provider Anthropic\n",
      "2025-03-21 00:23:35,241 [DEBUG] ember.core.registry.model.initialization: Attempting to register discovered model: anthropic:claude-3-haiku (provider: Anthropic)\n",
      "2025-03-21 00:23:35,242 [INFO] ember.core.registry.model.initialization: Successfully registered model: anthropic:claude-3-haiku with provider Anthropic\n",
      "2025-03-21 00:23:35,252 [INFO] ember.core.registry.model.initialization: Successfully registered model: anthropic:claude-3-haiku with provider Anthropic\n",
      "2025-03-21 00:23:35,260 [DEBUG] ember.core.registry.model.initialization: Attempting to register discovered model: anthropic:claude-3.5-sonnet (provider: Anthropic)\n",
      "2025-03-21 00:23:35,261 [INFO] ember.core.registry.model.initialization: Successfully registered model: anthropic:claude-3.5-sonnet with provider Anthropic\n",
      "2025-03-21 00:23:35,262 [INFO] ember.core.registry.model.initialization: Successfully registered model: anthropic:claude-3.5-sonnet with provider Anthropic\n",
      "2025-03-21 00:23:35,263 [DEBUG] ember.core.registry.model.initialization: Attempting to register discovered model: anthropic:claude-3.7-sonnet (provider: Anthropic)\n",
      "2025-03-21 00:23:35,265 [INFO] ember.core.registry.model.initialization: Successfully registered model: anthropic:claude-3.7-sonnet with provider Anthropic\n",
      "2025-03-21 00:23:35,266 [INFO] ember.core.registry.model.initialization: Successfully registered model: anthropic:claude-3.7-sonnet with provider Anthropic\n",
      "2025-03-21 00:23:35,266 [DEBUG] ember.core.registry.model.initialization: Attempting to register discovered model: google:models/gemini-1.0-pro-vision-latest (provider: Google)\n",
      "2025-03-21 00:23:35,267 [INFO] ember.core.registry.model.initialization: Successfully registered model: google:models/gemini-1.0-pro-vision-latest with provider Google\n",
      "2025-03-21 00:23:35,268 [INFO] ember.core.registry.model.initialization: Successfully registered model: google:models/gemini-1.0-pro-vision-latest with provider Google\n",
      "2025-03-21 00:23:35,269 [DEBUG] ember.core.registry.model.initialization: Attempting to register discovered model: google:models/gemini-pro-vision (provider: Google)\n",
      "2025-03-21 00:23:35,270 [INFO] ember.core.registry.model.initialization: Successfully registered model: google:models/gemini-pro-vision with provider Google\n",
      "2025-03-21 00:23:35,270 [INFO] ember.core.registry.model.initialization: Successfully registered model: google:models/gemini-pro-vision with provider Google\n",
      "2025-03-21 00:23:35,271 [DEBUG] ember.core.registry.model.initialization: Attempting to register discovered model: google:models/gemini-1.5-pro-latest (provider: Google)\n",
      "2025-03-21 00:23:35,271 [INFO] ember.core.registry.model.initialization: Successfully registered model: google:models/gemini-1.5-pro-latest with provider Google\n",
      "2025-03-21 00:23:35,273 [INFO] ember.core.registry.model.initialization: Successfully registered model: google:models/gemini-1.5-pro-latest with provider Google\n",
      "2025-03-21 00:23:35,275 [DEBUG] ember.core.registry.model.initialization: Attempting to register discovered model: google:models/gemini-1.5-pro-001 (provider: Google)\n",
      "2025-03-21 00:23:35,276 [INFO] ember.core.registry.model.initialization: Successfully registered model: google:models/gemini-1.5-pro-001 with provider Google\n",
      "2025-03-21 00:23:35,277 [INFO] ember.core.registry.model.initialization: Successfully registered model: google:models/gemini-1.5-pro-001 with provider Google\n",
      "2025-03-21 00:23:35,278 [DEBUG] ember.core.registry.model.initialization: Attempting to register discovered model: google:models/gemini-1.5-pro-002 (provider: Google)\n",
      "2025-03-21 00:23:35,280 [INFO] ember.core.registry.model.initialization: Successfully registered model: google:models/gemini-1.5-pro-002 with provider Google\n",
      "2025-03-21 00:23:35,281 [INFO] ember.core.registry.model.initialization: Successfully registered model: google:models/gemini-1.5-pro-002 with provider Google\n",
      "2025-03-21 00:23:35,283 [DEBUG] ember.core.registry.model.initialization: Attempting to register discovered model: google:models/gemini-1.5-pro (provider: Google)\n",
      "2025-03-21 00:23:35,285 [INFO] ember.core.registry.model.initialization: Successfully registered model: google:models/gemini-1.5-pro with provider Google\n",
      "2025-03-21 00:23:35,285 [INFO] ember.core.registry.model.initialization: Successfully registered model: google:models/gemini-1.5-pro with provider Google\n",
      "2025-03-21 00:23:35,286 [DEBUG] ember.core.registry.model.initialization: Attempting to register discovered model: google:models/gemini-1.5-flash-latest (provider: Google)\n",
      "2025-03-21 00:23:35,287 [INFO] ember.core.registry.model.initialization: Successfully registered model: google:models/gemini-1.5-flash-latest with provider Google\n",
      "2025-03-21 00:23:35,288 [INFO] ember.core.registry.model.initialization: Successfully registered model: google:models/gemini-1.5-flash-latest with provider Google\n",
      "2025-03-21 00:23:35,290 [DEBUG] ember.core.registry.model.initialization: Attempting to register discovered model: google:models/gemini-1.5-flash-001 (provider: Google)\n",
      "2025-03-21 00:23:35,290 [INFO] ember.core.registry.model.initialization: Successfully registered model: google:models/gemini-1.5-flash-001 with provider Google\n",
      "2025-03-21 00:23:35,291 [INFO] ember.core.registry.model.initialization: Successfully registered model: google:models/gemini-1.5-flash-001 with provider Google\n",
      "2025-03-21 00:23:35,292 [DEBUG] ember.core.registry.model.initialization: Attempting to register discovered model: google:models/gemini-1.5-flash-001-tuning (provider: Google)\n",
      "2025-03-21 00:23:35,292 [INFO] ember.core.registry.model.initialization: Successfully registered model: google:models/gemini-1.5-flash-001-tuning with provider Google\n",
      "2025-03-21 00:23:35,293 [INFO] ember.core.registry.model.initialization: Successfully registered model: google:models/gemini-1.5-flash-001-tuning with provider Google\n",
      "2025-03-21 00:23:35,296 [DEBUG] ember.core.registry.model.initialization: Attempting to register discovered model: google:models/gemini-1.5-flash (provider: Google)\n",
      "2025-03-21 00:23:35,305 [INFO] ember.core.registry.model.initialization: Successfully registered model: google:models/gemini-1.5-flash with provider Google\n",
      "2025-03-21 00:23:35,307 [INFO] ember.core.registry.model.initialization: Successfully registered model: google:models/gemini-1.5-flash with provider Google\n",
      "2025-03-21 00:23:35,308 [DEBUG] ember.core.registry.model.initialization: Attempting to register discovered model: google:models/gemini-1.5-flash-002 (provider: Google)\n",
      "2025-03-21 00:23:35,309 [INFO] ember.core.registry.model.initialization: Successfully registered model: google:models/gemini-1.5-flash-002 with provider Google\n",
      "2025-03-21 00:23:35,310 [INFO] ember.core.registry.model.initialization: Successfully registered model: google:models/gemini-1.5-flash-002 with provider Google\n",
      "2025-03-21 00:23:35,312 [DEBUG] ember.core.registry.model.initialization: Attempting to register discovered model: google:models/gemini-1.5-flash-8b (provider: Google)\n",
      "2025-03-21 00:23:35,314 [INFO] ember.core.registry.model.initialization: Successfully registered model: google:models/gemini-1.5-flash-8b with provider Google\n",
      "2025-03-21 00:23:35,315 [INFO] ember.core.registry.model.initialization: Successfully registered model: google:models/gemini-1.5-flash-8b with provider Google\n",
      "2025-03-21 00:23:35,318 [DEBUG] ember.core.registry.model.initialization: Attempting to register discovered model: google:models/gemini-1.5-flash-8b-001 (provider: Google)\n",
      "2025-03-21 00:23:35,319 [INFO] ember.core.registry.model.initialization: Successfully registered model: google:models/gemini-1.5-flash-8b-001 with provider Google\n",
      "2025-03-21 00:23:35,321 [INFO] ember.core.registry.model.initialization: Successfully registered model: google:models/gemini-1.5-flash-8b-001 with provider Google\n",
      "2025-03-21 00:23:35,325 [DEBUG] ember.core.registry.model.initialization: Attempting to register discovered model: google:models/gemini-1.5-flash-8b-latest (provider: Google)\n",
      "2025-03-21 00:23:35,326 [INFO] ember.core.registry.model.initialization: Successfully registered model: google:models/gemini-1.5-flash-8b-latest with provider Google\n",
      "2025-03-21 00:23:35,328 [INFO] ember.core.registry.model.initialization: Successfully registered model: google:models/gemini-1.5-flash-8b-latest with provider Google\n",
      "2025-03-21 00:23:35,330 [DEBUG] ember.core.registry.model.initialization: Attempting to register discovered model: google:models/gemini-1.5-flash-8b-exp-0827 (provider: Google)\n",
      "2025-03-21 00:23:35,332 [INFO] ember.core.registry.model.initialization: Successfully registered model: google:models/gemini-1.5-flash-8b-exp-0827 with provider Google\n",
      "2025-03-21 00:23:35,335 [INFO] ember.core.registry.model.initialization: Successfully registered model: google:models/gemini-1.5-flash-8b-exp-0827 with provider Google\n",
      "2025-03-21 00:23:35,338 [DEBUG] ember.core.registry.model.initialization: Attempting to register discovered model: google:models/gemini-1.5-flash-8b-exp-0924 (provider: Google)\n",
      "2025-03-21 00:23:35,340 [INFO] ember.core.registry.model.initialization: Successfully registered model: google:models/gemini-1.5-flash-8b-exp-0924 with provider Google\n",
      "2025-03-21 00:23:35,341 [INFO] ember.core.registry.model.initialization: Successfully registered model: google:models/gemini-1.5-flash-8b-exp-0924 with provider Google\n",
      "2025-03-21 00:23:35,344 [DEBUG] ember.core.registry.model.initialization: Attempting to register discovered model: google:models/gemini-2.0-flash-exp (provider: Google)\n",
      "2025-03-21 00:23:35,352 [INFO] ember.core.registry.model.initialization: Successfully registered model: google:models/gemini-2.0-flash-exp with provider Google\n",
      "2025-03-21 00:23:35,354 [INFO] ember.core.registry.model.initialization: Successfully registered model: google:models/gemini-2.0-flash-exp with provider Google\n",
      "2025-03-21 00:23:35,357 [DEBUG] ember.core.registry.model.initialization: Attempting to register discovered model: google:models/gemini-2.0-flash (provider: Google)\n",
      "2025-03-21 00:23:35,359 [INFO] ember.core.registry.model.initialization: Successfully registered model: google:models/gemini-2.0-flash with provider Google\n",
      "2025-03-21 00:23:35,362 [INFO] ember.core.registry.model.initialization: Successfully registered model: google:models/gemini-2.0-flash with provider Google\n",
      "2025-03-21 00:23:35,365 [DEBUG] ember.core.registry.model.initialization: Attempting to register discovered model: google:models/gemini-2.0-flash-001 (provider: Google)\n",
      "2025-03-21 00:23:35,369 [INFO] ember.core.registry.model.initialization: Successfully registered model: google:models/gemini-2.0-flash-001 with provider Google\n",
      "2025-03-21 00:23:35,372 [INFO] ember.core.registry.model.initialization: Successfully registered model: google:models/gemini-2.0-flash-001 with provider Google\n",
      "2025-03-21 00:23:35,374 [DEBUG] ember.core.registry.model.initialization: Attempting to register discovered model: google:models/gemini-2.0-flash-exp-image-generation (provider: Google)\n",
      "2025-03-21 00:23:35,376 [INFO] ember.core.registry.model.initialization: Successfully registered model: google:models/gemini-2.0-flash-exp-image-generation with provider Google\n",
      "2025-03-21 00:23:35,378 [INFO] ember.core.registry.model.initialization: Successfully registered model: google:models/gemini-2.0-flash-exp-image-generation with provider Google\n",
      "2025-03-21 00:23:35,380 [DEBUG] ember.core.registry.model.initialization: Attempting to register discovered model: google:models/gemini-2.0-flash-lite-001 (provider: Google)\n",
      "2025-03-21 00:23:35,382 [INFO] ember.core.registry.model.initialization: Successfully registered model: google:models/gemini-2.0-flash-lite-001 with provider Google\n",
      "2025-03-21 00:23:35,384 [INFO] ember.core.registry.model.initialization: Successfully registered model: google:models/gemini-2.0-flash-lite-001 with provider Google\n",
      "2025-03-21 00:23:35,386 [DEBUG] ember.core.registry.model.initialization: Attempting to register discovered model: google:models/gemini-2.0-flash-lite (provider: Google)\n",
      "2025-03-21 00:23:35,388 [INFO] ember.core.registry.model.initialization: Successfully registered model: google:models/gemini-2.0-flash-lite with provider Google\n",
      "2025-03-21 00:23:35,390 [INFO] ember.core.registry.model.initialization: Successfully registered model: google:models/gemini-2.0-flash-lite with provider Google\n",
      "2025-03-21 00:23:35,391 [DEBUG] ember.core.registry.model.initialization: Attempting to register discovered model: google:models/gemini-2.0-flash-lite-preview-02-05 (provider: Google)\n",
      "2025-03-21 00:23:35,393 [INFO] ember.core.registry.model.initialization: Successfully registered model: google:models/gemini-2.0-flash-lite-preview-02-05 with provider Google\n",
      "2025-03-21 00:23:35,399 [INFO] ember.core.registry.model.initialization: Successfully registered model: google:models/gemini-2.0-flash-lite-preview-02-05 with provider Google\n",
      "2025-03-21 00:23:35,405 [DEBUG] ember.core.registry.model.initialization: Attempting to register discovered model: google:models/gemini-2.0-flash-lite-preview (provider: Google)\n",
      "2025-03-21 00:23:35,409 [INFO] ember.core.registry.model.initialization: Successfully registered model: google:models/gemini-2.0-flash-lite-preview with provider Google\n",
      "2025-03-21 00:23:35,411 [INFO] ember.core.registry.model.initialization: Successfully registered model: google:models/gemini-2.0-flash-lite-preview with provider Google\n",
      "2025-03-21 00:23:35,413 [DEBUG] ember.core.registry.model.initialization: Attempting to register discovered model: google:models/gemini-2.0-pro-exp (provider: Google)\n",
      "2025-03-21 00:23:35,418 [INFO] ember.core.registry.model.initialization: Successfully registered model: google:models/gemini-2.0-pro-exp with provider Google\n",
      "2025-03-21 00:23:35,422 [INFO] ember.core.registry.model.initialization: Successfully registered model: google:models/gemini-2.0-pro-exp with provider Google\n",
      "2025-03-21 00:23:35,424 [DEBUG] ember.core.registry.model.initialization: Attempting to register discovered model: google:models/gemini-2.0-pro-exp-02-05 (provider: Google)\n",
      "2025-03-21 00:23:35,427 [INFO] ember.core.registry.model.initialization: Successfully registered model: google:models/gemini-2.0-pro-exp-02-05 with provider Google\n",
      "2025-03-21 00:23:35,431 [INFO] ember.core.registry.model.initialization: Successfully registered model: google:models/gemini-2.0-pro-exp-02-05 with provider Google\n",
      "2025-03-21 00:23:35,434 [DEBUG] ember.core.registry.model.initialization: Attempting to register discovered model: google:models/gemini-exp-1206 (provider: Google)\n",
      "2025-03-21 00:23:35,435 [INFO] ember.core.registry.model.initialization: Successfully registered model: google:models/gemini-exp-1206 with provider Google\n",
      "2025-03-21 00:23:35,437 [INFO] ember.core.registry.model.initialization: Successfully registered model: google:models/gemini-exp-1206 with provider Google\n",
      "2025-03-21 00:23:35,439 [DEBUG] ember.core.registry.model.initialization: Attempting to register discovered model: google:models/gemini-2.0-flash-thinking-exp-01-21 (provider: Google)\n",
      "2025-03-21 00:23:35,440 [INFO] ember.core.registry.model.initialization: Successfully registered model: google:models/gemini-2.0-flash-thinking-exp-01-21 with provider Google\n",
      "2025-03-21 00:23:35,440 [INFO] ember.core.registry.model.initialization: Successfully registered model: google:models/gemini-2.0-flash-thinking-exp-01-21 with provider Google\n",
      "2025-03-21 00:23:35,442 [DEBUG] ember.core.registry.model.initialization: Attempting to register discovered model: google:models/gemini-2.0-flash-thinking-exp (provider: Google)\n",
      "2025-03-21 00:23:35,443 [INFO] ember.core.registry.model.initialization: Successfully registered model: google:models/gemini-2.0-flash-thinking-exp with provider Google\n",
      "2025-03-21 00:23:35,444 [INFO] ember.core.registry.model.initialization: Successfully registered model: google:models/gemini-2.0-flash-thinking-exp with provider Google\n",
      "2025-03-21 00:23:35,445 [DEBUG] ember.core.registry.model.initialization: Attempting to register discovered model: google:models/gemini-2.0-flash-thinking-exp-1219 (provider: Google)\n",
      "2025-03-21 00:23:35,446 [INFO] ember.core.registry.model.initialization: Successfully registered model: google:models/gemini-2.0-flash-thinking-exp-1219 with provider Google\n",
      "2025-03-21 00:23:35,447 [INFO] ember.core.registry.model.initialization: Successfully registered model: google:models/gemini-2.0-flash-thinking-exp-1219 with provider Google\n",
      "2025-03-21 00:23:35,448 [DEBUG] ember.core.registry.model.initialization: Attempting to register discovered model: google:models/learnlm-1.5-pro-experimental (provider: Google)\n",
      "2025-03-21 00:23:35,449 [INFO] ember.core.registry.model.initialization: Successfully registered model: google:models/learnlm-1.5-pro-experimental with provider Google\n",
      "2025-03-21 00:23:35,450 [INFO] ember.core.registry.model.initialization: Successfully registered model: google:models/learnlm-1.5-pro-experimental with provider Google\n",
      "2025-03-21 00:23:35,451 [DEBUG] ember.core.registry.model.initialization: Attempting to register discovered model: google:models/gemma-3-27b-it (provider: Google)\n",
      "2025-03-21 00:23:35,454 [INFO] ember.core.registry.model.initialization: Successfully registered model: google:models/gemma-3-27b-it with provider Google\n",
      "2025-03-21 00:23:35,455 [INFO] ember.core.registry.model.initialization: Successfully registered model: google:models/gemma-3-27b-it with provider Google\n",
      "2025-03-21 00:23:35,456 [INFO] ember.core.registry.model.initialization: Registration summary: 80 new, 0 skipped, 0 failed\n",
      "2025-03-21 00:23:35,457 [INFO] ember.core.registry.model.initialization: Successfully discovered and registered 80 new models: ['openai:gpt-4o-mini-transcribe', 'openai:gpt-4o-audio-preview-2024-12-17', 'openai:dall-e-3', 'openai:dall-e-2', 'openai:gpt-4o-audio-preview-2024-10-01', 'openai:gpt-4o-realtime-preview-2024-10-01', 'openai:gpt-4o-audio-preview', 'openai:text-embedding-3-large', 'openai:gpt-4', 'openai:gpt-4o-2024-05-13', 'openai:gpt-4o-realtime-preview', 'openai:gpt-4o-mini-audio-preview', 'openai:gpt-3.5-turbo-instruct-0914', 'openai:gpt-4o-mini-search-preview', 'openai:gpt-3.5-turbo-1106', 'openai:gpt-4o-search-preview', 'openai:gpt-4-turbo', 'openai:gpt-4o-realtime-preview-2024-12-17', 'openai:gpt-3.5-turbo-instruct', 'openai:gpt-3.5-turbo', 'openai:gpt-4-turbo-preview', 'openai:gpt-4o-mini-search-preview-2025-03-11', 'openai:gpt-4o-mini-realtime-preview', 'openai:gpt-3.5-turbo-0125', 'openai:gpt-4o-2024-08-06', 'openai:gpt-4-turbo-2024-04-09', 'openai:gpt-3.5-turbo-16k', 'openai:gpt-4o', 'openai:gpt-4o-mini-realtime-preview-2024-12-17', 'openai:gpt-4-1106-preview', 'openai:text-embedding-ada-002', 'openai:gpt-4-0613', 'openai:gpt-4.5-preview', 'openai:gpt-4.5-preview-2025-02-27', 'openai:gpt-4o-search-preview-2025-03-11', 'openai:gpt-4o-2024-11-20', 'openai:gpt-4o-mini-2024-07-18', 'openai:gpt-4o-mini-tts', 'openai:gpt-4o-mini', 'openai:gpt-4-0125-preview', 'openai:gpt-4o-transcribe', 'openai:text-embedding-3-small', 'openai:gpt-4o-mini-audio-preview-2024-12-17', 'anthropic:claude-3-sonnet', 'anthropic:claude-3-opus', 'anthropic:claude-3-haiku', 'anthropic:claude-3.5-sonnet', 'anthropic:claude-3.7-sonnet', 'google:models/gemini-1.0-pro-vision-latest', 'google:models/gemini-pro-vision', 'google:models/gemini-1.5-pro-latest', 'google:models/gemini-1.5-pro-001', 'google:models/gemini-1.5-pro-002', 'google:models/gemini-1.5-pro', 'google:models/gemini-1.5-flash-latest', 'google:models/gemini-1.5-flash-001', 'google:models/gemini-1.5-flash-001-tuning', 'google:models/gemini-1.5-flash', 'google:models/gemini-1.5-flash-002', 'google:models/gemini-1.5-flash-8b', 'google:models/gemini-1.5-flash-8b-001', 'google:models/gemini-1.5-flash-8b-latest', 'google:models/gemini-1.5-flash-8b-exp-0827', 'google:models/gemini-1.5-flash-8b-exp-0924', 'google:models/gemini-2.0-flash-exp', 'google:models/gemini-2.0-flash', 'google:models/gemini-2.0-flash-001', 'google:models/gemini-2.0-flash-exp-image-generation', 'google:models/gemini-2.0-flash-lite-001', 'google:models/gemini-2.0-flash-lite', 'google:models/gemini-2.0-flash-lite-preview-02-05', 'google:models/gemini-2.0-flash-lite-preview', 'google:models/gemini-2.0-pro-exp', 'google:models/gemini-2.0-pro-exp-02-05', 'google:models/gemini-exp-1206', 'google:models/gemini-2.0-flash-thinking-exp-01-21', 'google:models/gemini-2.0-flash-thinking-exp', 'google:models/gemini-2.0-flash-thinking-exp-1219', 'google:models/learnlm-1.5-pro-experimental', 'google:models/gemma-3-27b-it']\n",
      "2025-03-21 00:23:35,458 [INFO] ember.core.registry.model.initialization: Discovered 80 new models in 1.53s: ['openai:gpt-4o-mini-transcribe', 'openai:gpt-4o-audio-preview-2024-12-17', 'openai:dall-e-3', 'openai:dall-e-2', 'openai:gpt-4o-audio-preview-2024-10-01', 'openai:gpt-4o-realtime-preview-2024-10-01', 'openai:gpt-4o-audio-preview', 'openai:text-embedding-3-large', 'openai:gpt-4', 'openai:gpt-4o-2024-05-13'] and 70 more\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['openai:gpt-4o-mini-transcribe', 'openai:gpt-4o-audio-preview-2024-12-17', 'openai:dall-e-3', 'openai:dall-e-2', 'openai:gpt-4o-audio-preview-2024-10-01', 'openai:gpt-4o-realtime-preview-2024-10-01', 'openai:gpt-4o-audio-preview', 'openai:text-embedding-3-large', 'openai:gpt-4', 'openai:gpt-4o-2024-05-13', 'openai:gpt-4o-realtime-preview', 'openai:gpt-4o-mini-audio-preview', 'openai:gpt-3.5-turbo-instruct-0914', 'openai:gpt-4o-mini-search-preview', 'openai:gpt-3.5-turbo-1106', 'openai:gpt-4o-search-preview', 'openai:gpt-4-turbo', 'openai:gpt-4o-realtime-preview-2024-12-17', 'openai:gpt-3.5-turbo-instruct', 'openai:gpt-3.5-turbo', 'openai:gpt-4-turbo-preview', 'openai:gpt-4o-mini-search-preview-2025-03-11', 'openai:gpt-4o-mini-realtime-preview', 'openai:gpt-3.5-turbo-0125', 'openai:gpt-4o-2024-08-06', 'openai:gpt-4-turbo-2024-04-09', 'openai:gpt-3.5-turbo-16k', 'openai:gpt-4o', 'openai:gpt-4o-mini-realtime-preview-2024-12-17', 'openai:gpt-4-1106-preview', 'openai:text-embedding-ada-002', 'openai:gpt-4-0613', 'openai:gpt-4.5-preview', 'openai:gpt-4.5-preview-2025-02-27', 'openai:gpt-4o-search-preview-2025-03-11', 'openai:gpt-4o-2024-11-20', 'openai:gpt-4o-mini-2024-07-18', 'openai:gpt-4o-mini-tts', 'openai:gpt-4o-mini', 'openai:gpt-4-0125-preview', 'openai:gpt-4o-transcribe', 'openai:text-embedding-3-small', 'openai:gpt-4o-mini-audio-preview-2024-12-17', 'anthropic:claude-3-sonnet', 'anthropic:claude-3-opus', 'anthropic:claude-3-haiku', 'anthropic:claude-3.5-sonnet', 'anthropic:claude-3.7-sonnet', 'google:models/gemini-1.0-pro-vision-latest', 'google:models/gemini-pro-vision', 'google:models/gemini-1.5-pro-latest', 'google:models/gemini-1.5-pro-001', 'google:models/gemini-1.5-pro-002', 'google:models/gemini-1.5-pro', 'google:models/gemini-1.5-flash-latest', 'google:models/gemini-1.5-flash-001', 'google:models/gemini-1.5-flash-001-tuning', 'google:models/gemini-1.5-flash', 'google:models/gemini-1.5-flash-002', 'google:models/gemini-1.5-flash-8b', 'google:models/gemini-1.5-flash-8b-001', 'google:models/gemini-1.5-flash-8b-latest', 'google:models/gemini-1.5-flash-8b-exp-0827', 'google:models/gemini-1.5-flash-8b-exp-0924', 'google:models/gemini-2.0-flash-exp', 'google:models/gemini-2.0-flash', 'google:models/gemini-2.0-flash-001', 'google:models/gemini-2.0-flash-exp-image-generation', 'google:models/gemini-2.0-flash-lite-001', 'google:models/gemini-2.0-flash-lite', 'google:models/gemini-2.0-flash-lite-preview-02-05', 'google:models/gemini-2.0-flash-lite-preview', 'google:models/gemini-2.0-pro-exp', 'google:models/gemini-2.0-pro-exp-02-05', 'google:models/gemini-exp-1206', 'google:models/gemini-2.0-flash-thinking-exp-01-21', 'google:models/gemini-2.0-flash-thinking-exp', 'google:models/gemini-2.0-flash-thinking-exp-1219', 'google:models/learnlm-1.5-pro-experimental', 'google:models/gemma-3-27b-it']\n"
>>>>>>> feb7b31 (added embedding model)
     ]
    }
   ],
   "source": [
    "model_registry = initialize_ember()\n",
    "print(model_registry.list_models())\n",
    "llm = ModelService(registry=model_registry)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
=======
   "execution_count": 8,
   "metadata": {},
>>>>>>> feb7b31 (added embedding model)
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['openai:gpt-4o-mini-transcribe',\n",
       " 'openai:gpt-4o-audio-preview-2024-12-17',\n",
       " 'openai:dall-e-3',\n",
       " 'openai:dall-e-2',\n",
       " 'openai:gpt-4o-audio-preview-2024-10-01',\n",
       " 'openai:gpt-4o-realtime-preview-2024-10-01',\n",
       " 'openai:gpt-4o-audio-preview',\n",
       " 'openai:text-embedding-3-large',\n",
       " 'openai:gpt-4',\n",
       " 'openai:gpt-4o-2024-05-13',\n",
       " 'openai:gpt-4o-realtime-preview',\n",
       " 'openai:gpt-4o-mini-audio-preview',\n",
       " 'openai:gpt-3.5-turbo-instruct-0914',\n",
       " 'openai:gpt-4o-mini-search-preview',\n",
       " 'openai:gpt-3.5-turbo-1106',\n",
       " 'openai:gpt-4o-search-preview',\n",
       " 'openai:gpt-4-turbo',\n",
       " 'openai:gpt-4o-realtime-preview-2024-12-17',\n",
       " 'openai:gpt-3.5-turbo-instruct',\n",
       " 'openai:gpt-3.5-turbo',\n",
       " 'openai:gpt-4-turbo-preview',\n",
       " 'openai:gpt-4o-mini-search-preview-2025-03-11',\n",
       " 'openai:gpt-4o-mini-realtime-preview',\n",
       " 'openai:gpt-3.5-turbo-0125',\n",
       " 'openai:gpt-4o-2024-08-06',\n",
       " 'openai:gpt-4-turbo-2024-04-09',\n",
       " 'openai:gpt-3.5-turbo-16k',\n",
       " 'openai:gpt-4o',\n",
       " 'openai:gpt-4o-mini-realtime-preview-2024-12-17',\n",
       " 'openai:gpt-4-1106-preview',\n",
       " 'openai:text-embedding-ada-002',\n",
       " 'openai:gpt-4-0613',\n",
       " 'openai:gpt-4.5-preview',\n",
       " 'openai:gpt-4.5-preview-2025-02-27',\n",
       " 'openai:gpt-4o-search-preview-2025-03-11',\n",
       " 'openai:gpt-4o-2024-11-20',\n",
       " 'openai:gpt-4o-mini-2024-07-18',\n",
       " 'openai:gpt-4o-mini-tts',\n",
       " 'openai:gpt-4o-mini',\n",
       " 'openai:gpt-4-0125-preview',\n",
       " 'openai:gpt-4o-transcribe',\n",
       " 'openai:text-embedding-3-small',\n",
       " 'openai:gpt-4o-mini-audio-preview-2024-12-17',\n",
       " 'anthropic:claude-3-sonnet',\n",
       " 'anthropic:claude-3-opus',\n",
       " 'anthropic:claude-3-haiku',\n",
       " 'anthropic:claude-3.5-sonnet',\n",
       " 'anthropic:claude-3.7-sonnet',\n",
       " 'google:models/gemini-1.0-pro-vision-latest',\n",
       " 'google:models/gemini-pro-vision',\n",
       " 'google:models/gemini-1.5-pro-latest',\n",
       " 'google:models/gemini-1.5-pro-001',\n",
       " 'google:models/gemini-1.5-pro-002',\n",
       " 'google:models/gemini-1.5-pro',\n",
       " 'google:models/gemini-1.5-flash-latest',\n",
       " 'google:models/gemini-1.5-flash-001',\n",
       " 'google:models/gemini-1.5-flash-001-tuning',\n",
       " 'google:models/gemini-1.5-flash',\n",
       " 'google:models/gemini-1.5-flash-002',\n",
       " 'google:models/gemini-1.5-flash-8b',\n",
       " 'google:models/gemini-1.5-flash-8b-001',\n",
       " 'google:models/gemini-1.5-flash-8b-latest',\n",
       " 'google:models/gemini-1.5-flash-8b-exp-0827',\n",
       " 'google:models/gemini-1.5-flash-8b-exp-0924',\n",
       " 'google:models/gemini-2.0-flash-exp',\n",
       " 'google:models/gemini-2.0-flash',\n",
       " 'google:models/gemini-2.0-flash-001',\n",
       " 'google:models/gemini-2.0-flash-exp-image-generation',\n",
       " 'google:models/gemini-2.0-flash-lite-001',\n",
       " 'google:models/gemini-2.0-flash-lite',\n",
       " 'google:models/gemini-2.0-flash-lite-preview-02-05',\n",
       " 'google:models/gemini-2.0-flash-lite-preview',\n",
       " 'google:models/gemini-2.0-pro-exp',\n",
       " 'google:models/gemini-2.0-pro-exp-02-05',\n",
       " 'google:models/gemini-exp-1206',\n",
       " 'google:models/gemini-2.0-flash-thinking-exp-01-21',\n",
       " 'google:models/gemini-2.0-flash-thinking-exp',\n",
       " 'google:models/gemini-2.0-flash-thinking-exp-1219',\n",
       " 'google:models/learnlm-1.5-pro-experimental',\n",
       " 'google:models/gemma-3-27b-it']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_registry.list_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ids: List[str] = [\n",
    "            \"openai:o1\",\n",
    "            \"openai:gpt-4o\",\n",
    "            \"openai:gpt-4o-mini\",\n",
    "            # \"anthropic:claude-3.5-sonnet\", # API key not working\n",
    "            # \"invalid:model\",  # Expected to trigger an error.\n",
    "            # \"google:model/gemini-1.5-pro\", # need to fix model alignment\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-21 00:18:22,993 [WARNING] ember.core.registry.model.base.registry.factory: Provider name case mismatch: 'Openai' vs 'OpenAI'. Using the registered provider.\n",
      "2025-03-21 00:18:22,994 [DEBUG] ember.core.registry.model.base.registry.factory: Creating model 'openai:gpt-4o' using provider class 'OpenAIModel'.\n",
      "2025-03-21 00:18:22,995 [INFO] ember.core.registry.model.initialization: Instantiated model: openai:gpt-4o\n",
      "2025-03-21 00:18:22,997 [INFO] ember.core.registry.model.providers.openai.openai_provider: OpenAI forward invoked\n",
      "2025-03-21 00:18:23,001 [DEBUG] httpx: load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "2025-03-21 00:18:23,005 [DEBUG] httpx: load_verify_locations cafile='/root/anaconda3/envs/ember_upgrade/lib/python3.11/site-packages/certifi/cacert.pem'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-21 00:18:23,032 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'timeout': 30, 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'Explain quantum computing in 50 words'}], 'model': 'gpt-4o', 'max_completion_tokens': 512, 'temperature': None}}\n",
      "2025-03-21 00:18:23,033 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "2025-03-21 00:18:23,035 [DEBUG] httpcore.connection: connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=30 socket_options=None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Testing model: openai:o1\n",
      " Error with model openai:o1: Model 'openai:o1' not found. Available models:\n",
      "- openai:gpt-4o-mini-transcribe\n",
      "- openai:gpt-4o-audio-preview-2024-12-17\n",
      "- openai:dall-e-3\n",
      "- openai:dall-e-2\n",
      "- openai:gpt-4o-audio-preview-2024-10-01\n",
      "- openai:gpt-4o-realtime-preview-2024-10-01\n",
      "- openai:gpt-4o-audio-preview\n",
      "- openai:text-embedding-3-large\n",
      "- openai:gpt-4\n",
      "- openai:gpt-4o-2024-05-13\n",
      "- openai:gpt-4o-realtime-preview\n",
      "- openai:gpt-4o-mini-audio-preview\n",
      "- openai:gpt-3.5-turbo-instruct-0914\n",
      "- openai:gpt-4o-mini-search-preview\n",
      "- openai:gpt-3.5-turbo-1106\n",
      "- openai:gpt-4o-search-preview\n",
      "- openai:gpt-4-turbo\n",
      "- openai:gpt-4o-realtime-preview-2024-12-17\n",
      "- openai:gpt-3.5-turbo-instruct\n",
      "- openai:gpt-3.5-turbo\n",
      "- openai:gpt-4-turbo-preview\n",
      "- openai:gpt-4o-mini-search-preview-2025-03-11\n",
      "- openai:gpt-4o-mini-realtime-preview\n",
      "- openai:gpt-3.5-turbo-0125\n",
      "- openai:gpt-4o-2024-08-06\n",
      "- openai:gpt-4-turbo-2024-04-09\n",
      "- openai:gpt-3.5-turbo-16k\n",
      "- openai:gpt-4o\n",
      "- openai:gpt-4o-mini-realtime-preview-2024-12-17\n",
      "- openai:gpt-4-1106-preview\n",
      "- openai:text-embedding-ada-002\n",
      "- openai:gpt-4-0613\n",
      "- openai:gpt-4.5-preview\n",
      "- openai:gpt-4.5-preview-2025-02-27\n",
      "- openai:gpt-4o-search-preview-2025-03-11\n",
      "- openai:gpt-4o-2024-11-20\n",
      "- openai:gpt-4o-mini-2024-07-18\n",
      "- openai:gpt-4o-mini-tts\n",
      "- openai:gpt-4o-mini\n",
      "- openai:gpt-4-0125-preview\n",
      "- openai:gpt-4o-transcribe\n",
      "- openai:text-embedding-3-small\n",
      "- openai:gpt-4o-mini-audio-preview-2024-12-17\n",
      "- anthropic:claude-3-sonnet\n",
      "- anthropic:claude-3-opus\n",
      "- anthropic:claude-3-haiku\n",
      "- anthropic:claude-3.5-sonnet\n",
      "- anthropic:claude-3.7-sonnet\n",
      "- google:models/gemini-1.0-pro-vision-latest\n",
      "- google:models/gemini-pro-vision\n",
      "- google:models/gemini-1.5-pro-latest\n",
      "- google:models/gemini-1.5-pro-001\n",
      "- google:models/gemini-1.5-pro-002\n",
      "- google:models/gemini-1.5-pro\n",
      "- google:models/gemini-1.5-flash-latest\n",
      "- google:models/gemini-1.5-flash-001\n",
      "- google:models/gemini-1.5-flash-001-tuning\n",
      "- google:models/gemini-1.5-flash\n",
      "- google:models/gemini-1.5-flash-002\n",
      "- google:models/gemini-1.5-flash-8b\n",
      "- google:models/gemini-1.5-flash-8b-001\n",
      "- google:models/gemini-1.5-flash-8b-latest\n",
      "- google:models/gemini-1.5-flash-8b-exp-0827\n",
      "- google:models/gemini-1.5-flash-8b-exp-0924\n",
      "- google:models/gemini-2.0-flash-exp\n",
      "- google:models/gemini-2.0-flash\n",
      "- google:models/gemini-2.0-flash-001\n",
      "- google:models/gemini-2.0-flash-exp-image-generation\n",
      "- google:models/gemini-2.0-flash-lite-001\n",
      "- google:models/gemini-2.0-flash-lite\n",
      "- google:models/gemini-2.0-flash-lite-preview-02-05\n",
      "- google:models/gemini-2.0-flash-lite-preview\n",
      "- google:models/gemini-2.0-pro-exp\n",
      "- google:models/gemini-2.0-pro-exp-02-05\n",
      "- google:models/gemini-exp-1206\n",
      "- google:models/gemini-2.0-flash-thinking-exp-01-21\n",
      "- google:models/gemini-2.0-flash-thinking-exp\n",
      "- google:models/gemini-2.0-flash-thinking-exp-1219\n",
      "- google:models/learnlm-1.5-pro-experimental\n",
      "- google:models/gemma-3-27b-it\n",
      " Testing model: openai:gpt-4o\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-21 00:18:23,052 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f16ab6f7c50>\n",
      "2025-03-21 00:18:23,053 [DEBUG] httpcore.connection: start_tls.started ssl_context=<ssl.SSLContext object at 0x7f16a96ed910> server_hostname='api.openai.com' timeout=30\n",
      "2025-03-21 00:18:23,068 [DEBUG] httpcore.connection: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f16ab0c1f10>\n",
      "2025-03-21 00:18:23,069 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>\n",
      "2025-03-21 00:18:23,071 [DEBUG] httpcore.http11: send_request_headers.complete\n",
      "2025-03-21 00:18:23,072 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>\n",
      "2025-03-21 00:18:23,075 [DEBUG] httpcore.http11: send_request_body.complete\n",
      "2025-03-21 00:18:23,078 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>\n",
      "2025-03-21 00:18:24,532 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 21 Mar 2025 07:18:24 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-iqhmndueuqg2ljzblqkr2tgh'), (b'openai-processing-ms', b'1350'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'50000'), (b'x-ratelimit-limit-tokens', b'150000000'), (b'x-ratelimit-remaining-requests', b'49999'), (b'x-ratelimit-remaining-tokens', b'149999987'), (b'x-ratelimit-reset-requests', b'1ms'), (b'x-ratelimit-reset-tokens', b'0s'), (b'x-request-id', b'req_4484c1b7b2d43adb83ccc149b107da95'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=6lh2Yp5h0FaYvXxpQQAxO9Jt6HDCdmUeuY4.kM2i6ps-1742541504-1.0.1.1-_IHIr..1OAWdoybv_Qs3tz4oLMWDWudghLRy7.RfguO5RHXiKnjZ_j3p3t6MOuUfyuRPgEE7hksYaVr_aZjLjYeXWFZh8PG6vgZ3yCPlnOk; path=/; expires=Fri, 21-Mar-25 07:48:24 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=DanRUEufXKZ7K8DxP_7kPrhHNdJOhS0UH.jyo2WiVto-1742541504892-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'923baccc7a771566-SJC'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2025-03-21 00:18:24,535 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-21 00:18:24,536 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>\n",
      "2025-03-21 00:18:24,594 [DEBUG] httpcore.http11: receive_response_body.complete\n",
      "2025-03-21 00:18:24,596 [DEBUG] httpcore.http11: response_closed.started\n",
      "2025-03-21 00:18:24,598 [DEBUG] httpcore.http11: response_closed.complete\n",
      "2025-03-21 00:18:24,601 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers([('date', 'Fri, 21 Mar 2025 07:18:24 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-iqhmndueuqg2ljzblqkr2tgh'), ('openai-processing-ms', '1350'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '50000'), ('x-ratelimit-limit-tokens', '150000000'), ('x-ratelimit-remaining-requests', '49999'), ('x-ratelimit-remaining-tokens', '149999987'), ('x-ratelimit-reset-requests', '1ms'), ('x-ratelimit-reset-tokens', '0s'), ('x-request-id', 'req_4484c1b7b2d43adb83ccc149b107da95'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=6lh2Yp5h0FaYvXxpQQAxO9Jt6HDCdmUeuY4.kM2i6ps-1742541504-1.0.1.1-_IHIr..1OAWdoybv_Qs3tz4oLMWDWudghLRy7.RfguO5RHXiKnjZ_j3p3t6MOuUfyuRPgEE7hksYaVr_aZjLjYeXWFZh8PG6vgZ3yCPlnOk; path=/; expires=Fri, 21-Mar-25 07:48:24 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=DanRUEufXKZ7K8DxP_7kPrhHNdJOhS0UH.jyo2WiVto-1742541504892-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '923baccc7a771566-SJC'), ('content-encoding', 'br'), ('alt-svc', 'h3=\":443\"; ma=86400')])\n",
      "2025-03-21 00:18:24,604 [DEBUG] openai._base_client: request_id: req_4484c1b7b2d43adb83ccc149b107da95\n",
      "2025-03-21 00:18:24,615 [INFO] ember.core.registry.model.providers.openai.openai_provider: OpenAI forward invoked\n",
      "2025-03-21 00:18:24,624 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'timeout': 30, 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': \"What's the capital of France?\"}], 'model': 'gpt-4o', 'max_completion_tokens': 512, 'temperature': None}}\n",
      "2025-03-21 00:18:24,631 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "2025-03-21 00:18:24,637 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>\n",
      "2025-03-21 00:18:24,641 [DEBUG] httpcore.http11: send_request_headers.complete\n",
      "2025-03-21 00:18:24,646 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>\n",
      "2025-03-21 00:18:24,654 [DEBUG] httpcore.http11: send_request_body.complete\n",
      "2025-03-21 00:18:24,660 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Service response from openai:gpt-4o:\n",
      "Quantum computing leverages quantum mechanics principles, using qubits that exist in multiple states simultaneously. This allows for immense parallel processing power, enabling computations beyond classical computers' capabilities. Entanglement and superposition enhance efficiency, promising breakthroughs in cryptography, optimization, and complex problem-solving. It's transformative, yet still largely experimental.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-21 00:18:24,922 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 21 Mar 2025 07:18:25 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-iqhmndueuqg2ljzblqkr2tgh'), (b'openai-processing-ms', b'227'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'50000'), (b'x-ratelimit-limit-tokens', b'150000000'), (b'x-ratelimit-remaining-requests', b'49999'), (b'x-ratelimit-remaining-tokens', b'149999989'), (b'x-ratelimit-reset-requests', b'1ms'), (b'x-ratelimit-reset-tokens', b'0s'), (b'x-request-id', b'req_a4d75e258ae593c95536f95bfb4b46d8'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'923bacd65ade1566-SJC'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2025-03-21 00:18:24,924 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-21 00:18:24,925 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>\n",
      "2025-03-21 00:18:24,927 [DEBUG] httpcore.http11: receive_response_body.complete\n",
      "2025-03-21 00:18:24,928 [DEBUG] httpcore.http11: response_closed.started\n",
      "2025-03-21 00:18:24,929 [DEBUG] httpcore.http11: response_closed.complete\n",
      "2025-03-21 00:18:24,930 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Fri, 21 Mar 2025 07:18:25 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-iqhmndueuqg2ljzblqkr2tgh', 'openai-processing-ms': '227', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '50000', 'x-ratelimit-limit-tokens': '150000000', 'x-ratelimit-remaining-requests': '49999', 'x-ratelimit-remaining-tokens': '149999989', 'x-ratelimit-reset-requests': '1ms', 'x-ratelimit-reset-tokens': '0s', 'x-request-id': 'req_a4d75e258ae593c95536f95bfb4b46d8', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '923bacd65ade1566-SJC', 'content-encoding': 'br', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "2025-03-21 00:18:24,931 [DEBUG] openai._base_client: request_id: req_a4d75e258ae593c95536f95bfb4b46d8\n",
      "2025-03-21 00:18:24,932 [WARNING] ember.core.registry.model.base.registry.factory: Provider name case mismatch: 'Openai' vs 'OpenAI'. Using the registered provider.\n",
      "2025-03-21 00:18:24,933 [DEBUG] ember.core.registry.model.base.registry.factory: Creating model 'openai:gpt-4o-mini' using provider class 'OpenAIModel'.\n",
      "2025-03-21 00:18:24,933 [INFO] ember.core.registry.model.initialization: Instantiated model: openai:gpt-4o-mini\n",
      "2025-03-21 00:18:24,934 [INFO] ember.core.registry.model.providers.openai.openai_provider: OpenAI forward invoked\n",
      "2025-03-21 00:18:24,938 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'timeout': 30, 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'Explain quantum computing in 50 words'}], 'model': 'gpt-4o-mini', 'max_completion_tokens': 512, 'temperature': None}}\n",
      "2025-03-21 00:18:24,939 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "2025-03-21 00:18:24,940 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>\n",
      "2025-03-21 00:18:24,941 [DEBUG] httpcore.http11: send_request_headers.complete\n",
      "2025-03-21 00:18:24,943 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>\n",
      "2025-03-21 00:18:24,944 [DEBUG] httpcore.http11: send_request_body.complete\n",
      "2025-03-21 00:18:24,945 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Direct response from openai:gpt-4o:\n",
      "The capital of France is Paris.\n",
      "\n",
      " Testing model: openai:gpt-4o-mini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-21 00:18:26,197 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 21 Mar 2025 07:18:26 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-iqhmndueuqg2ljzblqkr2tgh'), (b'openai-processing-ms', b'1201'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'30000'), (b'x-ratelimit-limit-tokens', b'150000000'), (b'x-ratelimit-remaining-requests', b'29999'), (b'x-ratelimit-remaining-tokens', b'149999988'), (b'x-ratelimit-reset-requests', b'2ms'), (b'x-ratelimit-reset-tokens', b'0s'), (b'x-request-id', b'req_5e2501f946b9db85f3fe2255e49f7894'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'923bacd83c6f1566-SJC'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2025-03-21 00:18:26,201 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-21 00:18:26,204 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>\n",
      "2025-03-21 00:18:26,210 [DEBUG] httpcore.http11: receive_response_body.complete\n",
      "2025-03-21 00:18:26,213 [DEBUG] httpcore.http11: response_closed.started\n",
      "2025-03-21 00:18:26,215 [DEBUG] httpcore.http11: response_closed.complete\n",
      "2025-03-21 00:18:26,218 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Fri, 21 Mar 2025 07:18:26 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-iqhmndueuqg2ljzblqkr2tgh', 'openai-processing-ms': '1201', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '30000', 'x-ratelimit-limit-tokens': '150000000', 'x-ratelimit-remaining-requests': '29999', 'x-ratelimit-remaining-tokens': '149999988', 'x-ratelimit-reset-requests': '2ms', 'x-ratelimit-reset-tokens': '0s', 'x-request-id': 'req_5e2501f946b9db85f3fe2255e49f7894', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '923bacd83c6f1566-SJC', 'content-encoding': 'br', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "2025-03-21 00:18:26,221 [DEBUG] openai._base_client: request_id: req_5e2501f946b9db85f3fe2255e49f7894\n",
      "2025-03-21 00:18:26,225 [INFO] ember.core.registry.model.providers.openai.openai_provider: OpenAI forward invoked\n",
      "2025-03-21 00:18:26,235 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'timeout': 30, 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': \"What's the capital of France?\"}], 'model': 'gpt-4o-mini', 'max_completion_tokens': 512, 'temperature': None}}\n",
      "2025-03-21 00:18:26,238 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "2025-03-21 00:18:26,240 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>\n",
      "2025-03-21 00:18:26,245 [DEBUG] httpcore.http11: send_request_headers.complete\n",
      "2025-03-21 00:18:26,247 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>\n",
      "2025-03-21 00:18:26,251 [DEBUG] httpcore.http11: send_request_body.complete\n",
      "2025-03-21 00:18:26,253 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Service response from openai:gpt-4o-mini:\n",
      "Quantum computing harnesses the principles of quantum mechanics to process information. Unlike classical bits, quantum bits (qubits) can exist in multiple states simultaneously, enabling parallel computations. This potential for massive parallelism allows quantum computers to solve complex problems, such as optimization and cryptography, much faster than traditional computers can.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-21 00:18:26,743 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 21 Mar 2025 07:18:27 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-iqhmndueuqg2ljzblqkr2tgh'), (b'openai-processing-ms', b'450'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'30000'), (b'x-ratelimit-limit-tokens', b'150000000'), (b'x-ratelimit-remaining-requests', b'29999'), (b'x-ratelimit-remaining-tokens', b'149999990'), (b'x-ratelimit-reset-requests', b'2ms'), (b'x-ratelimit-reset-tokens', b'0s'), (b'x-request-id', b'req_7c748282fa721b7ab5121245acddd69d'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'923bace05afe1566-SJC'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2025-03-21 00:18:26,745 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-21 00:18:26,746 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>\n",
      "2025-03-21 00:18:26,752 [DEBUG] httpcore.http11: receive_response_body.complete\n",
      "2025-03-21 00:18:26,753 [DEBUG] httpcore.http11: response_closed.started\n",
      "2025-03-21 00:18:26,755 [DEBUG] httpcore.http11: response_closed.complete\n",
      "2025-03-21 00:18:26,756 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Fri, 21 Mar 2025 07:18:27 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-iqhmndueuqg2ljzblqkr2tgh', 'openai-processing-ms': '450', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '30000', 'x-ratelimit-limit-tokens': '150000000', 'x-ratelimit-remaining-requests': '29999', 'x-ratelimit-remaining-tokens': '149999990', 'x-ratelimit-reset-requests': '2ms', 'x-ratelimit-reset-tokens': '0s', 'x-request-id': 'req_7c748282fa721b7ab5121245acddd69d', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '923bace05afe1566-SJC', 'content-encoding': 'br', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "2025-03-21 00:18:26,757 [DEBUG] openai._base_client: request_id: req_7c748282fa721b7ab5121245acddd69d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Direct response from openai:gpt-4o-mini:\n",
      "The capital of France is Paris.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model_id in model_ids:\n",
    "    try:\n",
    "        print(f\" Testing model: {model_id}\")\n",
    "\n",
    "        # Two usage styles are demonstrated below:\n",
    "        # 1. Service-based invocation: Recommended for automatic usage tracking.\n",
    "        service_response: ChatResponse = llm.invoke_model(\n",
    "            model_id=model_id,\n",
    "            prompt=\"Explain quantum computing in 50 words\",\n",
    "        )\n",
    "        print(f\" Service response from {model_id}:\\n{service_response.data}\\n\")\n",
    "\n",
    "        # 2. Direct model instance usage: Useful for more granular or PyTorch-like workflows.\n",
    "        model = load_model(model_id=model_id, registry=model_registry)\n",
    "        direct_response: ChatResponse = model(\n",
    "            prompt=\"What's the capital of France?\"\n",
    "        )\n",
    "        print(f\" Direct response from {model_id}:\\n{direct_response.data}\\n\")\n",
    "\n",
    "    except Exception as error:\n",
    "        print(f\" Error with model {model_id}: {str(error)}\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register an OpenAI GPT-4o model\n",
    "# openai_info = ModelInfo(\n",
    "#     model_id=\"openai:gpt-4o\",\n",
    "#     model_name=\"gpt-4o\",\n",
    "#     cost=ModelCost(input_cost_per_thousand=0.03, output_cost_per_thousand=0.06),\n",
    "#     rate_limit=RateLimit(tokens_per_minute=80000, requests_per_minute=5000),\n",
    "#     provider=ProviderInfo(name=\"OpenAI\", default_api_key=openai_key),\n",
    "#     api_key=openai_key,\n",
    "# )\n",
    "# model_registry.register_model(openai_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-21 00:19:41,794 [INFO] ember.core.registry.model.providers.openai.openai_provider: OpenAI forward invoked\n",
      "2025-03-21 00:19:41,802 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'timeout': 30, 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'Hello!'}], 'model': 'gpt-4o', 'max_completion_tokens': 512, 'temperature': None}}\n",
      "2025-03-21 00:19:41,807 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "2025-03-21 00:19:41,811 [DEBUG] httpcore.connection: close.started\n",
      "2025-03-21 00:19:41,813 [DEBUG] httpcore.connection: close.complete\n",
      "2025-03-21 00:19:41,815 [DEBUG] httpcore.connection: connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=30 socket_options=None\n",
      "2025-03-21 00:19:41,885 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f17561c00d0>\n",
      "2025-03-21 00:19:41,886 [DEBUG] httpcore.connection: start_tls.started ssl_context=<ssl.SSLContext object at 0x7f16a96ed910> server_hostname='api.openai.com' timeout=30\n",
      "2025-03-21 00:19:41,902 [DEBUG] httpcore.connection: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f16a8fe8510>\n",
      "2025-03-21 00:19:41,904 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>\n",
      "2025-03-21 00:19:41,906 [DEBUG] httpcore.http11: send_request_headers.complete\n",
      "2025-03-21 00:19:41,907 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>\n",
      "2025-03-21 00:19:41,909 [DEBUG] httpcore.http11: send_request_body.complete\n",
      "2025-03-21 00:19:41,910 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>\n",
      "2025-03-21 00:19:42,443 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 21 Mar 2025 07:19:42 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-iqhmndueuqg2ljzblqkr2tgh'), (b'openai-processing-ms', b'452'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'50000'), (b'x-ratelimit-limit-tokens', b'150000000'), (b'x-ratelimit-remaining-requests', b'49999'), (b'x-ratelimit-remaining-tokens', b'149999996'), (b'x-ratelimit-reset-requests', b'1ms'), (b'x-ratelimit-reset-tokens', b'0s'), (b'x-request-id', b'req_43be483befeb53bf9ac56f8f100d5aae'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'923baeb93b086459-SJC'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2025-03-21 00:19:42,444 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-21 00:19:42,445 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>\n",
      "2025-03-21 00:19:42,448 [DEBUG] httpcore.http11: receive_response_body.complete\n",
      "2025-03-21 00:19:42,448 [DEBUG] httpcore.http11: response_closed.started\n",
      "2025-03-21 00:19:42,449 [DEBUG] httpcore.http11: response_closed.complete\n",
      "2025-03-21 00:19:42,451 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Fri, 21 Mar 2025 07:19:42 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-iqhmndueuqg2ljzblqkr2tgh', 'openai-processing-ms': '452', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '50000', 'x-ratelimit-limit-tokens': '150000000', 'x-ratelimit-remaining-requests': '49999', 'x-ratelimit-remaining-tokens': '149999996', 'x-ratelimit-reset-requests': '1ms', 'x-ratelimit-reset-tokens': '0s', 'x-request-id': 'req_43be483befeb53bf9ac56f8f100d5aae', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '923baeb93b086459-SJC', 'content-encoding': 'br', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "2025-03-21 00:19:42,451 [DEBUG] openai._base_client: request_id: req_43be483befeb53bf9ac56f8f100d5aae\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "response = llm(prompt=\"Hello!\", model_id=\"openai:gpt-4o\")\n",
    "print(response.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "## Neural Similarity Scoring - Cosine Similarity (WIP)\n",
    "\n",
    "- from `src/ember/core/utils/embedding_utils.py`\n",
    "- from jason\n",
    "- need to merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q openai"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 7,
=======
   "execution_count": 50,
>>>>>>> feb7b31 (added embedding model)
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from abc import ABC, abstractmethod\n",
    "from typing import List, Protocol\n",
    "import math\n",
    "\n",
    "import openai\n",
    "import os\n",
    "\n",
    "\n",
    "################################################################\n",
    "# 1) Embedding Model Interfaces & Implementations\n",
    "################################################################\n",
    "\n",
    "\n",
    "class EmbeddingModel(Protocol):\n",
    "    \"\"\"Interface for embedding models.\n",
    "\n",
    "    This protocol defines the minimal interface required to compute a text\n",
    "    embedding. Implementations may use local models, external APIs, or custom\n",
    "    neural networks.\n",
    "\n",
    "    Methods:\n",
    "        embed_text: Compute the embedding for a given text.\n",
    "    \"\"\"\n",
    "\n",
    "    def embed_text(self, text: str) -> List[float]:\n",
    "        \"\"\"Computes the embedding vector for the provided text.\n",
    "\n",
    "        Args:\n",
    "            text (str): The text to be embedded.\n",
    "\n",
    "        Returns:\n",
    "            List[float]: A list of floats representing the embedding vector.\n",
    "        \"\"\"\n",
    "        ...\n",
    "\n",
    "class Text_Embedding_3_EmbeddingModel(EmbeddingModel):\n",
    "    \"\"\"Interface for embedding models.\n",
    "\n",
    "    This protocol defines the minimal interface required to compute a text\n",
    "    embedding. Implementations may use local models, external APIs, or custom\n",
    "    neural networks.\n",
    "\n",
    "    Methods:\n",
    "        embed_text: Compute the embedding for a given text.\n",
    "    \"\"\"\n",
    "\n",
    "    def embed_text(self, text: str) -> List[float]:\n",
    "        \"\"\"Computes the embedding vector for the provided text.\n",
    "\n",
    "        Args:\n",
    "            text (str): The text to be embedded.\n",
    "\n",
    "        Returns:\n",
    "            List[float]: A list of floats representing the embedding vector.\n",
    "        \"\"\"\n",
    "        response = llm(model_id=\"openai:text-embedding-3-small\", prompt=text)\n",
    "\n",
    "        # response = openai.Embedding.create(\n",
    "        #     model=\"text-embedding-3\",\n",
    "        #     input=text\n",
    "        # )\n",
    "        return response.data\n",
    "\n",
    "\n",
    "class MockEmbeddingModel:\n",
    "    \"\"\"Mock implementation of an embedding model using naive ASCII encoding.\n",
    "\n",
    "    This simple model converts each character in the text to a normalized ASCII\n",
    "    value. It is intended solely for demonstration and testing purposes.\n",
    "\n",
    "    Methods:\n",
    "        embed_text: Converts text to a sequence of normalized ASCII values.\n",
    "    \"\"\"\n",
    "\n",
    "    def embed_text(self, text: str) -> List[float]:\n",
    "        \"\"\"Embeds text by converting each character to its normalized ASCII code.\n",
    "\n",
    "        Args:\n",
    "            text (str): The input text to be embedded.\n",
    "\n",
    "        Returns:\n",
    "            List[float]: A list of floats representing the embedding. Returns an\n",
    "            empty list if the text is empty.\n",
    "        \"\"\"\n",
    "        if not text:\n",
    "            return []\n",
    "        return [ord(ch) / 256.0 for ch in text]\n",
    "\n",
    "\n",
    "################################################################\n",
    "# 2) Similarity Metric Interface & Implementations\n",
    "################################################################\n",
    "\n",
    "\n",
    "class SimilarityMetric(ABC):\n",
    "    \"\"\"Abstract base class for computing similarity between embedding vectors.\n",
    "\n",
    "    Subclasses must implement the similarity method to calculate a similarity\n",
    "    score between two vectors.\n",
    "    \"\"\"\n",
    "\n",
    "    @abstractmethod\n",
    "    def similarity(self, vec_a: List[float], vec_b: List[float]) -> float:\n",
    "        \"\"\"Calculates the similarity between two embedding vectors.\n",
    "\n",
    "        Args:\n",
    "            vec_a (List[float]): The first embedding vector.\n",
    "            vec_b (List[float]): The second embedding vector.\n",
    "\n",
    "        Returns:\n",
    "            float: The similarity score, typically in the range [0, 1] or [-1, 1].\n",
    "        \"\"\"\n",
    "        ...\n",
    "\n",
    "\n",
    "class CosineSimilarity(SimilarityMetric):\n",
    "    \"\"\"Implementation of cosine similarity for embedding vectors.\n",
    "\n",
    "    The cosine similarity is defined as:\n",
    "        similarity(a, b) = (a  b) / (||a|| * ||b||)\n",
    "\n",
    "    Returns 0.0 if either vector is empty or if any vector's norm is zero.\n",
    "    \"\"\"\n",
    "\n",
    "    def similarity(self, vec_a: List[float], vec_b: List[float]) -> float:\n",
    "        \"\"\"Computes cosine similarity between two embedding vectors.\n",
    "\n",
    "        Args:\n",
    "            vec_a (List[float]): The first embedding vector.\n",
    "            vec_b (List[float]): The second embedding vector.\n",
    "\n",
    "        Returns:\n",
    "            float: The cosine similarity score.\n",
    "        \"\"\"\n",
    "        if not vec_a or not vec_b:\n",
    "            return 0.0\n",
    "\n",
    "        dot_product: float = sum(a * b for a, b in zip(vec_a, vec_b))\n",
    "        norm_a: float = math.sqrt(sum(a * a for a in vec_a))\n",
    "        norm_b: float = math.sqrt(sum(b * b for b in vec_b))\n",
    "        if norm_a == 0 or norm_b == 0:\n",
    "            return 0.0\n",
    "\n",
    "        return dot_product / (norm_a * norm_b)\n",
    "\n",
    "\n",
    "################################################################\n",
    "# 3) High-Level Utility Function\n",
    "################################################################\n",
    "\n",
    "\n",
    "def calculate_text_similarity(\n",
    "    text1: str, text2: str, model: EmbeddingModel, metric: SimilarityMetric\n",
    ") -> float:\n",
    "    \"\"\"Calculates text similarity using an embedding model and a similarity metric.\n",
    "\n",
    "    This function generates embeddings for the provided texts and then computes a\n",
    "    similarity score using the given similarity metric.\n",
    "\n",
    "    Args:\n",
    "        text1 (str): The first text string.\n",
    "        text2 (str): The second text string.\n",
    "        model (EmbeddingModel): An instance conforming to the embedding model interface.\n",
    "        metric (SimilarityMetric): An instance implementing a similarity metric.\n",
    "\n",
    "    Returns:\n",
    "        float: The computed similarity score.\n",
    "    \"\"\"\n",
    "    embedding1: List[float] = model.embed_text(text=text1)\n",
    "    embedding2: List[float] = model.embed_text(text=text2)\n",
    "    return metric.similarity(vec_a=embedding1, vec_b=embedding2)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mock_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 8\u001b[0m\n\u001b[1;32m      4\u001b[0m text_a: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHello world!\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      5\u001b[0m text_b: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHello, world??\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      7\u001b[0m score: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m=\u001b[39m calculate_text_similarity(\n\u001b[0;32m----> 8\u001b[0m     text1\u001b[38;5;241m=\u001b[39mtext_a, text2\u001b[38;5;241m=\u001b[39mtext_b, model\u001b[38;5;241m=\u001b[39mmock_model, metric\u001b[38;5;241m=\u001b[39mcosine\n\u001b[1;32m      9\u001b[0m )\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSimilarity between \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtext_a\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtext_b\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscore\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mock_model' is not defined"
=======
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-21 00:37:15,471 [WARNING] ember.core.registry.model.base.registry.factory: Provider name case mismatch: 'Openai' vs 'OpenAI'. Using the registered provider.\n",
      "2025-03-21 00:37:15,475 [DEBUG] ember.core.registry.model.base.registry.factory: Creating model 'openai:text-embedding-3-large' using provider class 'OpenAIModel'.\n",
      "2025-03-21 00:37:15,482 [INFO] ember.core.registry.model.initialization: Instantiated model: openai:text-embedding-3-large\n",
      "2025-03-21 00:37:15,528 [INFO] ember.core.registry.model.providers.openai.openai_provider: OpenAI forward invoked\n",
      "2025-03-21 00:37:15,661 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'timeout': 30, 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'Hello world!'}], 'model': 'text-embedding-3-large', 'max_completion_tokens': 512, 'temperature': None}}\n",
      "2025-03-21 00:37:15,695 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "2025-03-21 00:37:15,708 [DEBUG] httpcore.connection: close.started\n",
      "2025-03-21 00:37:15,744 [DEBUG] httpcore.connection: close.complete\n",
      "2025-03-21 00:37:15,752 [DEBUG] httpcore.connection: connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=30 socket_options=None\n",
      "2025-03-21 00:37:15,775 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f1604213410>\n",
      "2025-03-21 00:37:15,779 [DEBUG] httpcore.connection: start_tls.started ssl_context=<ssl.SSLContext object at 0x7f16a96ed910> server_hostname='api.openai.com' timeout=30\n",
      "2025-03-21 00:37:15,866 [DEBUG] httpcore.connection: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f16a8ff5750>\n",
      "2025-03-21 00:37:15,870 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>\n",
      "2025-03-21 00:37:15,876 [DEBUG] httpcore.http11: send_request_headers.complete\n",
      "2025-03-21 00:37:15,877 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>\n",
      "2025-03-21 00:37:15,878 [DEBUG] httpcore.http11: send_request_body.complete\n",
      "2025-03-21 00:37:15,879 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>\n",
      "2025-03-21 00:37:15,920 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 403, b'Forbidden', [(b'Date', b'Fri, 21 Mar 2025 07:37:16 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'vary', b'Origin'), (b'x-request-id', b'req_536398e43921f797ac509114aae14cae'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=rQJfdoJ54KiOHVXBfvUG99o9mGLvvP81mJe39yApwnM-1742542636-1.0.1.1-t6_oW0vtdbrhY.lVxM0S223ktjIO_SQ4ohXzxKRtCabBNZWZq9TEun6DIfyIJAlK77DPrCUMENp6Wkwrxd67RJJmb35J0Piu0S8e7F2TFoE; path=/; expires=Fri, 21-Mar-25 08:07:16 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'923bc87478aaeb35-SJC'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2025-03-21 00:37:15,936 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 403 Forbidden\"\n",
      "2025-03-21 00:37:15,943 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>\n",
      "2025-03-21 00:37:15,948 [DEBUG] httpcore.http11: receive_response_body.complete\n",
      "2025-03-21 00:37:15,952 [DEBUG] httpcore.http11: response_closed.started\n",
      "2025-03-21 00:37:15,955 [DEBUG] httpcore.http11: response_closed.complete\n",
      "2025-03-21 00:37:15,958 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions \"403 Forbidden\" Headers({'date': 'Fri, 21 Mar 2025 07:37:16 GMT', 'content-type': 'application/json; charset=utf-8', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'vary': 'Origin', 'x-request-id': 'req_536398e43921f797ac509114aae14cae', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'set-cookie': '__cf_bm=rQJfdoJ54KiOHVXBfvUG99o9mGLvvP81mJe39yApwnM-1742542636-1.0.1.1-t6_oW0vtdbrhY.lVxM0S223ktjIO_SQ4ohXzxKRtCabBNZWZq9TEun6DIfyIJAlK77DPrCUMENp6Wkwrxd67RJJmb35J0Piu0S8e7F2TFoE; path=/; expires=Fri, 21-Mar-25 08:07:16 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '923bc87478aaeb35-SJC', 'content-encoding': 'br', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "2025-03-21 00:37:15,962 [DEBUG] openai._base_client: request_id: req_536398e43921f797ac509114aae14cae\n",
      "2025-03-21 00:37:15,972 [DEBUG] openai._base_client: Encountered httpx.HTTPStatusError\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/anaconda3/envs/ember_upgrade/lib/python3.11/site-packages/openai/_base_client.py\", line 1040, in _request\n",
      "    response.raise_for_status()\n",
      "  File \"/root/anaconda3/envs/ember_upgrade/lib/python3.11/site-packages/httpx/_models.py\", line 763, in raise_for_status\n",
      "    raise HTTPStatusError(message, request=request, response=self)\n",
      "httpx.HTTPStatusError: Client error '403 Forbidden' for url 'https://api.openai.com/v1/chat/completions'\n",
      "For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/403\n",
      "2025-03-21 00:37:16,136 [DEBUG] openai._base_client: Not retrying\n",
      "2025-03-21 00:37:16,137 [DEBUG] openai._base_client: Re-raising status error\n",
      "2025-03-21 00:37:16,151 [ERROR] ember.core.registry.model.providers.openai.openai_provider: Unexpected error in OpenAIModel.forward()\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/ember/jared/ember/src/ember/core/registry/model/providers/openai/openai_provider.py\", line 389, in forward\n",
      "    response: Any = self.client.chat.completions.create(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/anaconda3/envs/ember_upgrade/lib/python3.11/site-packages/openai/_utils/_utils.py\", line 275, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/anaconda3/envs/ember_upgrade/lib/python3.11/site-packages/openai/resources/chat/completions.py\", line 829, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/root/anaconda3/envs/ember_upgrade/lib/python3.11/site-packages/openai/_base_client.py\", line 1280, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/anaconda3/envs/ember_upgrade/lib/python3.11/site-packages/openai/_base_client.py\", line 957, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/root/anaconda3/envs/ember_upgrade/lib/python3.11/site-packages/openai/_base_client.py\", line 1061, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.PermissionDeniedError: Error code: 403 - {'error': {'message': 'You are not allowed to sample from this model', 'type': 'invalid_request_error', 'param': None, 'code': None}}\n",
      "2025-03-21 00:37:17,168 [INFO] ember.core.registry.model.providers.openai.openai_provider: OpenAI forward invoked\n",
      "2025-03-21 00:37:17,172 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'timeout': 30, 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'Hello world!'}], 'model': 'text-embedding-3-large', 'max_completion_tokens': 512, 'temperature': None}}\n",
      "2025-03-21 00:37:17,174 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "2025-03-21 00:37:17,175 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>\n",
      "2025-03-21 00:37:17,176 [DEBUG] httpcore.http11: send_request_headers.complete\n",
      "2025-03-21 00:37:17,178 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>\n",
      "2025-03-21 00:37:17,182 [DEBUG] httpcore.http11: send_request_body.complete\n",
      "2025-03-21 00:37:17,184 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>\n",
      "2025-03-21 00:37:17,215 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 403, b'Forbidden', [(b'Date', b'Fri, 21 Mar 2025 07:37:17 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'vary', b'Origin'), (b'x-request-id', b'req_b1c4e773cbe460c0c8d22a74e4869095'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'923bc87c9c9beb35-SJC'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2025-03-21 00:37:17,219 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 403 Forbidden\"\n",
      "2025-03-21 00:37:17,222 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>\n",
      "2025-03-21 00:37:17,227 [DEBUG] httpcore.http11: receive_response_body.complete\n",
      "2025-03-21 00:37:17,231 [DEBUG] httpcore.http11: response_closed.started\n",
      "2025-03-21 00:37:17,235 [DEBUG] httpcore.http11: response_closed.complete\n",
      "2025-03-21 00:37:17,242 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions \"403 Forbidden\" Headers({'date': 'Fri, 21 Mar 2025 07:37:17 GMT', 'content-type': 'application/json; charset=utf-8', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'vary': 'Origin', 'x-request-id': 'req_b1c4e773cbe460c0c8d22a74e4869095', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '923bc87c9c9beb35-SJC', 'content-encoding': 'br', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "2025-03-21 00:37:17,245 [DEBUG] openai._base_client: request_id: req_b1c4e773cbe460c0c8d22a74e4869095\n",
      "2025-03-21 00:37:17,248 [DEBUG] openai._base_client: Encountered httpx.HTTPStatusError\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/anaconda3/envs/ember_upgrade/lib/python3.11/site-packages/openai/_base_client.py\", line 1040, in _request\n",
      "    response.raise_for_status()\n",
      "  File \"/root/anaconda3/envs/ember_upgrade/lib/python3.11/site-packages/httpx/_models.py\", line 763, in raise_for_status\n",
      "    raise HTTPStatusError(message, request=request, response=self)\n",
      "httpx.HTTPStatusError: Client error '403 Forbidden' for url 'https://api.openai.com/v1/chat/completions'\n",
      "For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/403\n",
      "2025-03-21 00:37:17,253 [DEBUG] openai._base_client: Not retrying\n",
      "2025-03-21 00:37:17,258 [DEBUG] openai._base_client: Re-raising status error\n",
      "2025-03-21 00:37:17,261 [ERROR] ember.core.registry.model.providers.openai.openai_provider: Unexpected error in OpenAIModel.forward()\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/ember/jared/ember/src/ember/core/registry/model/providers/openai/openai_provider.py\", line 389, in forward\n",
      "    response: Any = self.client.chat.completions.create(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/anaconda3/envs/ember_upgrade/lib/python3.11/site-packages/openai/_utils/_utils.py\", line 275, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/anaconda3/envs/ember_upgrade/lib/python3.11/site-packages/openai/resources/chat/completions.py\", line 829, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/root/anaconda3/envs/ember_upgrade/lib/python3.11/site-packages/openai/_base_client.py\", line 1280, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/anaconda3/envs/ember_upgrade/lib/python3.11/site-packages/openai/_base_client.py\", line 957, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/root/anaconda3/envs/ember_upgrade/lib/python3.11/site-packages/openai/_base_client.py\", line 1061, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.PermissionDeniedError: Error code: 403 - {'error': {'message': 'You are not allowed to sample from this model', 'type': 'invalid_request_error', 'param': None, 'code': None}}\n",
      "2025-03-21 00:37:19,267 [INFO] ember.core.registry.model.providers.openai.openai_provider: OpenAI forward invoked\n",
      "2025-03-21 00:37:19,277 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'timeout': 30, 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'Hello world!'}], 'model': 'text-embedding-3-large', 'max_completion_tokens': 512, 'temperature': None}}\n",
      "2025-03-21 00:37:19,281 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "2025-03-21 00:37:19,284 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>\n",
      "2025-03-21 00:37:19,288 [DEBUG] httpcore.http11: send_request_headers.complete\n",
      "2025-03-21 00:37:19,290 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>\n",
      "2025-03-21 00:37:19,295 [DEBUG] httpcore.http11: send_request_body.complete\n",
      "2025-03-21 00:37:19,298 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>\n",
      "2025-03-21 00:37:19,332 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 403, b'Forbidden', [(b'Date', b'Fri, 21 Mar 2025 07:37:19 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'vary', b'Origin'), (b'x-request-id', b'req_e3547707ff5d4f5809990164a72b6a49'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'923bc889cd03eb35-SJC'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2025-03-21 00:37:19,334 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 403 Forbidden\"\n",
      "2025-03-21 00:37:19,339 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>\n",
      "2025-03-21 00:37:19,346 [DEBUG] httpcore.http11: receive_response_body.complete\n",
      "2025-03-21 00:37:19,349 [DEBUG] httpcore.http11: response_closed.started\n",
      "2025-03-21 00:37:19,351 [DEBUG] httpcore.http11: response_closed.complete\n",
      "2025-03-21 00:37:19,354 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions \"403 Forbidden\" Headers({'date': 'Fri, 21 Mar 2025 07:37:19 GMT', 'content-type': 'application/json; charset=utf-8', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'vary': 'Origin', 'x-request-id': 'req_e3547707ff5d4f5809990164a72b6a49', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '923bc889cd03eb35-SJC', 'content-encoding': 'br', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "2025-03-21 00:37:19,355 [DEBUG] openai._base_client: request_id: req_e3547707ff5d4f5809990164a72b6a49\n",
      "2025-03-21 00:37:19,362 [DEBUG] openai._base_client: Encountered httpx.HTTPStatusError\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/anaconda3/envs/ember_upgrade/lib/python3.11/site-packages/openai/_base_client.py\", line 1040, in _request\n",
      "    response.raise_for_status()\n",
      "  File \"/root/anaconda3/envs/ember_upgrade/lib/python3.11/site-packages/httpx/_models.py\", line 763, in raise_for_status\n",
      "    raise HTTPStatusError(message, request=request, response=self)\n",
      "httpx.HTTPStatusError: Client error '403 Forbidden' for url 'https://api.openai.com/v1/chat/completions'\n",
      "For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/403\n",
      "2025-03-21 00:37:19,368 [DEBUG] openai._base_client: Not retrying\n",
      "2025-03-21 00:37:19,374 [DEBUG] openai._base_client: Re-raising status error\n",
      "2025-03-21 00:37:19,377 [ERROR] ember.core.registry.model.providers.openai.openai_provider: Unexpected error in OpenAIModel.forward()\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/ember/jared/ember/src/ember/core/registry/model/providers/openai/openai_provider.py\", line 389, in forward\n",
      "    response: Any = self.client.chat.completions.create(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/anaconda3/envs/ember_upgrade/lib/python3.11/site-packages/openai/_utils/_utils.py\", line 275, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/anaconda3/envs/ember_upgrade/lib/python3.11/site-packages/openai/resources/chat/completions.py\", line 829, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/root/anaconda3/envs/ember_upgrade/lib/python3.11/site-packages/openai/_base_client.py\", line 1280, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/anaconda3/envs/ember_upgrade/lib/python3.11/site-packages/openai/_base_client.py\", line 957, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/root/anaconda3/envs/ember_upgrade/lib/python3.11/site-packages/openai/_base_client.py\", line 1061, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.PermissionDeniedError: Error code: 403 - {'error': {'message': 'You are not allowed to sample from this model', 'type': 'invalid_request_error', 'param': None, 'code': None}}\n",
      "2025-03-21 00:37:19,380 [ERROR] ModelService: Error invoking model 'openai:text-embedding-3-large'.\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/ember/jared/ember/src/ember/core/registry/model/providers/openai/openai_provider.py\", line 389, in forward\n",
      "    response: Any = self.client.chat.completions.create(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/anaconda3/envs/ember_upgrade/lib/python3.11/site-packages/openai/_utils/_utils.py\", line 275, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/anaconda3/envs/ember_upgrade/lib/python3.11/site-packages/openai/resources/chat/completions.py\", line 829, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/root/anaconda3/envs/ember_upgrade/lib/python3.11/site-packages/openai/_base_client.py\", line 1280, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/anaconda3/envs/ember_upgrade/lib/python3.11/site-packages/openai/_base_client.py\", line 957, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/root/anaconda3/envs/ember_upgrade/lib/python3.11/site-packages/openai/_base_client.py\", line 1061, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.PermissionDeniedError: Error code: 403 - {'error': {'message': 'You are not allowed to sample from this model', 'type': 'invalid_request_error', 'param': None, 'code': None}}\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/ember/jared/ember/src/ember/core/registry/model/base/services/model_service.py\", line 106, in _invoke\n",
      "    response = model(prompt=prompt, **kwargs)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/ember/jared/ember/src/ember/core/registry/model/providers/base_provider.py\", line 182, in __call__\n",
      "    return self.forward(request=chat_request)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/anaconda3/envs/ember_upgrade/lib/python3.11/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n",
      "    return copy(f, *args, **kw)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/anaconda3/envs/ember_upgrade/lib/python3.11/site-packages/tenacity/__init__.py\", line 475, in __call__\n",
      "    do = self.iter(retry_state=retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/anaconda3/envs/ember_upgrade/lib/python3.11/site-packages/tenacity/__init__.py\", line 376, in iter\n",
      "    result = action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/anaconda3/envs/ember_upgrade/lib/python3.11/site-packages/tenacity/__init__.py\", line 418, in exc_check\n",
      "    raise retry_exc.reraise()\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/anaconda3/envs/ember_upgrade/lib/python3.11/site-packages/tenacity/__init__.py\", line 185, in reraise\n",
      "    raise self.last_attempt.result()\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/anaconda3/envs/ember_upgrade/lib/python3.11/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/anaconda3/envs/ember_upgrade/lib/python3.11/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/root/anaconda3/envs/ember_upgrade/lib/python3.11/site-packages/tenacity/__init__.py\", line 478, in __call__\n",
      "    result = fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/ember/jared/ember/src/ember/core/registry/model/providers/openai/openai_provider.py\", line 406, in forward\n",
      "    raise ProviderAPIError(str(exc)) from exc\n",
      "ember.core.exceptions.ProviderAPIError: Error code: 403 - {'error': {'message': 'You are not allowed to sample from this model', 'type': 'invalid_request_error', 'param': None, 'code': None}}\n"
     ]
    },
    {
     "ename": "ProviderAPIError",
     "evalue": "Error invoking model openai:text-embedding-3-large",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mPermissionDeniedError\u001b[39m                     Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ember/jared/ember/src/ember/core/registry/model/providers/openai/openai_provider.py:389\u001b[39m, in \u001b[36mOpenAIModel.forward\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    388\u001b[39m timeout = openai_kwargs.pop(\u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m, \u001b[32m30\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m389\u001b[39m response: Any = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mchat\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompletions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    390\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel_info\u001b[49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    391\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    392\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mopenai_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    393\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    394\u001b[39m content: \u001b[38;5;28mstr\u001b[39m = response.choices[\u001b[32m0\u001b[39m].message.content.strip()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/ember_upgrade/lib/python3.11/site-packages/openai/_utils/_utils.py:275\u001b[39m, in \u001b[36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    274\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[32m--> \u001b[39m\u001b[32m275\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/ember_upgrade/lib/python3.11/site-packages/openai/resources/chat/completions.py:829\u001b[39m, in \u001b[36mCompletions.create\u001b[39m\u001b[34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m    828\u001b[39m validate_response_format(response_format)\n\u001b[32m--> \u001b[39m\u001b[32m829\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    830\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/chat/completions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    831\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    832\u001b[39m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    833\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    834\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    835\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43maudio\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    836\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfrequency_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    837\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunction_call\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    838\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunctions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    839\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogit_bias\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    840\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    841\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_completion_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    842\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    843\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    844\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodalities\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    845\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    846\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparallel_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    847\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprediction\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    848\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpresence_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    849\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    850\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    851\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    852\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstop\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    853\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    854\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    855\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    856\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    857\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    858\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    859\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_logprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    860\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    861\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    862\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    863\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    864\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    865\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    866\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    867\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    868\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    869\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    870\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    871\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/ember_upgrade/lib/python3.11/site-packages/openai/_base_client.py:1280\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1277\u001b[39m opts = FinalRequestOptions.construct(\n\u001b[32m   1278\u001b[39m     method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1279\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1280\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/ember_upgrade/lib/python3.11/site-packages/openai/_base_client.py:957\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[39m\n\u001b[32m    955\u001b[39m     retries_taken = \u001b[32m0\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m957\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    958\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    959\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    960\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    961\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    962\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    963\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/ember_upgrade/lib/python3.11/site-packages/openai/_base_client.py:1061\u001b[39m, in \u001b[36mSyncAPIClient._request\u001b[39m\u001b[34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[39m\n\u001b[32m   1060\u001b[39m     log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1061\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1063\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._process_response(\n\u001b[32m   1064\u001b[39m     cast_to=cast_to,\n\u001b[32m   1065\u001b[39m     options=options,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1069\u001b[39m     retries_taken=retries_taken,\n\u001b[32m   1070\u001b[39m )\n",
      "\u001b[31mPermissionDeniedError\u001b[39m: Error code: 403 - {'error': {'message': 'You are not allowed to sample from this model', 'type': 'invalid_request_error', 'param': None, 'code': None}}",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mProviderAPIError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ember/jared/ember/src/ember/core/registry/model/base/services/model_service.py:106\u001b[39m, in \u001b[36mModelService._invoke\u001b[39m\u001b[34m(self, model_id, prompt, **kwargs)\u001b[39m\n\u001b[32m    105\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m106\u001b[39m     response = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    107\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ember/jared/ember/src/ember/core/registry/model/providers/base_provider.py:182\u001b[39m, in \u001b[36mBaseProviderModel.__call__\u001b[39m\u001b[34m(self, prompt, **kwargs)\u001b[39m\n\u001b[32m    181\u001b[39m chat_request: ChatRequest = ChatRequest(prompt=prompt, **kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m182\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchat_request\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/ember_upgrade/lib/python3.11/site-packages/tenacity/__init__.py:336\u001b[39m, in \u001b[36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[39m\u001b[34m(*args, **kw)\u001b[39m\n\u001b[32m    335\u001b[39m wrapped_f.statistics = copy.statistics  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m336\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/ember_upgrade/lib/python3.11/site-packages/tenacity/__init__.py:475\u001b[39m, in \u001b[36mRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    474\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m475\u001b[39m     do = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    476\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/ember_upgrade/lib/python3.11/site-packages/tenacity/__init__.py:376\u001b[39m, in \u001b[36mBaseRetrying.iter\u001b[39m\u001b[34m(self, retry_state)\u001b[39m\n\u001b[32m    375\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.iter_state.actions:\n\u001b[32m--> \u001b[39m\u001b[32m376\u001b[39m     result = \u001b[43maction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    377\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/ember_upgrade/lib/python3.11/site-packages/tenacity/__init__.py:418\u001b[39m, in \u001b[36mBaseRetrying._post_stop_check_actions.<locals>.exc_check\u001b[39m\u001b[34m(rs)\u001b[39m\n\u001b[32m    417\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.reraise:\n\u001b[32m--> \u001b[39m\u001b[32m418\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43mretry_exc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    419\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m retry_exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mfut\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexception\u001b[39;00m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/ember_upgrade/lib/python3.11/site-packages/tenacity/__init__.py:185\u001b[39m, in \u001b[36mRetryError.reraise\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    184\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.last_attempt.failed:\n\u001b[32m--> \u001b[39m\u001b[32m185\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlast_attempt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    186\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/ember_upgrade/lib/python3.11/concurrent/futures/_base.py:449\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    448\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state == FINISHED:\n\u001b[32m--> \u001b[39m\u001b[32m449\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    451\u001b[39m \u001b[38;5;28mself\u001b[39m._condition.wait(timeout)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/ember_upgrade/lib/python3.11/concurrent/futures/_base.py:401\u001b[39m, in \u001b[36mFuture.__get_result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    400\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception\n\u001b[32m    402\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    403\u001b[39m     \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/ember_upgrade/lib/python3.11/site-packages/tenacity/__init__.py:478\u001b[39m, in \u001b[36mRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    477\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m478\u001b[39m     result = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    479\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ember/jared/ember/src/ember/core/registry/model/providers/openai/openai_provider.py:406\u001b[39m, in \u001b[36mOpenAIModel.forward\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    405\u001b[39m logger.exception(\u001b[33m\"\u001b[39m\u001b[33mUnexpected error in OpenAIModel.forward()\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m406\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m ProviderAPIError(\u001b[38;5;28mstr\u001b[39m(exc)) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc\u001b[39;00m\n",
      "\u001b[31mProviderAPIError\u001b[39m: Error code: 403 - {'error': {'message': 'You are not allowed to sample from this model', 'type': 'invalid_request_error', 'param': None, 'code': None}}",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mProviderAPIError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[51]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m text_a: \u001b[38;5;28mstr\u001b[39m = \u001b[33m\"\u001b[39m\u001b[33mHello world!\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      5\u001b[39m text_b: \u001b[38;5;28mstr\u001b[39m = \u001b[33m\"\u001b[39m\u001b[33mHello, world??\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m score: \u001b[38;5;28mfloat\u001b[39m = \u001b[43mcalculate_text_similarity\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtext1\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtext_a\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext2\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtext_b\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mopenai_embedding_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcosine\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSimilarity between \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtext_a\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m and \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtext_b\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscore\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[50]\u001b[39m\u001b[32m, line 171\u001b[39m, in \u001b[36mcalculate_text_similarity\u001b[39m\u001b[34m(text1, text2, model, metric)\u001b[39m\n\u001b[32m    154\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcalculate_text_similarity\u001b[39m(\n\u001b[32m    155\u001b[39m     text1: \u001b[38;5;28mstr\u001b[39m, text2: \u001b[38;5;28mstr\u001b[39m, model: EmbeddingModel, metric: SimilarityMetric\n\u001b[32m    156\u001b[39m ) -> \u001b[38;5;28mfloat\u001b[39m:\n\u001b[32m    157\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Calculates text similarity using an embedding model and a similarity metric.\u001b[39;00m\n\u001b[32m    158\u001b[39m \n\u001b[32m    159\u001b[39m \u001b[33;03m    This function generates embeddings for the provided texts and then computes a\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    169\u001b[39m \u001b[33;03m        float: The computed similarity score.\u001b[39;00m\n\u001b[32m    170\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m171\u001b[39m     embedding1: List[\u001b[38;5;28mfloat\u001b[39m] = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43membed_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtext1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    172\u001b[39m     embedding2: List[\u001b[38;5;28mfloat\u001b[39m] = model.embed_text(text=text2)\n\u001b[32m    173\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m metric.similarity(vec_a=embedding1, vec_b=embedding2)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[50]\u001b[39m\u001b[32m, line 58\u001b[39m, in \u001b[36mText_Embedding_3_EmbeddingModel.embed_text\u001b[39m\u001b[34m(self, text)\u001b[39m\n\u001b[32m     49\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34membed_text\u001b[39m(\u001b[38;5;28mself\u001b[39m, text: \u001b[38;5;28mstr\u001b[39m) -> List[\u001b[38;5;28mfloat\u001b[39m]:\n\u001b[32m     50\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Computes the embedding vector for the provided text.\u001b[39;00m\n\u001b[32m     51\u001b[39m \n\u001b[32m     52\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     56\u001b[39m \u001b[33;03m        List[float]: A list of floats representing the embedding vector.\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m58\u001b[39m     response = \u001b[43mllm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mopenai:text-embedding-3-large\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     60\u001b[39m     \u001b[38;5;66;03m# response = openai.Embedding.create(\u001b[39;00m\n\u001b[32m     61\u001b[39m     \u001b[38;5;66;03m#     model=\"text-embedding-3\",\u001b[39;00m\n\u001b[32m     62\u001b[39m     \u001b[38;5;66;03m#     input=text\u001b[39;00m\n\u001b[32m     63\u001b[39m     \u001b[38;5;66;03m# )\u001b[39;00m\n\u001b[32m     64\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m response.data\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ember/jared/ember/src/ember/core/registry/model/base/services/model_service.py:100\u001b[39m, in \u001b[36mModelService.invoke_model\u001b[39m\u001b[34m(self, model_id, prompt, **kwargs)\u001b[39m\n\u001b[32m     98\u001b[39m         response = \u001b[38;5;28mself\u001b[39m._invoke(model_id, prompt, **kwargs)\n\u001b[32m     99\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m100\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_invoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    101\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ember/jared/ember/src/ember/core/registry/model/base/services/model_service.py:109\u001b[39m, in \u001b[36mModelService._invoke\u001b[39m\u001b[34m(self, model_id, prompt, **kwargs)\u001b[39m\n\u001b[32m    107\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    108\u001b[39m     \u001b[38;5;28mself\u001b[39m._logger.exception(\u001b[33m\"\u001b[39m\u001b[33mError invoking model \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m, model_id)\n\u001b[32m--> \u001b[39m\u001b[32m109\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ProviderAPIError(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mError invoking model \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc\u001b[39;00m\n\u001b[32m    111\u001b[39m metric_counter = \u001b[38;5;28mself\u001b[39m._metrics.get(\u001b[33m\"\u001b[39m\u001b[33mmodel_invocations\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    112\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m metric_counter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mProviderAPIError\u001b[39m: Error invoking model openai:text-embedding-3-large"
>>>>>>> feb7b31 (added embedding model)
     ]
    }
   ],
   "source": [
    "openai_embedding_model = Text_Embedding_3_EmbeddingModel()\n",
    "cosine: CosineSimilarity = CosineSimilarity()\n",
    "\n",
    "text_a: str = \"Hello world!\"\n",
    "text_b: str = \"Hello, world??\"\n",
    "\n",
    "score: float = calculate_text_similarity(\n",
    "    text1=text_a, text2=text_b, model=openai_embedding_model, metric=cosine\n",
    ")\n",
    "print(f\"Similarity between '{text_a}' and '{text_b}': {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "## Compression Ratio (WIP)\n",
    "\n",
    "from `src/ember/core/utils/eval/evaluators.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q diversity==0.2.0\n",
    "%pip install -q spacy==3.8.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import re\n",
    "import subprocess\n",
    "from typing import Any, Dict, TypeVar, Optional, List, Generic, Callable, Union\n",
    "\n",
    "from ember.core.utils.eval.base_evaluator import IEvaluator, EvaluationResult\n",
    "from ember.core.utils.eval.extractors import RegexExtractor\n",
    "\n",
    "from diversity import compression_ratio\n",
    "\n",
    "T_out = TypeVar(\"T_out\")\n",
    "T_truth = TypeVar(\"T_truth\")\n",
    "\n",
    "\n",
    "class ComposedEvaluator(IEvaluator[T_out, T_truth], Generic[T_out, T_truth]):\n",
    "    \"\"\"Combines an output extractor with an evaluator for the extracted data.\n",
    "\n",
    "    This evaluator first transforms the system output using the provided extractor,\n",
    "    then evaluates the extracted value using the specified base evaluator.\n",
    "\n",
    "    Args:\n",
    "        extractor: An object with an `extract` method to process the system output.\n",
    "        base_evaluator (IEvaluator): An evaluator that processes the extracted output.\n",
    "\n",
    "    Returns:\n",
    "        EvaluationResult: The result of the evaluation.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        extractor: Any,  # Expecting an extractor with an `extract` method.\n",
    "        base_evaluator: IEvaluator[Any, Any],\n",
    "    ) -> None:\n",
    "        self.extractor = extractor\n",
    "        self.base_evaluator = base_evaluator\n",
    "\n",
    "    def evaluate(\n",
    "        self, system_output: T_out, correct_answer: Any, **kwargs: Any\n",
    "    ) -> EvaluationResult:\n",
    "        \"\"\"Evaluates the provided system output against the correct answer.\n",
    "\n",
    "        Args:\n",
    "            system_output (T_out): The raw output generated by the system.\n",
    "            correct_answer (Any): The expected correct answer.\n",
    "            **kwargs: Additional keyword arguments for extraction or evaluation.\n",
    "\n",
    "        Returns:\n",
    "            EvaluationResult: The result of evaluating the extracted value.\n",
    "        \"\"\"\n",
    "        extracted_value = self.extractor.extract(system_output, **kwargs)\n",
    "        return self.base_evaluator.evaluate(extracted_value, correct_answer, **kwargs)\n",
    "\n",
    "\n",
    "# Basic Evaluators\n",
    "\n",
    "\n",
    "class ExactMatchEaluator(IEvaluator[str, str]):\n",
    "    \"\"\"Evaluator to check for an exact match between two strings,\n",
    "    ignoring differences in whitespace and case.\n",
    "\n",
    "    Example:\n",
    "        evaluator = ExactMatchEvaluator()\n",
    "        result = evaluator.evaluate(\"Hello World\", \"hello   world\")\n",
    "\n",
    "    Args:\n",
    "        compare_fn (Optional[Callable[[str, str], bool]]): Optional custom comparison function.\n",
    "            If not provided, strings are normalized (whitespace removed, lowercase) before comparison.\n",
    "\n",
    "    Returns:\n",
    "        EvaluationResult: The result containing a correctness flag and a score.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, compare_fn: Optional[Callable[[str, str], bool]] = None) -> None:\n",
    "        self.compare_fn = compare_fn or self._default_compare\n",
    "\n",
    "    def _default_compare(self, str1: str, str2: str) -> bool:\n",
    "        \"\"\"Default string comparison function that ignores case and whitespace.\n",
    "\n",
    "        Args:\n",
    "            str1 (str): First string to compare\n",
    "            str2 (str): Second string to compare\n",
    "\n",
    "        Returns:\n",
    "            bool: True if strings match after normalization\n",
    "        \"\"\"\n",
    "        return str1.strip().lower() == str2.strip().lower()\n",
    "\n",
    "    def evaluate(\n",
    "        self, system_output: str, correct_answer: str, **kwargs: Any\n",
    "    ) -> EvaluationResult:\n",
    "        \"\"\"Evaluates whether a system output exactly matches the correct answer.\n",
    "\n",
    "        Args:\n",
    "            system_output (str): The system-generated string.\n",
    "            correct_answer (str): The expected answer string.\n",
    "            **kwargs: Additional keyword arguments (unused).\n",
    "\n",
    "        Returns:\n",
    "            EvaluationResult: An object with `is_correct` set to True if the normalized strings match,\n",
    "                              along with a corresponding score.\n",
    "        \"\"\"\n",
    "        is_correct = self.compare_fn(system_output, correct_answer)\n",
    "        score = 1.0 if is_correct else 0.0\n",
    "        return EvaluationResult(is_correct=is_correct, score=score)\n",
    "\n",
    "class DiversityScoringEvaluator(IEvaluator[List[str], None]):\n",
    "    \"\"\"\n",
    "    Evaluator to test ensemble outputs -> score them (float)\n",
    "    \"\"\"\n",
    "    def evaluate(\n",
    "            self, \n",
    "            system_output: List[str], \n",
    "            **kwargs) -> EvaluationResult:\n",
    "        if system_output is None or len(system_output) == 0:\n",
    "            return EvaluationResult(is_correct=False, score=-1)\n",
    "\n",
    "        # current compression ratio formula\n",
    "        # TODO: update scoring function to make it better\n",
    "        # -> like use token count\n",
    "\n",
    "        # example I was thinking about:\n",
    "        letter_sum = sum(len(response) for response in system_output)\n",
    "        ratio = compression_ratio(system_output) * min(1, len(system_output)/5) * min(1, letter_sum/100)\n",
    "        # ratio = compression_ratio(system_output, algorithm='gzip',verbose=True)\n",
    "        return EvaluationResult(is_correct=True,score=ratio,metadata = {'responses': system_output})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Edit Distance (WIP)\n",
    "- need to merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q python-Levenshtein"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 1,
=======
   "execution_count": 21,
>>>>>>> feb7b31 (added embedding model)
   "metadata": {},
   "outputs": [],
   "source": [
    "import Levenshtein\n",
    "from typing import List\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class EvaluationResult:\n",
    "    is_correct: bool\n",
    "    score: float\n",
    "    metadata: dict\n",
    "\n",
    "class EditDistanceScoringEvaluator:\n",
    "\n",
    "    def evaluate(self, system_output: List[str], **kwargs) -> EvaluationResult:\n",
    "        if system_output is None or len(system_output) == 0:\n",
    "            return EvaluationResult(is_correct=False, score=-1, metadata={})\n",
    "\n",
    "        diversity_score = self.compute_distance(system_output)\n",
    "\n",
    "        return EvaluationResult(\n",
    "            is_correct=True, \n",
    "            score=diversity_score,\n",
    "            metadata={'responses': system_output}\n",
    "        )\n",
    "\n",
    "    def compute_distance(self, outputs: List[str]) -> float:\n",
    "        n = len(outputs)\n",
    "        if n < 2:\n",
    "            return 0.0\n",
    "\n",
    "        total_distance = 0\n",
    "        pairs = 0\n",
    "\n",
    "        for i in range(n):\n",
    "            for j in range(i + 1, n):\n",
    "                dist = Levenshtein.distance(outputs[i], outputs[j])\n",
    "                max_len = max(len(outputs[i]), len(outputs[j]))\n",
    "                normalized_dist = dist / max_len if max_len > 0 else 0 \n",
    "                total_distance += normalized_dist\n",
    "                pairs += 1\n",
    "        \n",
    "        return total_distance / pairs if pairs > 0 else 0.0\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 2,
=======
   "execution_count": 22,
>>>>>>> feb7b31 (added embedding model)
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diversity Score: 0.8301\n",
      "Is Correct: True\n",
      "Metadata: {'responses': ['hi there', 'hi', 'hello', 'yo whatup']}\n"
     ]
    }
   ],
   "source": [
    "distance_evaluator = EditDistanceScoringEvaluator()\n",
    "\n",
    "# input_strs = [\n",
    "#     \";lkjawefopajwiefpoij23jf9aj8sdfj8903jf908j -- Understanding the importance of effective communication in the workplace cannot be overstated. Clear communication fosters a positive environment where people can express their ideas and work together efficiently. When team members understand one another, they can collaborate seamlessly, avoid misunderstandings, and achieve collective goals. Furthermore, communication skills are essential for building trust, resolving conflicts, and ensuring that expectations are clear. Whether through verbal discussions, emails, or presentations, knowing how to convey thoughts in an understandable way is key to success in any professional setting.\",\n",
    "#     \"fej89qw098efjq29f38j0938j20f398jqwe098fjq98wf -- In any workplace, the ability to communicate effectively is crucial for success. When individuals can clearly articulate their ideas and listen actively, it leads to a more productive and harmonious environment. Good communication prevents misunderstandings, aids in team collaboration, and helps in meeting shared objectives. It also plays a vital role in fostering trust among colleagues, resolving disputes, and ensuring transparency. Whether its through face-to-face conversations, written messages, or virtual meetings, mastering communication is essential to creating a positive, high-functioning work culture.\",\n",
    "#     \"Effective communication is a cornerstone of a successful work environment. When employees communicate clearly and efficiently, it improves the overall flow of work and enhances collaboration. Clear exchanges of ideas help to eliminate confusion, build mutual trust, and ensure that everyone is aligned in their goals. Additionally, strong communication skills are key to managing conflicts and setting clear expectations among teams. Whether in meetings, emails, or other formats, being able to communicate effectively contributes to a thriving and efficient workplace.\",\n",
    "#     \"The role of communication in the workplace cannot be overlooked. It serves as the foundation for successful teamwork and organizational growth. When team members share information clearly, it promotes a collaborative atmosphere and reduces the risk of errors or misinterpretations. Strong communication is also vital in building relationships, resolving issues, and making sure everyone is on the same page. Whether it's verbal exchanges or written correspondence, honing your ability to communicate well is vital for fostering an effective work environment.\",\n",
    "#     \"Communication within the workplace is a vital element for success. Clear and open communication promotes a cooperative and efficient atmosphere, helping team members to better understand each others ideas and work toward common goals. It reduces confusion, builds trust, and allows for smoother problem-solving when conflicts arise. By conveying thoughts and expectations effectively, individuals can create stronger working relationships and a productive team dynamic. Whether through emails, phone calls, or face-to-face interactions, mastering communication techniques is key for professional achievement.\",\n",
    "# ]\n",
    "\n",
    "input_strs = [\"hi there\", \"hi\", \"hello\", \"yo whatup\"]\n",
    "\n",
    "# input_strs = [\"This is a sample text with lots of repetition.\", \n",
    "#                 \"This is a sample text with lots of repetition.\",\n",
    "#                 \"This is a sample text with lots of repetition.\"]\n",
    "\n",
    "edit_distance = distance_evaluator.evaluate(input_strs)\n",
    "\n",
    "print(f\"Diversity Score: {edit_distance.score:.4f}\")\n",
    "print(f\"Is Correct: {edit_distance.is_correct}\")\n",
    "print(f\"Metadata: {edit_distance.metadata}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Novelty Score\n",
    "- need to merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from dataclasses import dataclass\n",
    "import numpy as np\n",
    "\n",
    "@dataclass\n",
    "class EvaluationResult:\n",
    "    is_correct: bool\n",
    "    score: float\n",
    "    metadata: dict\n",
    "\n",
    "class NoveltyScoringEvaluator:\n",
    "    \n",
    "    def evaluate(self, model: EmbeddingModel, system_output: List[str], **kwargs) -> EvaluationResult:\n",
    "        if not system_output or len(system_output) == 0:\n",
    "            return EvaluationResult(is_correct=False, score=-1, metadata={})\n",
    "\n",
    "        novelty_scores = [self.compute_novelty(r, system_output[:i]) for i, r in enumerate(system_output)]\n",
    "\n",
    "        avg_novelty = sum(novelty_scores) / len(novelty_scores) if novelty_scores else 0.0\n",
    "\n",
    "        return EvaluationResult(\n",
    "            is_correct=True,\n",
    "            score=avg_novelty,\n",
    "            metadata={'responses': system_output, 'novelty_scores': novelty_scores}\n",
    "        )\n",
    "\n",
    "    def compute_novelty(self, response: str, prior_responses: List[str]) -> float:\n",
    "        if not prior_responses:\n",
    "            return 1.0\n",
    "\n",
    "        new_embedding = self.model.embed_text(response)\n",
    "        prior_embeddings = [self.model.embed_text(r) for r in prior_responses]\n",
    "\n",
    "        similarities = [\n",
    "            np.dot(new_embedding, prior_embedding) /\n",
    "            (np.linalg.norm(new_embedding) * np.linalg.norm(prior_embedding))\n",
    "            for prior_embedding in prior_embeddings\n",
    "        ]\n",
    "\n",
    "        return 1 - max(similarities)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EvaluationResult(is_correct=True, score=0.08368770360509659, metadata={'responses': ['Hello world!', 'Hi there!', 'Goodbye!']})\n"
     ]
    }
   ],
   "source": [
    "novelty_evaluator = NoveltyScoringEvaluator()\n",
    "\n",
    "input_strs = [\"hi there\", \"hi\", \"hello\", \"yo whatup\"]\n",
    "\n",
    "mock_model: MockEmbeddingModel = MockEmbeddingModel()\n",
    "novelty = novelty_evaluator.evaluate(mock_model, input_strs)\n",
    "\n",
    "print(f\"Diversity Score: {novelty.score:.4f}\")\n",
    "print(f\"Is Correct: {novelty.is_correct}\")\n",
    "print(f\"Metadata: {novelty.metadata}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "## Putting it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "mock_model: MockEmbeddingModel = MockEmbeddingModel()\n",
    "cosine: CosineSimilarity = CosineSimilarity()\n",
    "diversity_evaluator = DiversityScoringEvaluator()\n",
    "edit_dist_evaluator = EditDistanceScoringEvaluator()\n",
    "\n",
    "def ensemble_diversity(strings):\n",
    "    compression = diversity_evaluator.evaluate(strings)\n",
    "    print(\"DiversityScoringEvaluator result:\", compression)\n",
    "    scores = list()\n",
    "    for ind1 in range(len(strings)):\n",
    "        ind2 = ind1+1 if ind1+1 != len(strings) else 0\n",
    "        curr_score = calculate_text_similarity(text1=strings[ind1], text2=strings[ind2], model=mock_model, metric=cosine)\n",
    "        print(f\"SimilarityScore between ind1={ind1} and ind2={ind2}: {curr_score}\")\n",
    "        scores.append(curr_score)\n",
    "    avg_score = np.average(scores)\n",
    "    print(f\"Avg cosine similarity: {avg_score}\")\n",
    "    print(f\"diversity cosine-sim inverse: {1-avg_score}\")\n",
    "    edit_distance = edit_dist_evaluator.evaluate(strings)\n",
    "    print(f\"edit-dist score: {edit_distance.score:.4f}\")\n",
    "    print(\"-------------------------------\")\n",
    "    print(f\"possible diversity score: {((1-avg_score) + compression.score  + edit_distance.score) / 3.}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DiversityScoringEvaluator result: EvaluationResult(is_correct=True, score=0.063936, metadata={'responses': ['hi there', 'hi', 'hello', 'yo whatup']})\n",
      "SimilarityScore between ind1=0 and ind2=1: 0.5207675658482732\n",
      "SimilarityScore between ind1=1 and ind2=2: 0.6088947130341378\n",
      "SimilarityScore between ind1=2 and ind2=3: 0.67913155770349\n",
      "SimilarityScore between ind1=3 and ind2=0: 0.9344774636399475\n",
      "Avg cosine similarity: 0.6858178250564622\n",
      "diversity cosine-sim inverse: 0.31418217494353784\n",
      "edit-dist score: 0.8301\n",
      "-------------------------------\n",
      "possible diversity score: 0.40273692251204346\n"
     ]
    }
   ],
   "source": [
    "# input_strs = [\n",
    "#     \";lkjawefopajwiefpoij23jf9aj8sdfj8903jf908j -- Understanding the importance of effective communication in the workplace cannot be overstated. Clear communication fosters a positive environment where people can express their ideas and work together efficiently. When team members understand one another, they can collaborate seamlessly, avoid misunderstandings, and achieve collective goals. Furthermore, communication skills are essential for building trust, resolving conflicts, and ensuring that expectations are clear. Whether through verbal discussions, emails, or presentations, knowing how to convey thoughts in an understandable way is key to success in any professional setting.\",\n",
    "#     \"fej89qw098efjq29f38j0938j20f398jqwe098fjq98wf -- In any workplace, the ability to communicate effectively is crucial for success. When individuals can clearly articulate their ideas and listen actively, it leads to a more productive and harmonious environment. Good communication prevents misunderstandings, aids in team collaboration, and helps in meeting shared objectives. It also plays a vital role in fostering trust among colleagues, resolving disputes, and ensuring transparency. Whether its through face-to-face conversations, written messages, or virtual meetings, mastering communication is essential to creating a positive, high-functioning work culture.\",\n",
    "#     \"Effective communication is a cornerstone of a successful work environment. When employees communicate clearly and efficiently, it improves the overall flow of work and enhances collaboration. Clear exchanges of ideas help to eliminate confusion, build mutual trust, and ensure that everyone is aligned in their goals. Additionally, strong communication skills are key to managing conflicts and setting clear expectations among teams. Whether in meetings, emails, or other formats, being able to communicate effectively contributes to a thriving and efficient workplace.\",\n",
    "#     \"The role of communication in the workplace cannot be overlooked. It serves as the foundation for successful teamwork and organizational growth. When team members share information clearly, it promotes a collaborative atmosphere and reduces the risk of errors or misinterpretations. Strong communication is also vital in building relationships, resolving issues, and making sure everyone is on the same page. Whether it's verbal exchanges or written correspondence, honing your ability to communicate well is vital for fostering an effective work environment.\",\n",
    "#     \"Communication within the workplace is a vital element for success. Clear and open communication promotes a cooperative and efficient atmosphere, helping team members to better understand each others ideas and work toward common goals. It reduces confusion, builds trust, and allows for smoother problem-solving when conflicts arise. By conveying thoughts and expectations effectively, individuals can create stronger working relationships and a productive team dynamic. Whether through emails, phone calls, or face-to-face interactions, mastering communication techniques is key for professional achievement.\",\n",
    "# ]\n",
    "\n",
    "input_strs = [\"hi there\", \"hi\", \"hello\", \"yo whatup\"]\n",
    "\n",
    "# input_strs = [\"This is a sample text with lots of repetition.\", \n",
    "#                 \"This is a sample text with lots of repetition.\",\n",
    "#                 \"This is a sample text with lots of repetition.\"]\n",
    "\n",
    "ensemble_diversity(input_strs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-21 00:21:27,328 [INFO] ember.core.registry.model.providers.openai.openai_provider: OpenAI forward invoked\n",
      "2025-03-21 00:21:27,340 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'timeout': 30, 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'Tell me a funny joke. Keep it concise.'}], 'model': 'gpt-4o', 'max_completion_tokens': 512, 'temperature': None}}\n",
      "2025-03-21 00:21:27,343 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "2025-03-21 00:21:27,348 [DEBUG] httpcore.connection: close.started\n",
      "2025-03-21 00:21:27,350 [DEBUG] httpcore.connection: close.complete\n",
      "2025-03-21 00:21:27,351 [DEBUG] httpcore.connection: connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=30 socket_options=None\n",
      "2025-03-21 00:21:27,391 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f16edef6d50>\n",
      "2025-03-21 00:21:27,393 [DEBUG] httpcore.connection: start_tls.started ssl_context=<ssl.SSLContext object at 0x7f16a96ed910> server_hostname='api.openai.com' timeout=30\n",
      "2025-03-21 00:21:27,405 [DEBUG] httpcore.connection: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f16edee5bd0>\n",
      "2025-03-21 00:21:27,407 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>\n",
      "2025-03-21 00:21:27,410 [DEBUG] httpcore.http11: send_request_headers.complete\n",
      "2025-03-21 00:21:27,412 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>\n",
      "2025-03-21 00:21:27,415 [DEBUG] httpcore.http11: send_request_body.complete\n",
      "2025-03-21 00:21:27,417 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>\n",
      "2025-03-21 00:21:27,854 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 21 Mar 2025 07:21:28 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-iqhmndueuqg2ljzblqkr2tgh'), (b'openai-processing-ms', b'375'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'50000'), (b'x-ratelimit-limit-tokens', b'150000000'), (b'x-ratelimit-remaining-requests', b'49999'), (b'x-ratelimit-remaining-tokens', b'149999988'), (b'x-ratelimit-reset-requests', b'1ms'), (b'x-ratelimit-reset-tokens', b'0s'), (b'x-request-id', b'req_a7db3170b0524e33464f32cef401550f'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'923bb14c9ea65c1d-SJC'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2025-03-21 00:21:27,856 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-21 00:21:27,858 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>\n",
      "2025-03-21 00:21:27,862 [DEBUG] httpcore.http11: receive_response_body.complete\n",
      "2025-03-21 00:21:27,864 [DEBUG] httpcore.http11: response_closed.started\n",
      "2025-03-21 00:21:27,866 [DEBUG] httpcore.http11: response_closed.complete\n",
      "2025-03-21 00:21:27,868 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Fri, 21 Mar 2025 07:21:28 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-iqhmndueuqg2ljzblqkr2tgh', 'openai-processing-ms': '375', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '50000', 'x-ratelimit-limit-tokens': '150000000', 'x-ratelimit-remaining-requests': '49999', 'x-ratelimit-remaining-tokens': '149999988', 'x-ratelimit-reset-requests': '1ms', 'x-ratelimit-reset-tokens': '0s', 'x-request-id': 'req_a7db3170b0524e33464f32cef401550f', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '923bb14c9ea65c1d-SJC', 'content-encoding': 'br', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "2025-03-21 00:21:27,869 [DEBUG] openai._base_client: request_id: req_a7db3170b0524e33464f32cef401550f\n",
      "2025-03-21 00:21:27,871 [INFO] ember.core.registry.model.providers.openai.openai_provider: OpenAI forward invoked\n",
      "2025-03-21 00:21:27,875 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'timeout': 30, 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'Tell me a funny joke. Keep it concise.'}], 'model': 'gpt-4o', 'max_completion_tokens': 512, 'temperature': None}}\n",
      "2025-03-21 00:21:27,877 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "2025-03-21 00:21:27,878 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>\n",
      "2025-03-21 00:21:27,882 [DEBUG] httpcore.http11: send_request_headers.complete\n",
      "2025-03-21 00:21:27,885 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>\n",
      "2025-03-21 00:21:27,887 [DEBUG] httpcore.http11: send_request_body.complete\n",
      "2025-03-21 00:21:27,888 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joke 0: [Why don't skeletons fight each other? They don't have the guts!]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-21 00:21:28,285 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 21 Mar 2025 07:21:28 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-iqhmndueuqg2ljzblqkr2tgh'), (b'openai-processing-ms', b'351'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'50000'), (b'x-ratelimit-limit-tokens', b'150000000'), (b'x-ratelimit-remaining-requests', b'49999'), (b'x-ratelimit-remaining-tokens', b'149999987'), (b'x-ratelimit-reset-requests', b'1ms'), (b'x-ratelimit-reset-tokens', b'0s'), (b'x-request-id', b'req_1e219a2e3ce8c441aab4f3e57c0a654f'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'923bb14f88c65c1d-SJC'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2025-03-21 00:21:28,286 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-21 00:21:28,287 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>\n",
      "2025-03-21 00:21:28,289 [DEBUG] httpcore.http11: receive_response_body.complete\n",
      "2025-03-21 00:21:28,290 [DEBUG] httpcore.http11: response_closed.started\n",
      "2025-03-21 00:21:28,291 [DEBUG] httpcore.http11: response_closed.complete\n",
      "2025-03-21 00:21:28,293 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Fri, 21 Mar 2025 07:21:28 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-iqhmndueuqg2ljzblqkr2tgh', 'openai-processing-ms': '351', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '50000', 'x-ratelimit-limit-tokens': '150000000', 'x-ratelimit-remaining-requests': '49999', 'x-ratelimit-remaining-tokens': '149999987', 'x-ratelimit-reset-requests': '1ms', 'x-ratelimit-reset-tokens': '0s', 'x-request-id': 'req_1e219a2e3ce8c441aab4f3e57c0a654f', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '923bb14f88c65c1d-SJC', 'content-encoding': 'br', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "2025-03-21 00:21:28,293 [DEBUG] openai._base_client: request_id: req_1e219a2e3ce8c441aab4f3e57c0a654f\n",
      "2025-03-21 00:21:28,296 [INFO] ember.core.registry.model.providers.openai.openai_provider: OpenAI forward invoked\n",
      "2025-03-21 00:21:28,306 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'timeout': 30, 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'Tell me a funny joke. Keep it concise.'}], 'model': 'gpt-4o', 'max_completion_tokens': 512, 'temperature': None}}\n",
      "2025-03-21 00:21:28,310 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "2025-03-21 00:21:28,314 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>\n",
      "2025-03-21 00:21:28,316 [DEBUG] httpcore.http11: send_request_headers.complete\n",
      "2025-03-21 00:21:28,323 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>\n",
      "2025-03-21 00:21:28,328 [DEBUG] httpcore.http11: send_request_body.complete\n",
      "2025-03-21 00:21:28,331 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joke 1: [Why don't skeletons fight each other? They don't have the guts.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-21 00:21:28,832 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 21 Mar 2025 07:21:29 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-iqhmndueuqg2ljzblqkr2tgh'), (b'openai-processing-ms', b'449'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'50000'), (b'x-ratelimit-limit-tokens', b'150000000'), (b'x-ratelimit-remaining-requests', b'49999'), (b'x-ratelimit-remaining-tokens', b'149999987'), (b'x-ratelimit-reset-requests', b'1ms'), (b'x-ratelimit-reset-tokens', b'0s'), (b'x-request-id', b'req_62cfe73bcae00e48f66067daa60b9a0f'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'923bb1525b025c1d-SJC'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2025-03-21 00:21:28,835 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-21 00:21:28,839 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>\n",
      "2025-03-21 00:21:28,844 [DEBUG] httpcore.http11: receive_response_body.complete\n",
      "2025-03-21 00:21:28,845 [DEBUG] httpcore.http11: response_closed.started\n",
      "2025-03-21 00:21:28,847 [DEBUG] httpcore.http11: response_closed.complete\n",
      "2025-03-21 00:21:28,848 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Fri, 21 Mar 2025 07:21:29 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-iqhmndueuqg2ljzblqkr2tgh', 'openai-processing-ms': '449', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '50000', 'x-ratelimit-limit-tokens': '150000000', 'x-ratelimit-remaining-requests': '49999', 'x-ratelimit-remaining-tokens': '149999987', 'x-ratelimit-reset-requests': '1ms', 'x-ratelimit-reset-tokens': '0s', 'x-request-id': 'req_62cfe73bcae00e48f66067daa60b9a0f', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '923bb1525b025c1d-SJC', 'content-encoding': 'br', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "2025-03-21 00:21:28,850 [DEBUG] openai._base_client: request_id: req_62cfe73bcae00e48f66067daa60b9a0f\n",
      "2025-03-21 00:21:28,854 [INFO] ember.core.registry.model.providers.openai.openai_provider: OpenAI forward invoked\n",
      "2025-03-21 00:21:28,861 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'timeout': 30, 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'Tell me a funny joke. Keep it concise.'}], 'model': 'gpt-4o', 'max_completion_tokens': 512, 'temperature': None}}\n",
      "2025-03-21 00:21:28,863 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "2025-03-21 00:21:28,865 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>\n",
      "2025-03-21 00:21:28,866 [DEBUG] httpcore.http11: send_request_headers.complete\n",
      "2025-03-21 00:21:28,867 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>\n",
      "2025-03-21 00:21:28,868 [DEBUG] httpcore.http11: send_request_body.complete\n",
      "2025-03-21 00:21:28,869 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joke 2: [Why did the scarecrow win an award? Because he was outstanding in his field!]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-21 00:21:29,612 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 21 Mar 2025 07:21:29 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-iqhmndueuqg2ljzblqkr2tgh'), (b'openai-processing-ms', b'654'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'50000'), (b'x-ratelimit-limit-tokens', b'150000000'), (b'x-ratelimit-remaining-requests', b'49999'), (b'x-ratelimit-remaining-tokens', b'149999987'), (b'x-ratelimit-reset-requests', b'1ms'), (b'x-ratelimit-reset-tokens', b'0s'), (b'x-request-id', b'req_c81335d39ba9bd3c52cdd33e341a3f5f'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'923bb155bdd35c1d-SJC'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2025-03-21 00:21:29,615 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-21 00:21:29,616 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>\n",
      "2025-03-21 00:21:29,620 [DEBUG] httpcore.http11: receive_response_body.complete\n",
      "2025-03-21 00:21:29,621 [DEBUG] httpcore.http11: response_closed.started\n",
      "2025-03-21 00:21:29,623 [DEBUG] httpcore.http11: response_closed.complete\n",
      "2025-03-21 00:21:29,624 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Fri, 21 Mar 2025 07:21:29 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-iqhmndueuqg2ljzblqkr2tgh', 'openai-processing-ms': '654', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '50000', 'x-ratelimit-limit-tokens': '150000000', 'x-ratelimit-remaining-requests': '49999', 'x-ratelimit-remaining-tokens': '149999987', 'x-ratelimit-reset-requests': '1ms', 'x-ratelimit-reset-tokens': '0s', 'x-request-id': 'req_c81335d39ba9bd3c52cdd33e341a3f5f', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '923bb155bdd35c1d-SJC', 'content-encoding': 'br', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "2025-03-21 00:21:29,625 [DEBUG] openai._base_client: request_id: req_c81335d39ba9bd3c52cdd33e341a3f5f\n",
      "2025-03-21 00:21:29,628 [INFO] ember.core.registry.model.providers.openai.openai_provider: OpenAI forward invoked\n",
      "2025-03-21 00:21:29,632 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'timeout': 30, 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'Tell me a funny joke. Keep it concise.'}], 'model': 'gpt-4o', 'max_completion_tokens': 512, 'temperature': None}}\n",
      "2025-03-21 00:21:29,633 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "2025-03-21 00:21:29,635 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>\n",
      "2025-03-21 00:21:29,638 [DEBUG] httpcore.http11: send_request_headers.complete\n",
      "2025-03-21 00:21:29,639 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>\n",
      "2025-03-21 00:21:29,641 [DEBUG] httpcore.http11: send_request_body.complete\n",
      "2025-03-21 00:21:29,642 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joke 3: [Why dont scientists trust atoms? Because they make up everything!]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-21 00:21:30,073 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 21 Mar 2025 07:21:30 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-iqhmndueuqg2ljzblqkr2tgh'), (b'openai-processing-ms', b'384'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'50000'), (b'x-ratelimit-limit-tokens', b'150000000'), (b'x-ratelimit-remaining-requests', b'49999'), (b'x-ratelimit-remaining-tokens', b'149999987'), (b'x-ratelimit-reset-requests', b'1ms'), (b'x-ratelimit-reset-tokens', b'0s'), (b'x-request-id', b'req_09b2adf96a48a99fc2ff344e924d2288'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'923bb15a89135c1d-SJC'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2025-03-21 00:21:30,075 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-21 00:21:30,076 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>\n",
      "2025-03-21 00:21:30,079 [DEBUG] httpcore.http11: receive_response_body.complete\n",
      "2025-03-21 00:21:30,081 [DEBUG] httpcore.http11: response_closed.started\n",
      "2025-03-21 00:21:30,082 [DEBUG] httpcore.http11: response_closed.complete\n",
      "2025-03-21 00:21:30,084 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Fri, 21 Mar 2025 07:21:30 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-iqhmndueuqg2ljzblqkr2tgh', 'openai-processing-ms': '384', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '50000', 'x-ratelimit-limit-tokens': '150000000', 'x-ratelimit-remaining-requests': '49999', 'x-ratelimit-remaining-tokens': '149999987', 'x-ratelimit-reset-requests': '1ms', 'x-ratelimit-reset-tokens': '0s', 'x-request-id': 'req_09b2adf96a48a99fc2ff344e924d2288', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '923bb15a89135c1d-SJC', 'content-encoding': 'br', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "2025-03-21 00:21:30,085 [DEBUG] openai._base_client: request_id: req_09b2adf96a48a99fc2ff344e924d2288\n",
      "2025-03-21 00:21:30,086 [INFO] ember.core.registry.model.providers.openai.openai_provider: OpenAI forward invoked\n",
      "2025-03-21 00:21:30,091 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'timeout': 30, 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'Tell me a funny joke. Keep it concise.'}], 'model': 'gpt-4o', 'max_completion_tokens': 512, 'temperature': None}}\n",
      "2025-03-21 00:21:30,093 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "2025-03-21 00:21:30,095 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>\n",
      "2025-03-21 00:21:30,098 [DEBUG] httpcore.http11: send_request_headers.complete\n",
      "2025-03-21 00:21:30,098 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>\n",
      "2025-03-21 00:21:30,100 [DEBUG] httpcore.http11: send_request_body.complete\n",
      "2025-03-21 00:21:30,101 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joke 4: [Why don't skeletons fight each other? They don't have the guts!]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-21 00:21:30,742 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 21 Mar 2025 07:21:31 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-iqhmndueuqg2ljzblqkr2tgh'), (b'openai-processing-ms', b'601'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'50000'), (b'x-ratelimit-limit-tokens', b'150000000'), (b'x-ratelimit-remaining-requests', b'49999'), (b'x-ratelimit-remaining-tokens', b'149999987'), (b'x-ratelimit-reset-requests', b'1ms'), (b'x-ratelimit-reset-tokens', b'0s'), (b'x-request-id', b'req_b762852f0cc93993624ba07c2e67ba9f'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'923bb15d6b105c1d-SJC'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2025-03-21 00:21:30,745 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-21 00:21:30,749 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>\n",
      "2025-03-21 00:21:30,755 [DEBUG] httpcore.http11: receive_response_body.complete\n",
      "2025-03-21 00:21:30,758 [DEBUG] httpcore.http11: response_closed.started\n",
      "2025-03-21 00:21:30,761 [DEBUG] httpcore.http11: response_closed.complete\n",
      "2025-03-21 00:21:30,763 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Fri, 21 Mar 2025 07:21:31 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-iqhmndueuqg2ljzblqkr2tgh', 'openai-processing-ms': '601', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '50000', 'x-ratelimit-limit-tokens': '150000000', 'x-ratelimit-remaining-requests': '49999', 'x-ratelimit-remaining-tokens': '149999987', 'x-ratelimit-reset-requests': '1ms', 'x-ratelimit-reset-tokens': '0s', 'x-request-id': 'req_b762852f0cc93993624ba07c2e67ba9f', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '923bb15d6b105c1d-SJC', 'content-encoding': 'br', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "2025-03-21 00:21:30,767 [DEBUG] openai._base_client: request_id: req_b762852f0cc93993624ba07c2e67ba9f\n",
      "2025-03-21 00:21:30,773 [INFO] ember.core.registry.model.providers.openai.openai_provider: OpenAI forward invoked\n",
      "2025-03-21 00:21:30,785 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'timeout': 30, 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'Tell me a funny joke. Keep it concise.'}], 'model': 'gpt-4o', 'max_completion_tokens': 512, 'temperature': None}}\n",
      "2025-03-21 00:21:30,788 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "2025-03-21 00:21:30,795 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>\n",
      "2025-03-21 00:21:30,797 [DEBUG] httpcore.http11: send_request_headers.complete\n",
      "2025-03-21 00:21:30,801 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>\n",
      "2025-03-21 00:21:30,807 [DEBUG] httpcore.http11: send_request_body.complete\n",
      "2025-03-21 00:21:30,813 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joke 5: [Why don't skeletons fight each other?  \n",
      "They don't have the guts.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-21 00:21:31,353 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 21 Mar 2025 07:21:31 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-iqhmndueuqg2ljzblqkr2tgh'), (b'openai-processing-ms', b'471'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'50000'), (b'x-ratelimit-limit-tokens', b'150000000'), (b'x-ratelimit-remaining-requests', b'49999'), (b'x-ratelimit-remaining-tokens', b'149999987'), (b'x-ratelimit-reset-requests', b'1ms'), (b'x-ratelimit-reset-tokens', b'0s'), (b'x-request-id', b'req_ba026095394aadcd39b29c1bb1ce6973'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'923bb161cdd35c1d-SJC'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2025-03-21 00:21:31,357 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-21 00:21:31,360 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>\n",
      "2025-03-21 00:21:31,363 [DEBUG] httpcore.http11: receive_response_body.complete\n",
      "2025-03-21 00:21:31,364 [DEBUG] httpcore.http11: response_closed.started\n",
      "2025-03-21 00:21:31,365 [DEBUG] httpcore.http11: response_closed.complete\n",
      "2025-03-21 00:21:31,366 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Fri, 21 Mar 2025 07:21:31 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-iqhmndueuqg2ljzblqkr2tgh', 'openai-processing-ms': '471', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '50000', 'x-ratelimit-limit-tokens': '150000000', 'x-ratelimit-remaining-requests': '49999', 'x-ratelimit-remaining-tokens': '149999987', 'x-ratelimit-reset-requests': '1ms', 'x-ratelimit-reset-tokens': '0s', 'x-request-id': 'req_ba026095394aadcd39b29c1bb1ce6973', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '923bb161cdd35c1d-SJC', 'content-encoding': 'br', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "2025-03-21 00:21:31,368 [DEBUG] openai._base_client: request_id: req_ba026095394aadcd39b29c1bb1ce6973\n",
      "2025-03-21 00:21:31,372 [INFO] ember.core.registry.model.providers.openai.openai_provider: OpenAI forward invoked\n",
      "2025-03-21 00:21:31,381 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'timeout': 30, 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'Tell me a funny joke. Keep it concise.'}], 'model': 'gpt-4o', 'max_completion_tokens': 512, 'temperature': None}}\n",
      "2025-03-21 00:21:31,385 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "2025-03-21 00:21:31,389 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>\n",
      "2025-03-21 00:21:31,398 [DEBUG] httpcore.http11: send_request_headers.complete\n",
      "2025-03-21 00:21:31,401 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>\n",
      "2025-03-21 00:21:31,408 [DEBUG] httpcore.http11: send_request_body.complete\n",
      "2025-03-21 00:21:31,410 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joke 6: [Why don't scientists trust atoms? Because they make up everything!]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-21 00:21:31,944 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 21 Mar 2025 07:21:32 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-iqhmndueuqg2ljzblqkr2tgh'), (b'openai-processing-ms', b'444'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'50000'), (b'x-ratelimit-limit-tokens', b'150000000'), (b'x-ratelimit-remaining-requests', b'49999'), (b'x-ratelimit-remaining-tokens', b'149999987'), (b'x-ratelimit-reset-requests', b'1ms'), (b'x-ratelimit-reset-tokens', b'0s'), (b'x-request-id', b'req_d8bd19c90a2b876b62adaad8f0a58b70'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'923bb16588705c1d-SJC'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2025-03-21 00:21:31,945 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-21 00:21:31,947 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>\n",
      "2025-03-21 00:21:31,951 [DEBUG] httpcore.http11: receive_response_body.complete\n",
      "2025-03-21 00:21:31,952 [DEBUG] httpcore.http11: response_closed.started\n",
      "2025-03-21 00:21:31,953 [DEBUG] httpcore.http11: response_closed.complete\n",
      "2025-03-21 00:21:31,955 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Fri, 21 Mar 2025 07:21:32 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-iqhmndueuqg2ljzblqkr2tgh', 'openai-processing-ms': '444', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '50000', 'x-ratelimit-limit-tokens': '150000000', 'x-ratelimit-remaining-requests': '49999', 'x-ratelimit-remaining-tokens': '149999987', 'x-ratelimit-reset-requests': '1ms', 'x-ratelimit-reset-tokens': '0s', 'x-request-id': 'req_d8bd19c90a2b876b62adaad8f0a58b70', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '923bb16588705c1d-SJC', 'content-encoding': 'br', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "2025-03-21 00:21:31,956 [DEBUG] openai._base_client: request_id: req_d8bd19c90a2b876b62adaad8f0a58b70\n",
      "2025-03-21 00:21:31,958 [INFO] ember.core.registry.model.providers.openai.openai_provider: OpenAI forward invoked\n",
      "2025-03-21 00:21:31,965 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'timeout': 30, 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'Tell me a funny joke. Keep it concise.'}], 'model': 'gpt-4o', 'max_completion_tokens': 512, 'temperature': None}}\n",
      "2025-03-21 00:21:31,970 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "2025-03-21 00:21:31,973 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>\n",
      "2025-03-21 00:21:31,976 [DEBUG] httpcore.http11: send_request_headers.complete\n",
      "2025-03-21 00:21:31,978 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>\n",
      "2025-03-21 00:21:31,981 [DEBUG] httpcore.http11: send_request_body.complete\n",
      "2025-03-21 00:21:31,986 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joke 7: [Why don't scientists trust atoms?\n",
      "\n",
      "Because they make up everything!]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-21 00:21:32,559 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 21 Mar 2025 07:21:32 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-iqhmndueuqg2ljzblqkr2tgh'), (b'openai-processing-ms', b'519'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'50000'), (b'x-ratelimit-limit-tokens', b'150000000'), (b'x-ratelimit-remaining-requests', b'49999'), (b'x-ratelimit-remaining-tokens', b'149999987'), (b'x-ratelimit-reset-requests', b'1ms'), (b'x-ratelimit-reset-tokens', b'0s'), (b'x-request-id', b'req_1aea1c3c615b3eb8ed8e75303a68f56a'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'923bb1692b0b5c1d-SJC'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2025-03-21 00:21:32,561 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-21 00:21:32,564 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>\n",
      "2025-03-21 00:21:32,568 [DEBUG] httpcore.http11: receive_response_body.complete\n",
      "2025-03-21 00:21:32,570 [DEBUG] httpcore.http11: response_closed.started\n",
      "2025-03-21 00:21:32,573 [DEBUG] httpcore.http11: response_closed.complete\n",
      "2025-03-21 00:21:32,573 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Fri, 21 Mar 2025 07:21:32 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-iqhmndueuqg2ljzblqkr2tgh', 'openai-processing-ms': '519', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '50000', 'x-ratelimit-limit-tokens': '150000000', 'x-ratelimit-remaining-requests': '49999', 'x-ratelimit-remaining-tokens': '149999987', 'x-ratelimit-reset-requests': '1ms', 'x-ratelimit-reset-tokens': '0s', 'x-request-id': 'req_1aea1c3c615b3eb8ed8e75303a68f56a', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '923bb1692b0b5c1d-SJC', 'content-encoding': 'br', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "2025-03-21 00:21:32,575 [DEBUG] openai._base_client: request_id: req_1aea1c3c615b3eb8ed8e75303a68f56a\n",
      "2025-03-21 00:21:32,580 [INFO] ember.core.registry.model.providers.openai.openai_provider: OpenAI forward invoked\n",
      "2025-03-21 00:21:32,595 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'timeout': 30, 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'Tell me a funny joke. Keep it concise.'}], 'model': 'gpt-4o', 'max_completion_tokens': 512, 'temperature': None}}\n",
      "2025-03-21 00:21:32,598 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "2025-03-21 00:21:32,601 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>\n",
      "2025-03-21 00:21:32,604 [DEBUG] httpcore.http11: send_request_headers.complete\n",
      "2025-03-21 00:21:32,604 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>\n",
      "2025-03-21 00:21:32,607 [DEBUG] httpcore.http11: send_request_body.complete\n",
      "2025-03-21 00:21:32,608 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joke 8: [Why did the scarecrow win an award? Because he was outstanding in his field!]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-21 00:21:33,085 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 21 Mar 2025 07:21:33 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-iqhmndueuqg2ljzblqkr2tgh'), (b'openai-processing-ms', b'424'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'50000'), (b'x-ratelimit-limit-tokens', b'150000000'), (b'x-ratelimit-remaining-requests', b'49999'), (b'x-ratelimit-remaining-tokens', b'149999987'), (b'x-ratelimit-reset-requests', b'1ms'), (b'x-ratelimit-reset-tokens', b'0s'), (b'x-request-id', b'req_62bf812cc022bb70e422a7dc80b83749'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'923bb16d1dac5c1d-SJC'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2025-03-21 00:21:33,086 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-21 00:21:33,088 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>\n",
      "2025-03-21 00:21:33,091 [DEBUG] httpcore.http11: receive_response_body.complete\n",
      "2025-03-21 00:21:33,092 [DEBUG] httpcore.http11: response_closed.started\n",
      "2025-03-21 00:21:33,093 [DEBUG] httpcore.http11: response_closed.complete\n",
      "2025-03-21 00:21:33,094 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Fri, 21 Mar 2025 07:21:33 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-iqhmndueuqg2ljzblqkr2tgh', 'openai-processing-ms': '424', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '50000', 'x-ratelimit-limit-tokens': '150000000', 'x-ratelimit-remaining-requests': '49999', 'x-ratelimit-remaining-tokens': '149999987', 'x-ratelimit-reset-requests': '1ms', 'x-ratelimit-reset-tokens': '0s', 'x-request-id': 'req_62bf812cc022bb70e422a7dc80b83749', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '923bb16d1dac5c1d-SJC', 'content-encoding': 'br', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "2025-03-21 00:21:33,095 [DEBUG] openai._base_client: request_id: req_62bf812cc022bb70e422a7dc80b83749\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joke 9: [Why don't scientists trust atoms?\n",
      "\n",
      "Because they make up everything!]\n",
      "-----\n",
      "DiversityScoringEvaluator result: EvaluationResult(is_correct=True, score=2.919, metadata={'responses': [\"Why don't skeletons fight each other? They don't have the guts!\", \"Why don't skeletons fight each other? They don't have the guts.\", 'Why did the scarecrow win an award? Because he was outstanding in his field!', 'Why dont scientists trust atoms? Because they make up everything!', \"Why don't skeletons fight each other? They don't have the guts!\", \"Why don't skeletons fight each other?  \\nThey don't have the guts.\", \"Why don't scientists trust atoms? Because they make up everything!\", \"Why don't scientists trust atoms?\\n\\nBecause they make up everything!\", 'Why did the scarecrow win an award? Because he was outstanding in his field!', \"Why don't scientists trust atoms?\\n\\nBecause they make up everything!\"]})\n",
      "SimilarityScore between ind1=0 and ind2=1: 0.9998557731781514\n",
      "SimilarityScore between ind1=1 and ind2=2: 0.8516952804862096\n",
      "SimilarityScore between ind1=2 and ind2=3: 0.12224781375093245\n",
      "SimilarityScore between ind1=3 and ind2=4: 0.13899372940048665\n",
      "SimilarityScore between ind1=4 and ind2=5: 0.930451468399891\n",
      "SimilarityScore between ind1=5 and ind2=6: 0.9066215700385928\n",
      "SimilarityScore between ind1=6 and ind2=7: 0.9524292508952135\n",
      "SimilarityScore between ind1=7 and ind2=8: 0.8506419386731088\n",
      "SimilarityScore between ind1=8 and ind2=9: 0.8506419386731088\n",
      "SimilarityScore between ind1=9 and ind2=0: 0.8843819811752456\n",
      "Avg cosine similarity: 0.748796074467094\n",
      "diversity cosine-sim inverse: 0.25120392553290605\n",
      "edit-dist score: 0.4794\n",
      "-------------------------------\n",
      "possible diversity score: 1.2165215583179603\n"
     ]
    }
   ],
   "source": [
    "num_jokes = 10\n",
    "responses = []\n",
    "\n",
    "for i in range(num_jokes):\n",
    "    res = llm(prompt=\"Tell me a funny joke. Keep it concise.\", model_id=\"openai:gpt-4o\").data\n",
    "    responses.append(res)\n",
    "    print(f\"Joke {i}: [{res}]\")\n",
    "\n",
    "print(\"-----\")\n",
    "ensemble_diversity(responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-21 00:20:51,760 [INFO] ember.core.registry.model.providers.openai.openai_provider: OpenAI forward invoked\n",
      "2025-03-21 00:20:51,776 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'timeout': 30, 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': \"Tell me 10 jokes. make them split with '||'. Don't say anything else besides the joke. \"}], 'model': 'gpt-4o', 'max_completion_tokens': 512, 'temperature': None}}\n",
      "2025-03-21 00:20:51,780 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "2025-03-21 00:20:51,786 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>\n",
      "2025-03-21 00:20:51,790 [DEBUG] httpcore.http11: send_request_headers.complete\n",
      "2025-03-21 00:20:51,792 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>\n",
      "2025-03-21 00:20:51,798 [DEBUG] httpcore.http11: send_request_body.complete\n",
      "2025-03-21 00:20:51,800 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>\n",
      "2025-03-21 00:20:53,925 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 21 Mar 2025 07:20:54 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-iqhmndueuqg2ljzblqkr2tgh'), (b'openai-processing-ms', b'2074'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'50000'), (b'x-ratelimit-limit-tokens', b'150000000'), (b'x-ratelimit-remaining-requests', b'49999'), (b'x-ratelimit-remaining-tokens', b'149999976'), (b'x-ratelimit-reset-requests', b'1ms'), (b'x-ratelimit-reset-tokens', b'0s'), (b'x-request-id', b'req_fc11eea25331eac4ebdbdc434053f357'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'923bb06dfcffd001-SJC'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2025-03-21 00:20:53,928 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-21 00:20:53,930 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>\n",
      "2025-03-21 00:20:53,934 [DEBUG] httpcore.http11: receive_response_body.complete\n",
      "2025-03-21 00:20:53,935 [DEBUG] httpcore.http11: response_closed.started\n",
      "2025-03-21 00:20:53,936 [DEBUG] httpcore.http11: response_closed.complete\n",
      "2025-03-21 00:20:53,938 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Fri, 21 Mar 2025 07:20:54 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-iqhmndueuqg2ljzblqkr2tgh', 'openai-processing-ms': '2074', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '50000', 'x-ratelimit-limit-tokens': '150000000', 'x-ratelimit-remaining-requests': '49999', 'x-ratelimit-remaining-tokens': '149999976', 'x-ratelimit-reset-requests': '1ms', 'x-ratelimit-reset-tokens': '0s', 'x-request-id': 'req_fc11eea25331eac4ebdbdc434053f357', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '923bb06dfcffd001-SJC', 'content-encoding': 'br', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "2025-03-21 00:20:53,940 [DEBUG] openai._base_client: request_id: req_fc11eea25331eac4ebdbdc434053f357\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joke 0: [Why did the scarecrow win an award? Because he was outstanding in his field! ]\n",
      "Joke 1: [ Parallel lines have so much in common. Its a shame theyll never meet. ]\n",
      "Joke 2: [ Why dont skeletons fight each other? They dont have the guts. ]\n",
      "Joke 3: [ What do you call fake spaghetti? An impasta! ]\n",
      "Joke 4: [ I would tell you a construction joke, but I'm still working on it. ]\n",
      "Joke 5: [ Why couldn't the bicycle stand up by itself? It was two tired. ]\n",
      "Joke 6: [ Why did the tomato turn red? Because it saw the salad dressing! ]\n",
      "Joke 7: [ What did the ocean say to the beach? Nothing, it just waved. ]\n",
      "Joke 8: [ Why did the math book look sad? Because it had too many problems. ]\n",
      "Joke 9: [ I told my computer I needed a break, and now it won't stop sending me kit-kat ads!]\n",
      "-----\n",
      "DiversityScoringEvaluator result: EvaluationResult(is_correct=True, score=1.513, metadata={'responses': ['Why did the scarecrow win an award? Because he was outstanding in his field! ', ' Parallel lines have so much in common. Its a shame theyll never meet. ', ' Why dont skeletons fight each other? They dont have the guts. ', ' What do you call fake spaghetti? An impasta! ', \" I would tell you a construction joke, but I'm still working on it. \", \" Why couldn't the bicycle stand up by itself? It was two tired. \", ' Why did the tomato turn red? Because it saw the salad dressing! ', ' What did the ocean say to the beach? Nothing, it just waved. ', ' Why did the math book look sad? Because it had too many problems. ', \" I told my computer I needed a break, and now it won't stop sending me kit-kat ads!\"]})\n",
      "SimilarityScore between ind1=0 and ind2=1: 0.23585869748408375\n",
      "SimilarityScore between ind1=1 and ind2=2: 0.030690112807883127\n",
      "SimilarityScore between ind1=2 and ind2=3: 0.08483849065288684\n",
      "SimilarityScore between ind1=3 and ind2=4: 0.750109080659053\n",
      "SimilarityScore between ind1=4 and ind2=5: 0.894508987836746\n",
      "SimilarityScore between ind1=5 and ind2=6: 0.9046943831161538\n",
      "SimilarityScore between ind1=6 and ind2=7: 0.8888453958820549\n",
      "SimilarityScore between ind1=7 and ind2=8: 0.8324994273641826\n",
      "SimilarityScore between ind1=8 and ind2=9: 0.7777342312519292\n",
      "SimilarityScore between ind1=9 and ind2=0: 0.8589345591870938\n",
      "Avg cosine similarity: 0.6258713366242067\n",
      "diversity cosine-sim inverse: 0.3741286633757933\n",
      "edit-dist score: 0.7251\n",
      "-------------------------------\n",
      "possible diversity score: 0.8707337636418844\n"
     ]
    }
   ],
   "source": [
    "prompts = 1\n",
    "responses = []\n",
    "\n",
    "for i in range(prompts):\n",
    "    res = llm(prompt=\"Tell me 10 jokes. make them split with \\'||\\'. Don't say anything else besides the joke. \", model_id=\"openai:gpt-4o\").data.split('||')\n",
    "    responses += res\n",
    "\n",
    "if prompts == 1 and len(responses) > 1:\n",
    "    for i in range(len(responses)):\n",
    "        print(f\"Joke {i}: [{responses[i]}]\")\n",
    "\n",
    "print(\"-----\")\n",
    "ensemble_diversity(responses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "## Improvements TODO\n",
    "- Merge all functions\n",
    "- fix ensembling\n",
    "## Potential other cases to explore\n",
    "- work ensembling all \"diversity\" related metrics \n",
    "  - add more metrics\n",
    "  - tune added metrics\n",
    "- combination of validation/hallucination metric + ensembled diversity metric -> score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ember_upgrade",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
