{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:ember.core.registry.model.providers.anthropic.anthropic_discovery:Error fetching Anthropic models via REST API: 401 Client Error: Unauthorized for url: https://api.anthropic.com/v1/models\n",
      "/root/anaconda3/envs/ember_upgrade/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1742550067.907817  410594 check_gcp_environment.cc:61] BIOS data file does not exist or cannot be opened.\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import logging\n",
    "\n",
    "# Set global logging level to ERROR\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "\n",
    "os.environ[\"EMBER_LOGGING_LEVEL\"] = \"ERROR\"\n",
    "\n",
    "# from ember.core.registry.model.model_module.lm import LMModule, LMModuleConfig\n",
    "from ember.core.registry.model.config.settings import initialize_registry\n",
    "from ember.core.registry.model.base.services.model_service import ModelService"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:ember.core.registry.model.providers.anthropic.anthropic_discovery:Error fetching Anthropic models via REST API: 401 Client Error: Unauthorized for url: https://api.anthropic.com/v1/models\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['openai:gpt-4o-mini-transcribe', 'openai:gpt-4o-audio-preview-2024-12-17', 'openai:dall-e-3', 'openai:dall-e-2', 'openai:gpt-4o-audio-preview-2024-10-01', 'openai:gpt-4o-realtime-preview-2024-10-01', 'openai:gpt-4o-audio-preview', 'openai:text-embedding-3-large', 'openai:gpt-4', 'openai:gpt-4o-mini-2024-07-18', 'openai:gpt-4o-2024-05-13', 'openai:gpt-4o-realtime-preview', 'openai:gpt-4o-mini', 'openai:gpt-4o-mini-audio-preview', 'openai:gpt-3.5-turbo-instruct-0914', 'openai:gpt-4o-mini-search-preview', 'openai:gpt-3.5-turbo-1106', 'openai:gpt-4o-search-preview', 'openai:gpt-4-turbo', 'openai:gpt-4o-realtime-preview-2024-12-17', 'openai:gpt-3.5-turbo-instruct', 'openai:gpt-3.5-turbo', 'openai:gpt-4-turbo-preview', 'openai:gpt-4o-mini-search-preview-2025-03-11', 'openai:gpt-4o-mini-realtime-preview', 'openai:gpt-3.5-turbo-0125', 'openai:gpt-4o-2024-08-06', 'openai:gpt-4-turbo-2024-04-09', 'openai:gpt-3.5-turbo-16k', 'openai:gpt-4o', 'openai:gpt-4o-mini-realtime-preview-2024-12-17', 'openai:gpt-4-1106-preview', 'openai:text-embedding-ada-002', 'openai:gpt-4-0613', 'openai:gpt-4.5-preview', 'openai:gpt-4.5-preview-2025-02-27', 'openai:gpt-4o-search-preview-2025-03-11', 'openai:gpt-4o-2024-11-20', 'openai:gpt-4o-mini-tts', 'openai:gpt-4-0125-preview', 'openai:gpt-4o-transcribe', 'openai:text-embedding-3-small', 'openai:gpt-4o-mini-audio-preview-2024-12-17', 'anthropic:claude-3-sonnet', 'anthropic:claude-3-opus', 'anthropic:claude-3-haiku', 'anthropic:claude-3.5-sonnet', 'anthropic:claude-3.7-sonnet', 'google:models/gemini-1.0-pro-vision-latest', 'google:models/gemini-pro-vision', 'google:models/gemini-1.5-pro-latest', 'google:models/gemini-1.5-pro-001', 'google:models/gemini-1.5-pro-002', 'google:models/gemini-1.5-pro', 'google:models/gemini-1.5-flash-latest', 'google:models/gemini-1.5-flash-001', 'google:models/gemini-1.5-flash-001-tuning', 'google:models/gemini-1.5-flash', 'google:models/gemini-1.5-flash-002', 'google:models/gemini-1.5-flash-8b', 'google:models/gemini-1.5-flash-8b-001', 'google:models/gemini-1.5-flash-8b-latest', 'google:models/gemini-1.5-flash-8b-exp-0827', 'google:models/gemini-1.5-flash-8b-exp-0924', 'google:models/gemini-2.0-flash-exp', 'google:models/gemini-2.0-flash', 'google:models/gemini-2.0-flash-001', 'google:models/gemini-2.0-flash-exp-image-generation', 'google:models/gemini-2.0-flash-lite-001', 'google:models/gemini-2.0-flash-lite', 'google:models/gemini-2.0-flash-lite-preview-02-05', 'google:models/gemini-2.0-flash-lite-preview', 'google:models/gemini-2.0-pro-exp', 'google:models/gemini-2.0-pro-exp-02-05', 'google:models/gemini-exp-1206', 'google:models/gemini-2.0-flash-thinking-exp-01-21', 'google:models/gemini-2.0-flash-thinking-exp', 'google:models/gemini-2.0-flash-thinking-exp-1219', 'google:models/learnlm-1.5-pro-experimental', 'google:models/gemma-3-27b-it']\n"
     ]
    }
   ],
   "source": [
    "model_registry = initialize_registry()\n",
    "print(model_registry.list_models())\n",
    "llm = ModelService(registry=model_registry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['openai:gpt-4o-mini-transcribe',\n",
       " 'openai:gpt-4o-audio-preview-2024-12-17',\n",
       " 'openai:dall-e-3',\n",
       " 'openai:dall-e-2',\n",
       " 'openai:gpt-4o-audio-preview-2024-10-01',\n",
       " 'openai:gpt-4o-realtime-preview-2024-10-01',\n",
       " 'openai:gpt-4o-audio-preview',\n",
       " 'openai:text-embedding-3-large',\n",
       " 'openai:gpt-4',\n",
       " 'openai:gpt-4o-mini-2024-07-18',\n",
       " 'openai:gpt-4o-2024-05-13',\n",
       " 'openai:gpt-4o-realtime-preview',\n",
       " 'openai:gpt-4o-mini',\n",
       " 'openai:gpt-4o-mini-audio-preview',\n",
       " 'openai:gpt-3.5-turbo-instruct-0914',\n",
       " 'openai:gpt-4o-mini-search-preview',\n",
       " 'openai:gpt-3.5-turbo-1106',\n",
       " 'openai:gpt-4o-search-preview',\n",
       " 'openai:gpt-4-turbo',\n",
       " 'openai:gpt-4o-realtime-preview-2024-12-17',\n",
       " 'openai:gpt-3.5-turbo-instruct',\n",
       " 'openai:gpt-3.5-turbo',\n",
       " 'openai:gpt-4-turbo-preview',\n",
       " 'openai:gpt-4o-mini-search-preview-2025-03-11',\n",
       " 'openai:gpt-4o-mini-realtime-preview',\n",
       " 'openai:gpt-3.5-turbo-0125',\n",
       " 'openai:gpt-4o-2024-08-06',\n",
       " 'openai:gpt-4-turbo-2024-04-09',\n",
       " 'openai:gpt-3.5-turbo-16k',\n",
       " 'openai:gpt-4o',\n",
       " 'openai:gpt-4o-mini-realtime-preview-2024-12-17',\n",
       " 'openai:gpt-4-1106-preview',\n",
       " 'openai:text-embedding-ada-002',\n",
       " 'openai:gpt-4-0613',\n",
       " 'openai:gpt-4.5-preview',\n",
       " 'openai:gpt-4.5-preview-2025-02-27',\n",
       " 'openai:gpt-4o-search-preview-2025-03-11',\n",
       " 'openai:gpt-4o-2024-11-20',\n",
       " 'openai:gpt-4o-mini-tts',\n",
       " 'openai:gpt-4-0125-preview',\n",
       " 'openai:gpt-4o-transcribe',\n",
       " 'openai:text-embedding-3-small',\n",
       " 'openai:gpt-4o-mini-audio-preview-2024-12-17',\n",
       " 'anthropic:claude-3-sonnet',\n",
       " 'anthropic:claude-3-opus',\n",
       " 'anthropic:claude-3-haiku',\n",
       " 'anthropic:claude-3.5-sonnet',\n",
       " 'anthropic:claude-3.7-sonnet',\n",
       " 'google:models/gemini-1.0-pro-vision-latest',\n",
       " 'google:models/gemini-pro-vision',\n",
       " 'google:models/gemini-1.5-pro-latest',\n",
       " 'google:models/gemini-1.5-pro-001',\n",
       " 'google:models/gemini-1.5-pro-002',\n",
       " 'google:models/gemini-1.5-pro',\n",
       " 'google:models/gemini-1.5-flash-latest',\n",
       " 'google:models/gemini-1.5-flash-001',\n",
       " 'google:models/gemini-1.5-flash-001-tuning',\n",
       " 'google:models/gemini-1.5-flash',\n",
       " 'google:models/gemini-1.5-flash-002',\n",
       " 'google:models/gemini-1.5-flash-8b',\n",
       " 'google:models/gemini-1.5-flash-8b-001',\n",
       " 'google:models/gemini-1.5-flash-8b-latest',\n",
       " 'google:models/gemini-1.5-flash-8b-exp-0827',\n",
       " 'google:models/gemini-1.5-flash-8b-exp-0924',\n",
       " 'google:models/gemini-2.0-flash-exp',\n",
       " 'google:models/gemini-2.0-flash',\n",
       " 'google:models/gemini-2.0-flash-001',\n",
       " 'google:models/gemini-2.0-flash-exp-image-generation',\n",
       " 'google:models/gemini-2.0-flash-lite-001',\n",
       " 'google:models/gemini-2.0-flash-lite',\n",
       " 'google:models/gemini-2.0-flash-lite-preview-02-05',\n",
       " 'google:models/gemini-2.0-flash-lite-preview',\n",
       " 'google:models/gemini-2.0-pro-exp',\n",
       " 'google:models/gemini-2.0-pro-exp-02-05',\n",
       " 'google:models/gemini-exp-1206',\n",
       " 'google:models/gemini-2.0-flash-thinking-exp-01-21',\n",
       " 'google:models/gemini-2.0-flash-thinking-exp',\n",
       " 'google:models/gemini-2.0-flash-thinking-exp-1219',\n",
       " 'google:models/learnlm-1.5-pro-experimental',\n",
       " 'google:models/gemma-3-27b-it']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_registry.list_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diversity Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from abc import ABC, abstractmethod\n",
    "from typing import List, Protocol\n",
    "import math\n",
    "\n",
    "\n",
    "################################################################\n",
    "# 1) Embedding Model Interfaces & Implementations\n",
    "################################################################\n",
    "\n",
    "\n",
    "class EmbeddingModel(Protocol):\n",
    "    \"\"\"Interface for embedding models.\n",
    "\n",
    "    This protocol defines the minimal interface required to compute a text\n",
    "    embedding. Implementations may use local models, external APIs, or custom\n",
    "    neural networks.\n",
    "\n",
    "    Methods:\n",
    "        embed_text: Compute the embedding for a given text.\n",
    "    \"\"\"\n",
    "\n",
    "    def embed_text(self, text: str) -> List[float]:\n",
    "        \"\"\"Computes the embedding vector for the provided text.\n",
    "\n",
    "        Args:\n",
    "            text (str): The text to be embedded.\n",
    "\n",
    "        Returns:\n",
    "            List[float]: A list of floats representing the embedding vector.\n",
    "        \"\"\"\n",
    "        ...\n",
    "\n",
    "class Text_Embedding_Ada_002_Model:\n",
    "    \"\"\"Interface for embedding models.\n",
    "\n",
    "    This protocol defines the minimal interface required to compute a text\n",
    "    embedding. Implementations may use local models, external APIs, or custom\n",
    "    neural networks.\n",
    "\n",
    "    Methods:\n",
    "        embed_text: Compute the embedding for a given text.\n",
    "    \"\"\"\n",
    "\n",
    "    def embed_text(self, text: str) -> List[float]:\n",
    "        \"\"\"Computes the embedding vector for the provided text.\n",
    "\n",
    "        Args:\n",
    "            text (str): The text to be embedded.\n",
    "\n",
    "        Returns:\n",
    "            List[float]: A list of floats representing the embedding vector.\n",
    "        \"\"\"\n",
    "        response = llm(model_id=\"openai:text-embedding-ada-002\", prompt=text)\n",
    "        return response.embedding\n",
    "\n",
    "\n",
    "class MockEmbeddingModel:\n",
    "    \"\"\"Mock implementation of an embedding model using naive ASCII encoding.\n",
    "\n",
    "    This simple model converts each character in the text to a normalized ASCII\n",
    "    value. It is intended solely for demonstration and testing purposes.\n",
    "\n",
    "    Methods:\n",
    "        embed_text: Converts text to a sequence of normalized ASCII values.\n",
    "    \"\"\"\n",
    "\n",
    "    def embed_text(self, text: str) -> List[float]:\n",
    "        \"\"\"Embeds text by converting each character to its normalized ASCII code.\n",
    "\n",
    "        Args:\n",
    "            text (str): The input text to be embedded.\n",
    "\n",
    "        Returns:\n",
    "            List[float]: A list of floats representing the embedding. Returns an\n",
    "            empty list if the text is empty.\n",
    "        \"\"\"\n",
    "        if not text:\n",
    "            return []\n",
    "        return [ord(ch) / 256.0 for ch in text]\n",
    "\n",
    "\n",
    "################################################################\n",
    "# 2) Similarity Metric Interface & Implementations\n",
    "################################################################\n",
    "\n",
    "\n",
    "class SimilarityMetric(ABC):\n",
    "    \"\"\"Abstract base class for computing similarity between embedding vectors.\n",
    "\n",
    "    Subclasses must implement the similarity method to calculate a similarity\n",
    "    score between two vectors.\n",
    "    \"\"\"\n",
    "\n",
    "    @abstractmethod\n",
    "    def similarity(self, vec_a: List[float], vec_b: List[float]) -> float:\n",
    "        \"\"\"Calculates the similarity between two embedding vectors.\n",
    "\n",
    "        Args:\n",
    "            vec_a (List[float]): The first embedding vector.\n",
    "            vec_b (List[float]): The second embedding vector.\n",
    "\n",
    "        Returns:\n",
    "            float: The similarity score, typically in the range [0, 1] or [-1, 1].\n",
    "        \"\"\"\n",
    "        ...\n",
    "\n",
    "\n",
    "class CosineSimilarity(SimilarityMetric):\n",
    "    \"\"\"Implementation of cosine similarity for embedding vectors.\n",
    "\n",
    "    The cosine similarity is defined as:\n",
    "        similarity(a, b) = (a · b) / (||a|| * ||b||)\n",
    "\n",
    "    Returns 0.0 if either vector is empty or if any vector's norm is zero.\n",
    "    \"\"\"\n",
    "\n",
    "    def similarity(self, vec_a: List[float], vec_b: List[float]) -> float:\n",
    "        \"\"\"Computes cosine similarity between two embedding vectors.\n",
    "\n",
    "        Args:\n",
    "            vec_a (List[float]): The first embedding vector.\n",
    "            vec_b (List[float]): The second embedding vector.\n",
    "\n",
    "        Returns:\n",
    "            float: The cosine similarity score.\n",
    "        \"\"\"\n",
    "        if not vec_a or not vec_b:\n",
    "            return 0.0\n",
    "\n",
    "        dot_product: float = sum(a * b for a, b in zip(vec_a, vec_b))\n",
    "        norm_a: float = math.sqrt(sum(a * a for a in vec_a))\n",
    "        norm_b: float = math.sqrt(sum(b * b for b in vec_b))\n",
    "        if norm_a == 0 or norm_b == 0:\n",
    "            return 0.0\n",
    "\n",
    "        return dot_product / (norm_a * norm_b)\n",
    "\n",
    "\n",
    "################################################################\n",
    "# 3) High-Level Utility Function\n",
    "################################################################\n",
    "\n",
    "\n",
    "def calculate_text_similarity(\n",
    "    text1: str, text2: str, model: EmbeddingModel, metric: SimilarityMetric\n",
    ") -> float:\n",
    "    \"\"\"Calculates text similarity using an embedding model and a similarity metric.\n",
    "\n",
    "    This function generates embeddings for the provided texts and then computes a\n",
    "    similarity score using the given similarity metric.\n",
    "\n",
    "    Args:\n",
    "        text1 (str): The first text string.\n",
    "        text2 (str): The second text string.\n",
    "        model (EmbeddingModel): An instance conforming to the embedding model interface.\n",
    "        metric (SimilarityMetric): An instance implementing a similarity metric.\n",
    "\n",
    "    Returns:\n",
    "        float: The computed similarity score.\n",
    "    \"\"\"\n",
    "    embedding1: List[float] = model.embed_text(text=text1)\n",
    "    embedding2: List[float] = model.embed_text(text=text2)\n",
    "\n",
    "    return metric.similarity(vec_a=embedding1, vec_b=embedding2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity Score: 0.7287\n",
      "\n",
      "Cosine similarity Score: 0.8205\n",
      "\n",
      "Cosine similarity Score: 1.0000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mock_model: Text_Embedding_Ada_002_Model = Text_Embedding_Ada_002_Model()\n",
    "cosine: CosineSimilarity = CosineSimilarity()\n",
    "\n",
    "text_a: str = \"Hello world!\"\n",
    "text_b: str = \"Hello, world??\"\n",
    "\n",
    "diverse_text = [\"Bananas don't belong in briefcases\", \"Abraham Lincoln\", \"ERROR 404: Index Not Found\"]\n",
    "\n",
    "different_words_not_diverse_strs = [\"peanut butter and jelly\", \"bacon lettuce tomato\"]\n",
    "\n",
    "repetition_strs = [\"This is a sample text with lots of repetition.\", \n",
    "                \"This is a sample text with lots of repetition.\"]\n",
    "\n",
    "test_strings = [diverse_text, different_words_not_diverse_strs, repetition_strs]\n",
    "\n",
    "for test in test_strings:\n",
    "    score: float = calculate_text_similarity(\n",
    "        text1=test[0], text2=test[1], model=mock_model, metric=cosine\n",
    "    )\n",
    "\n",
    "    print(f\"Cosine similarity Score: {score:.4f}\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "## Compression Ratio (WIP)\n",
    "\n",
    "from `src/ember/core/utils/eval/evaluators.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q diversity==0.2.0\n",
    "%pip install -q spacy==3.8.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from typing import Any, Dict, TypeVar, Optional, List, Generic, Callable, Union\n",
    "\n",
    "from ember.core.utils.eval.base_evaluator import IEvaluator, EvaluationResult\n",
    "from ember.core.utils.eval.extractors import RegexExtractor\n",
    "\n",
    "from diversity import compression_ratio\n",
    "\n",
    "T_out = TypeVar(\"T_out\")\n",
    "T_truth = TypeVar(\"T_truth\")\n",
    "\n",
    "\n",
    "class ComposedEvaluator(IEvaluator[T_out, T_truth], Generic[T_out, T_truth]):\n",
    "    \"\"\"Combines an output extractor with an evaluator for the extracted data.\n",
    "\n",
    "    This evaluator first transforms the system output using the provided extractor,\n",
    "    then evaluates the extracted value using the specified base evaluator.\n",
    "\n",
    "    Args:\n",
    "        extractor: An object with an `extract` method to process the system output.\n",
    "        base_evaluator (IEvaluator): An evaluator that processes the extracted output.\n",
    "\n",
    "    Returns:\n",
    "        EvaluationResult: The result of the evaluation.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        extractor: Any,  # Expecting an extractor with an `extract` method.\n",
    "        base_evaluator: IEvaluator[Any, Any],\n",
    "    ) -> None:\n",
    "        self.extractor = extractor\n",
    "        self.base_evaluator = base_evaluator\n",
    "\n",
    "    def evaluate(\n",
    "        self, system_output: T_out, correct_answer: Any, **kwargs: Any\n",
    "    ) -> EvaluationResult:\n",
    "        \"\"\"Evaluates the provided system output against the correct answer.\n",
    "\n",
    "        Args:\n",
    "            system_output (T_out): The raw output generated by the system.\n",
    "            correct_answer (Any): The expected correct answer.\n",
    "            **kwargs: Additional keyword arguments for extraction or evaluation.\n",
    "\n",
    "        Returns:\n",
    "            EvaluationResult: The result of evaluating the extracted value.\n",
    "        \"\"\"\n",
    "        extracted_value = self.extractor.extract(system_output, **kwargs)\n",
    "        return self.base_evaluator.evaluate(extracted_value, correct_answer, **kwargs)\n",
    "\n",
    "\n",
    "# Basic Evaluators\n",
    "\n",
    "\n",
    "class ExactMatchEvaluator(IEvaluator[str, str]):\n",
    "    \"\"\"Evaluator to check for an exact match between two strings,\n",
    "    ignoring differences in whitespace and case.\n",
    "\n",
    "    Example:\n",
    "        evaluator = ExactMatchEvaluator()\n",
    "        result = evaluator.evaluate(\"Hello World\", \"hello   world\")\n",
    "\n",
    "    Args:\n",
    "        compare_fn (Optional[Callable[[str, str], bool]]): Optional custom comparison function.\n",
    "            If not provided, strings are normalized (whitespace removed, lowercase) before comparison.\n",
    "\n",
    "    Returns:\n",
    "        EvaluationResult: The result containing a correctness flag and a score.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, compare_fn: Optional[Callable[[str, str], bool]] = None) -> None:\n",
    "        self.compare_fn = compare_fn or self._default_compare\n",
    "\n",
    "    def _default_compare(self, str1: str, str2: str) -> bool:\n",
    "        \"\"\"Default string comparison function that ignores case and whitespace.\n",
    "\n",
    "        Args:\n",
    "            str1 (str): First string to compare\n",
    "            str2 (str): Second string to compare\n",
    "\n",
    "        Returns:\n",
    "            bool: True if strings match after normalization\n",
    "        \"\"\"\n",
    "        return str1.strip().lower() == str2.strip().lower()\n",
    "\n",
    "    def evaluate(\n",
    "        self, system_output: str, correct_answer: str, **kwargs: Any\n",
    "    ) -> EvaluationResult:\n",
    "        \"\"\"Evaluates whether a system output exactly matches the correct answer.\n",
    "\n",
    "        Args:\n",
    "            system_output (str): The system-generated string.\n",
    "            correct_answer (str): The expected answer string.\n",
    "            **kwargs: Additional keyword arguments (unused).\n",
    "\n",
    "        Returns:\n",
    "            EvaluationResult: An object with `is_correct` set to True if the normalized strings match,\n",
    "                              along with a corresponding score.\n",
    "        \"\"\"\n",
    "        is_correct = self.compare_fn(system_output, correct_answer)\n",
    "        score = 1.0 if is_correct else 0.0\n",
    "        return EvaluationResult(is_correct=is_correct, score=score)\n",
    "\n",
    "class DiversityScoringEvaluator(IEvaluator[List[str], None]):\n",
    "    \"\"\"\n",
    "    Evaluator to test ensemble outputs -> score them (float)\n",
    "    \"\"\"\n",
    "    def evaluate(\n",
    "            self, \n",
    "            system_output: List[str], \n",
    "            **kwargs) -> EvaluationResult:\n",
    "        if system_output is None or len(system_output) == 0:\n",
    "            return EvaluationResult(is_correct=False, score=-1)\n",
    "\n",
    "\n",
    "        letter_sum = sum(len(response) for response in system_output)\n",
    "        ratio = compression_ratio(system_output) * min(1, len(system_output)/5) * min(1, letter_sum/100)\n",
    "\n",
    "        return EvaluationResult(is_correct=True,score=ratio,metadata = {'responses': system_output})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "---\n",
    "\n",
    "## **Edit Distance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q python-Levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Levenshtein\n",
    "from typing import List\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class EvaluationResult:\n",
    "    is_correct: bool\n",
    "    score: float\n",
    "    metadata: dict\n",
    "\n",
    "class EditDistanceScoringEvaluator:\n",
    "\n",
    "    def evaluate(self, system_output: List[str], **kwargs) -> EvaluationResult:\n",
    "        if system_output is None or len(system_output) == 0:\n",
    "            return EvaluationResult(is_correct=False, score=-1, metadata={})\n",
    "\n",
    "        diversity_score = self.compute_distance(system_output)\n",
    "\n",
    "        return EvaluationResult(\n",
    "            is_correct=True, \n",
    "            score=diversity_score,\n",
    "            metadata={'responses': system_output}\n",
    "        )\n",
    "\n",
    "    def compute_distance(self, outputs: List[str]) -> float:\n",
    "        n = len(outputs)\n",
    "        if n < 2:\n",
    "            return 0.0\n",
    "\n",
    "        total_distance = 0\n",
    "        pairs = 0\n",
    "\n",
    "        for i in range(n):\n",
    "            for j in range(i + 1, n):\n",
    "                dist = Levenshtein.distance(outputs[i], outputs[j])\n",
    "                max_len = max(len(outputs[i]), len(outputs[j]))\n",
    "                normalized_dist = dist / max_len if max_len > 0 else 0 \n",
    "                total_distance += normalized_dist\n",
    "                pairs += 1\n",
    "        \n",
    "        return total_distance / pairs if pairs > 0 else 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diversity Score: 0.8635\n",
      "Is Correct: True\n",
      "Metadata: {'responses': [\"Bananas don't belong in briefcases\", 'Abraham Lincoln', 'ERROR 404: Index Not Found']}\n",
      "\n",
      "Diversity Score: 0.8573\n",
      "Is Correct: True\n",
      "Metadata: {'responses': ['peanut butter and jelly', 'bacon lettuce tomato', 'grilled cheese', 'Banh mi']}\n",
      "\n",
      "Diversity Score: 0.0000\n",
      "Is Correct: True\n",
      "Metadata: {'responses': ['This is a sample text with lots of repetition.', 'This is a sample text with lots of repetition.', 'This is a sample text with lots of repetition.']}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "distance_evaluator = EditDistanceScoringEvaluator()\n",
    "\n",
    "# input_strs = [\n",
    "#     \";lkjawefopajwiefpoij23jf9aj8sdfj8903jf908j -- Understanding the importance of effective communication in the workplace cannot be overstated. Clear communication fosters a positive environment where people can express their ideas and work together efficiently. When team members understand one another, they can collaborate seamlessly, avoid misunderstandings, and achieve collective goals. Furthermore, communication skills are essential for building trust, resolving conflicts, and ensuring that expectations are clear. Whether through verbal discussions, emails, or presentations, knowing how to convey thoughts in an understandable way is key to success in any professional setting.\",\n",
    "#     \"fej89qw098efjq29f38j0938j20f398jqwe098fjq98wf -- In any workplace, the ability to communicate effectively is crucial for success. When individuals can clearly articulate their ideas and listen actively, it leads to a more productive and harmonious environment. Good communication prevents misunderstandings, aids in team collaboration, and helps in meeting shared objectives. It also plays a vital role in fostering trust among colleagues, resolving disputes, and ensuring transparency. Whether it’s through face-to-face conversations, written messages, or virtual meetings, mastering communication is essential to creating a positive, high-functioning work culture.\",\n",
    "#     \"Effective communication is a cornerstone of a successful work environment. When employees communicate clearly and efficiently, it improves the overall flow of work and enhances collaboration. Clear exchanges of ideas help to eliminate confusion, build mutual trust, and ensure that everyone is aligned in their goals. Additionally, strong communication skills are key to managing conflicts and setting clear expectations among teams. Whether in meetings, emails, or other formats, being able to communicate effectively contributes to a thriving and efficient workplace.\",\n",
    "#     \"The role of communication in the workplace cannot be overlooked. It serves as the foundation for successful teamwork and organizational growth. When team members share information clearly, it promotes a collaborative atmosphere and reduces the risk of errors or misinterpretations. Strong communication is also vital in building relationships, resolving issues, and making sure everyone is on the same page. Whether it's verbal exchanges or written correspondence, honing your ability to communicate well is vital for fostering an effective work environment.\",\n",
    "#     \"Communication within the workplace is a vital element for success. Clear and open communication promotes a cooperative and efficient atmosphere, helping team members to better understand each other’s ideas and work toward common goals. It reduces confusion, builds trust, and allows for smoother problem-solving when conflicts arise. By conveying thoughts and expectations effectively, individuals can create stronger working relationships and a productive team dynamic. Whether through emails, phone calls, or face-to-face interactions, mastering communication techniques is key for professional achievement.\",\n",
    "# ]\n",
    "\n",
    "diverse_text = [\"Bananas don't belong in briefcases\", \"Abraham Lincoln\", \"ERROR 404: Index Not Found\"]\n",
    "\n",
    "different_words_not_diverse_strs = [\"peanut butter and jelly\", \"bacon lettuce tomato\", \"grilled cheese\"]\n",
    "\n",
    "repetition_strs = [\"This is a sample text with lots of repetition.\", \n",
    "                \"This is a sample text with lots of repetition.\",\n",
    "                \"This is a sample text with lots of repetition.\"]\n",
    "\n",
    "test_strings = [diverse_text, different_words_not_diverse_strs, repetition_strs]\n",
    "\n",
    "for test in test_strings:\n",
    "    edit_distance = distance_evaluator.evaluate(test)\n",
    "\n",
    "    print(f\"Diversity Score: {edit_distance.score:.4f}\")\n",
    "    print(f\"Is Correct: {edit_distance.is_correct}\")\n",
    "    print(f\"Metadata: {edit_distance.metadata}\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "---\n",
    "\n",
    "## Novelty Score\n",
    "\n",
    "#### (From AidanBench)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from dataclasses import dataclass\n",
    "import numpy as np\n",
    "\n",
    "@dataclass\n",
    "class EvaluationResult:\n",
    "    is_correct: bool\n",
    "    score: float\n",
    "    metadata: dict\n",
    "\n",
    "class NoveltyScoringEvaluator:\n",
    "    \n",
    "    def evaluate(self, model: EmbeddingModel, system_output: List[str], **kwargs) -> EvaluationResult:\n",
    "        if not system_output or len(system_output) == 0:\n",
    "            return EvaluationResult(is_correct=False, score=-1, metadata={})\n",
    "        \n",
    "        self.model = model\n",
    "\n",
    "        novelty_scores = [self.compute_novelty(r, system_output[:i]) for i, r in enumerate(system_output)]\n",
    "\n",
    "        print(\"scores: \", novelty_scores)\n",
    "\n",
    "        avg_novelty = sum(novelty_scores) / len(novelty_scores) if novelty_scores else 0.0\n",
    "\n",
    "        return EvaluationResult(\n",
    "            is_correct=True,\n",
    "            score=avg_novelty,\n",
    "            metadata={'responses': system_output, 'novelty_scores': novelty_scores}\n",
    "        )\n",
    "\n",
    "    def compute_novelty(self, response: str, prior_responses: List[str]) -> float:\n",
    "        if not prior_responses:\n",
    "            return 1.0\n",
    "\n",
    "        new_embedding = self.model.embed_text(response)\n",
    "        prior_embeddings = [self.model.embed_text(r) for r in prior_responses]\n",
    "\n",
    "        similarities = [\n",
    "            np.dot(new_embedding, prior_embedding) /\n",
    "            (np.linalg.norm(new_embedding) * np.linalg.norm(prior_embedding))\n",
    "            for prior_embedding in prior_embeddings\n",
    "        ]\n",
    "\n",
    "        return 1 - max(similarities)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores:  [1.0, 0.2712776724205106, 0.259596190452704]\n",
      "Diversity Score: 0.5103\n",
      "Is Correct: True\n",
      "Metadata: {'responses': [\"Bananas don't belong in briefcases\", 'Abraham Lincoln', 'ERROR 404: Index Not Found'], 'novelty_scores': [1.0, 0.2712776724205106, 0.259596190452704]}\n",
      "\n",
      "scores:  [1.0, 0.17952900510509806, 0.13489158507389332]\n",
      "Diversity Score: 0.4381\n",
      "Is Correct: True\n",
      "Metadata: {'responses': ['peanut butter and jelly', 'bacon lettuce tomato', 'grilled cheese'], 'novelty_scores': [1.0, 0.17952900510509806, 0.13489158507389332]}\n",
      "\n",
      "scores:  [1.0, 0.0, 0.0]\n",
      "Diversity Score: 0.3333\n",
      "Is Correct: True\n",
      "Metadata: {'responses': ['This is a sample text with lots of repetition.', 'This is a sample text with lots of repetition.', 'This is a sample text with lots of repetition.'], 'novelty_scores': [1.0, 0.0, 0.0]}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "novelty_evaluator = NoveltyScoringEvaluator()\n",
    "\n",
    "diverse_text = [\"Bananas don't belong in briefcases\", \"Abraham Lincoln\", \"ERROR 404: Index Not Found\"]\n",
    "\n",
    "different_words_not_diverse_strs = [\"peanut butter and jelly\", \"bacon lettuce tomato\", \"grilled cheese\"]\n",
    "\n",
    "repetition_strs = [\"This is a sample text with lots of repetition.\", \n",
    "                \"This is a sample text with lots of repetition.\",\n",
    "                \"This is a sample text with lots of repetition.\"]\n",
    "\n",
    "ada_002: Text_Embedding_Ada_002_Model = Text_Embedding_Ada_002_Model()\n",
    "test_strings = [diverse_text, different_words_not_diverse_strs, repetition_strs]\n",
    "\n",
    "for test in test_strings:\n",
    "    results = novelty_evaluator.evaluate(ada_002, test)\n",
    "\n",
    "    print(f\"Diversity Score: {results.score:.4f}\")\n",
    "    print(f\"Is Correct: {results.is_correct}\")\n",
    "    print(f\"Metadata: {results.metadata}\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ember_upgrade",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
