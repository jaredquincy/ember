{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82cf3cbd-856f-4a77-934a-05ae47c1cbff",
   "metadata": {},
   "source": [
    "### Modifications from Original\n",
    "- Changed LLModuleConfig to take in registry, bug in README (Have not fixed README, however)\n",
    "- Created custom hallucination detection signatures, and operators\n",
    "- Fixed some refactorings and forgotten imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50b6837d-b7b3-42e2-8e9a-4c8e3d0b5efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "from typing import List, Dict, Any, Optional\n",
    "\n",
    "# 1) Import our dataset registry tools:\n",
    "from src.avior.registry.dataset.registry.metadata_registry import DatasetMetadataRegistry\n",
    "from src.avior.registry.dataset.registry.loader_factory import DatasetLoaderFactory\n",
    "from src.avior.registry.dataset.registry.initialization import initialize_dataset_registry\n",
    "\n",
    "# 2) Import or define dataset loader/validator/sampler:\n",
    "# If you have existing ones, import them. For now, we'll assume defaults or mocks.\n",
    "from src.avior.registry.dataset.base.loaders import HuggingFaceDatasetLoader, IDatasetLoader\n",
    "from src.avior.registry.dataset.base.validators import IDatasetValidator\n",
    "from src.avior.registry.dataset.base.samplers import IDatasetSampler\n",
    "from src.avior.registry.dataset.base.models import DatasetInfo, DatasetEntry, TaskType\n",
    "from src.avior.registry.dataset.base.preppers import IDatasetPrepper\n",
    "from src.avior.registry.dataset.datasets.mmlu import MMLUConfig\n",
    "from src.avior.registry.dataset.base.validators import DatasetValidator\n",
    "from src.avior.registry.dataset.base.samplers import DatasetSampler\n",
    "from src.avior.registry.dataset.datasets.halueval import HaluEvalConfig\n",
    "\n",
    "# 3) Import the DatasetService to actually use the pipeline:\n",
    "from src.avior.registry.dataset.registry.service import DatasetService"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a30e888-0392-40d4-855b-27edbc40f8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.avior.registry.model.registry.model_registry import ModelRegistry\n",
    "from src.avior.registry.model.schemas.model_info import ModelInfo\n",
    "from src.avior.registry.model.schemas.provider_info import ProviderInfo\n",
    "from src.avior.registry.model.schemas.cost import ModelCost, RateLimit\n",
    "from src.avior.registry.model.services.usage_service import UsageService\n",
    "from src.avior.registry.model.services.model_service import ModelService"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7467021b-93a5-45ac-875c-ab69e50a3c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.avior.registry.model.config import initialize_global_registry, GLOBAL_MODEL_REGISTRY\n",
    "from src.avior.registry.model.services.model_service import ModelService"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ff37b94-fed6-4064-888c-fc86fad39b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.avior.registry.model.registry.model_enum import OpenAIModelEnum as OME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5911865c-9511-435f-a210-65026b4c9689",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.avior.registry.model.config import AviorSettings\n",
    "\n",
    "settings = AviorSettings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b107a14-7376-4a52-95e0-0d74052ad769",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2d967b1-c2d9-4f09-81e2-5cec5830d1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Create a metadata registry and loader factory:\n",
    "metadata_registry = DatasetMetadataRegistry()\n",
    "loader_factory = DatasetLoaderFactory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db1b5879-85a2-4a9e-ba93-a2d48d0019bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.avior.registry.dataset.registry.loader_factory:Registered loader prepper for dataset: truthful_qa\n",
      "INFO:src.avior.registry.dataset.registry.loader_factory:Registered loader prepper for dataset: mmlu\n",
      "INFO:src.avior.registry.dataset.registry.loader_factory:Registered loader prepper for dataset: commonsense_qa\n",
      "INFO:src.avior.registry.dataset.registry.loader_factory:Registered loader prepper for dataset: halueval\n",
      "INFO:src.avior.registry.dataset.registry.loader_factory:Registered loader prepper for dataset: my_shortanswer_ds\n",
      "INFO:src.avior.registry.dataset.registry.loader_factory:Registered loader prepper for dataset: my_code_ds\n",
      "INFO:src.avior.registry.dataset.registry.initialization:Initialized dataset registry with known datasets.\n"
     ]
    }
   ],
   "source": [
    "# 2) Initialize the registry with known “built-in” datasets:\n",
    "initialize_dataset_registry(metadata_registry, loader_factory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ac165ec9-43c7-46b6-bfab-098127230c6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.avior.registry.dataset.registry.loader_factory:Auto-registered plugin preppers: []\n"
     ]
    }
   ],
   "source": [
    "# 3) Optionally, discover any additional plugin-based preppers from pyproject.toml:\n",
    "loader_factory.discover_and_register_plugins()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7220f8f7-6a17-41cc-84f8-af8557aaa09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cursor Suggestion\n",
    "\n",
    "# 6) Construct a dataset loader, validator, and sampler:\n",
    "loader: IDatasetLoader = HuggingFaceDatasetLoader()\n",
    "validator: IDatasetValidator = DatasetValidator()\n",
    "sampler: IDatasetSampler = DatasetSampler()\n",
    "\n",
    "# 7) Instantiate a DatasetService to handle load, validation, transform, sampling, and prep:\n",
    "dataset_service = DatasetService(\n",
    "    loader=loader,\n",
    "    validator=validator,\n",
    "    sampler=sampler,\n",
    "    transformers=[]  # Insert any specialized transformers if needed\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d3aca721-cb5b-40f3-8095-014db2d2003a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in /Users/kunalagrawal/anaconda3/lib/python3.11/site-packages (1.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install python-dotenv\n",
    "%load_ext dotenv\n",
    "%dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b05a932c-ef2b-460f-aeb2-e9d7dea8bf91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of using pydantic-based config or environment variables\n",
    "openai_key = settings.openai_api_key or os.getenv(\"OPENAI_API_KEY\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "89ae461a-95ec-429c-9b02-afff8b45b1ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kunalagrawal/anaconda3/lib/python3.11/site-packages/pydantic/_internal/_fields.py:132: UserWarning: Field \"model_id\" in LMModuleConfig has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from src.avior.registry.model.registry.model_registry import ModelRegistry\n",
    "from src.avior.registry.operator.operator_registry import EnsembleOperator, GetAnswerOperator\n",
    "from src.avior.registry.operator.operator_base import LMModuleConfig, LMModule\n",
    "\n",
    "# 1) Register the models\n",
    "registry = ModelRegistry()\n",
    "# (Imagine we've done registry.register_model(...) for each: gemini, claude, gpt-4o, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f34e45f1-942e-471a-a8bc-6169f5287ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register each model\n",
    "openai_provider = ProviderInfo(\n",
    "    name=\"OpenAI\", \n",
    "    default_api_key=openai_key,\n",
    "    base_url=\"https://api.openai.com\"\n",
    ")\n",
    "\n",
    "# GPT-4o\n",
    "gpt4o_info = ModelInfo(\n",
    "    model_id=\"openai:gpt-4o\",\n",
    "    model_name=\"gpt-4o\",\n",
    "    cost=ModelCost(\n",
    "        input_cost_per_million=5000,   # $5.00 per million input tokens\n",
    "        output_cost_per_million=15000  # $15.00 per million output tokens\n",
    "    ),\n",
    "    rate_limit=RateLimit(\n",
    "        tokens_per_minute=10000000,    # 10M tokens per minute\n",
    "        requests_per_minute=1500       # Tier 5 rate limit\n",
    "    ),\n",
    "    provider=openai_provider,\n",
    "    api_key=openai_key\n",
    ")\n",
    "\n",
    "# GPT-4o-mini\n",
    "gpt4o_mini_info = ModelInfo(\n",
    "    model_id=\"openai:gpt-4o-mini\",\n",
    "    model_name=\"gpt-4o-mini\",\n",
    "    cost=ModelCost(\n",
    "        input_cost_per_million=150,    # $0.15 per million input tokens\n",
    "        output_cost_per_million=600    # $0.60 per million output tokens\n",
    "    ),\n",
    "    rate_limit=RateLimit(\n",
    "        tokens_per_minute=10000000,\n",
    "        requests_per_minute=1500\n",
    "    ),\n",
    "    provider=openai_provider,\n",
    "    api_key=openai_key\n",
    ")\n",
    "\n",
    "# O1\n",
    "o1_info = ModelInfo(\n",
    "    model_id=\"openai:o1\",\n",
    "    model_name=\"o1\",\n",
    "    cost=ModelCost(\n",
    "        input_cost_per_million=10000,  # $10.00 per million input tokens\n",
    "        output_cost_per_million=20000  # $20.00 per million output tokens\n",
    "    ),\n",
    "    rate_limit=RateLimit(\n",
    "        tokens_per_minute=5000000,\n",
    "        requests_per_minute=1000\n",
    "    ),\n",
    "    provider=openai_provider,\n",
    "    api_key=openai_key\n",
    ")\n",
    "\n",
    "# Register all models\n",
    "registry.register_model(gpt4o_info)\n",
    "registry.register_model(gpt4o_mini_info)\n",
    "registry.register_model(o1_info)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92beba25-6948-4dd5-95ed-1456cef17b5e",
   "metadata": {},
   "source": [
    "#### README Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2eb3612a-a49a-4545-8985-6cbc3e4a30ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a usage service to use for the model service\n",
    "usage_service = UsageService()\n",
    "\n",
    "# Create a model service using the registry\n",
    "model_service = ModelService(registry=registry, usage_service=usage_service)\n",
    "\n",
    "# 2) Create LMModules for each\n",
    "# gemini_mod = LMModule(LMModuleConfig(model_name=\"gemini-1.5-pro\"), model_service) #TODO might be bug in README, registry instead of model_service\n",
    "# claude_mod = LMModule(LMModuleConfig(model_name=\"claude-3.5-sonnet\"), model_service)\n",
    "# Just using OpenAI models for now\n",
    "g4o_mod = LMModule(LMModuleConfig(model_name=\"gpt-4o\"), model_service)\n",
    "g4omini_mod = LMModule(LMModuleConfig(model_name=\"gpt-4o-mini\"), model_service)\n",
    "go1_mod = LMModule(LMModuleConfig(model_name=\"o1\"), model_service)\n",
    "\n",
    "# 3) Instantiate an EnsembleOperator\n",
    "ensemble_op = EnsembleOperator(lm_modules=[g4o_mod, g4omini_mod, go1_mod])\n",
    "\n",
    "# 4) Instantiate a \"Judge\" operator (GetAnswerOperator or MostCommonOperator)\n",
    "#    Here let's assume \"GetAnswerOperator\" uses a 'final_judge' LMModule\n",
    "#judge_mod = LMModule(LMModuleConfig(model_name=\"o1-mini\"), model_service) # I don't think there's an o1-mini\n",
    "judge_mod = LMModule(LMModuleConfig(model_name=\"o1\"), model_service) # I don't think there's an o1-mini\n",
    "judge_op = GetAnswerOperator(lm_modules=[judge_mod])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "efe37019-2949-4002-b7f2-9b5998af85e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:GraphExecutorService:GraphExecutorService run invoked.\n",
      "INFO:src.avior.registry.model.provider_registry.openai.openai_provider:OpenAI forward() invoked\n",
      "INFO:src.avior.registry.model.provider_registry.openai.openai_provider:OpenAI forward() invoked\n",
      "INFO:src.avior.registry.model.provider_registry.openai.openai_provider:OpenAI forward() invoked\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:src.avior.registry.model.provider_registry.openai.openai_provider:OpenAI forward() invoked\n",
      "INFO:src.avior.registry.model.provider_registry.openai.openai_provider:OpenAI forward() invoked\n",
      "INFO:src.avior.registry.model.provider_registry.openai.openai_provider:OpenAI forward() invoked\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:GraphExecutorService:Graph execution completed successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final answer from the judge: Setting up Avior for multi-model parallel usage involves several steps to ensure proper configuration and efficient execution of models in parallel. Avior, much like other parallel computing frameworks, allows for distributing computational tasks across multiple nodes or processing units, which can vastly improve performance and efficiency in handling large machine learning models. Below is a general guide to setting it up:\n",
      "\n",
      "### Step 1: Environment Setup\n",
      "\n",
      "1. **Hardware Requirements**:\n",
      "   - Ensure you have sufficient hardware resources, such as multiple CPUs or GPUs, to support parallel execution.\n",
      "   - Confirm that your system supports AVX or similar instruction sets, as parallel processing often relies on such capabilities.\n",
      "\n",
      "2. **Software Installation**:\n",
      "   - Install any necessary dependencies for Avior, such as MPI (Message Passing Interface) or other parallel computing libraries.\n",
      "   - Ensure you have the correct version of Python and necessary machine learning libraries like TensorFlow, PyTorch, etc.\n",
      "\n",
      "3. **Avior Installation**:\n",
      "   - Download and install Avior from the official repository or package manager if available.\n",
      "   - Follow any specific installation instructions related to the version you are using, which might involve using `pip` or `conda`.\n",
      "\n",
      "### Step 2: Model Configuration\n",
      "\n",
      "1. **Prepare Your Models**:\n",
      "   - Ensure all machine learning models are properly prepared and can be executed independently.\n",
      "   - Make sure you have pre-trained models saved in compatible formats, or that they can be instantiated programmatically.\n",
      "\n",
      "2. **Partition Data**:\n",
      "   - Partition the input data in a way that is compatible with multi-model execution.\n",
      "   - Ensure that each model receives a data subset appropriate for its operation, to avoid contention and ensure load balancing.\n",
      "\n",
      "### Step 3: Parallel Execution Setup\n",
      "\n",
      "1. **Define Parallel Tasks**:\n",
      "   - Use Avior's API to define how each model should be executed in parallel.\n",
      "   - Specify the resources each model will require, such as CPU/GPU allocation.\n",
      "\n",
      "2. **Configure Model Execution**:\n",
      "   - For each model, configure the batch size, number of threads, and other execution parameters that define how the model will process inputs.\n",
      "   - Implement any needed synchronization mechanisms to manage dependencies between models if they need to interact.\n",
      "\n",
      "3. **Use of MPI or Distributed Framework**:\n",
      "   - Set up MPI configurations with Avior, if needed, for communication between different nodes.\n",
      "   - Alternatively, configure any available distributed computing framework through Avior for load management and execution.\n",
      "\n",
      "### Step 4: Execution and Monitoring\n",
      "\n",
      "1. **Initiate Execution**:\n",
      "   -\n"
     ]
    }
   ],
   "source": [
    "from src.avior.core.graph_executor import NoNGraphData, GraphExecutorService\n",
    "\n",
    "graph_data = NoNGraphData()\n",
    "# Node: \"ensemble\"\n",
    "graph_data.add_node(\n",
    "    name=\"ensemble\", \n",
    "    operator=ensemble_op, \n",
    "    inputs=[]  # no prior node dependencies\n",
    ")\n",
    "# Node: \"judge\"\n",
    "graph_data.add_node(\n",
    "    name=\"judge\",\n",
    "    operator=judge_op,\n",
    "    inputs=[\"ensemble\"]  # feed ensemble output into judge\n",
    ")\n",
    "\n",
    "# 5) Provide the final input to the graph\n",
    "input_data = {\n",
    "        \"query\": \"Explain how to set up Avior for multi-model parallel usage\"\n",
    "}\n",
    "\n",
    "# 6) Execute the graph\n",
    "executor_service = GraphExecutorService()\n",
    "results = executor_service.run(graph_data=graph_data, input_data=input_data)\n",
    "\n",
    "print(\"Final answer from the judge:\", results[\"final_answer\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502fa2b4-fc11-42b9-a8cf-932e4d86c3ce",
   "metadata": {},
   "source": [
    "#### HaluEval LLM as a judge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2c99280a-6bcd-45c5-8dc4-910d7ba73ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.avior.core.graph_executor import NoNGraphData, GraphExecutorService\n",
    "from src.avior.registry.model.config import initialize_global_registry, AviorSettings\n",
    "from src.avior.registry.model.services.model_service import ModelService\n",
    "from src.avior.modules.lm_modules import LMModule, LMModuleConfig\n",
    "from src.avior.registry.operator.hallucination_operators import (\n",
    "    QAHallucinationOperator,\n",
    "    DialogueHallucinationOperator,\n",
    "    SummarizationHallucinationOperator\n",
    ")\n",
    "import os\n",
    "\n",
    "def setup_hallucination_detection():\n",
    "\n",
    "    #Explicitly set the path to your .env file\n",
    "    env_path = \"/Users/kunalagrawal/Desktop/Research/ember/.env\"\n",
    "    \n",
    "    # Initialize settings with explicit env file path\n",
    "    settings = AviorSettings(_env_file=env_path)\n",
    "    \n",
    "    # Set API keys before initialization\n",
    "    settings.openai_api_key = os.getenv(\"OPENAI_API_KEY\", \"\")\n",
    "    #settings.anthropic_api_key = os.getenv(\"ANTHROPIC_API_KEY\", \"\")\n",
    "    #settings.google_api_key = os.getenv(\"GOOGLE_API_KEY\", \"\")\n",
    "\n",
    "    usage_service = UsageService()\n",
    "\n",
    "    # Create a model service using the registry\n",
    "    model_service = ModelService(registry=registry, usage_service=usage_service)\n",
    "    \n",
    "    # 2) Create LMModules for each\n",
    "    # gemini_mod = LMModule(LMModuleConfig(model_name=\"gemini-1.5-pro\"), model_service) #TODO might be bug in README, registry instead of model_service\n",
    "    # claude_mod = LMModule(LMModuleConfig(model_name=\"claude-3.5-sonnet\"), model_service)\n",
    "    \n",
    "    # Just using OpenAI models for now\n",
    "    g4o_mod = LMModule(LMModuleConfig(model_name=\"gpt-4o\"), model_service)\n",
    "    g4omini_mod = LMModule(LMModuleConfig(model_name=\"gpt-4o-mini\"), model_service)\n",
    "    go1_mod = LMModule(LMModuleConfig(model_name=\"o1\"), model_service)\n",
    "\n",
    "    # Create LM modules for different models\n",
    "\n",
    "    # Create appropriate operator based on task\n",
    "    lm_modules = [g4o_mod, g4omini_mod, go1_mod]\n",
    "\n",
    "    #Hardcoding to qa task for now\n",
    "    operator = QAHallucinationOperator(lm_modules)\n",
    "    \n",
    "    # Create graph\n",
    "    graph_data = NoNGraphData()\n",
    "    graph_data.add_node(\n",
    "        name=\"detector\",\n",
    "        operator=operator,\n",
    "        inputs=[]\n",
    "    )\n",
    "\n",
    "    return graph_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2228e46b-8ef4-45ea-8a55-2c420849b931",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'awards' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 31\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     21\u001b[0m     qa_example \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     22\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKnowledge: Arthur\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms Magazine (1844–1846) was an American literary periodical published in Philadelphia in the 19th century.First for Women is a woman\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms magazine published by Bauer Media Group in the USA.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mQuestion: Which magazine was started first Arthur\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms Magazine or First for Women?\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mCandidate Answer: First for Women was started first.. Is this candidate answer supported by the provided knowledge?\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     23\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchoices\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     29\u001b[0m         }\n\u001b[1;32m     30\u001b[0m     }\n\u001b[0;32m---> 31\u001b[0m     qa_result \u001b[38;5;241m=\u001b[39m run_hallucination_detection(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mqa_example)\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mQA Hallucination Check:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQuery: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mqa_example[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[18], line 9\u001b[0m, in \u001b[0;36mrun_hallucination_detection\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# The query is already formatted in the HaluEval format from the input\u001b[39;00m\n\u001b[1;32m      5\u001b[0m query \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      7\u001b[0m input_data \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m\"\u001b[39m: kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m----> 9\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchoices\u001b[39m\u001b[38;5;124m\"\u001b[39m: awards\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchoices\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     10\u001b[0m }\n\u001b[1;32m     12\u001b[0m executor_service \u001b[38;5;241m=\u001b[39m GraphExecutorService()\n\u001b[1;32m     13\u001b[0m results \u001b[38;5;241m=\u001b[39m executor_service\u001b[38;5;241m.\u001b[39mrun(graph_data\u001b[38;5;241m=\u001b[39mgraph_data, input_data\u001b[38;5;241m=\u001b[39minput_data)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'awards' is not defined"
     ]
    }
   ],
   "source": [
    "def run_hallucination_detection(**kwargs):\n",
    "    graph_data = setup_hallucination_detection()\n",
    "    \n",
    "    # The query is already formatted in the HaluEval format from the input\n",
    "    query = kwargs.get(\"query\", \"\")\n",
    "\n",
    "    input_data = {\n",
    "        \"query\": kwargs.get(\"query\"),\n",
    "        \"choices\": kwargs.get(\"choices\")\n",
    "    }\n",
    "    \n",
    "    executor_service = GraphExecutorService()\n",
    "    results = executor_service.run(graph_data=graph_data, input_data=input_data)\n",
    "    \n",
    "    if \"detector\" not in results:\n",
    "        return results\n",
    "    return results[\"detector\"]\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    qa_example = {\n",
    "        \"query\": \"Knowledge: Arthur's Magazine (1844–1846) was an American literary periodical published in Philadelphia in the 19th century.First for Women is a woman's magazine published by Bauer Media Group in the USA.\\nQuestion: Which magazine was started first Arthur's Magazine or First for Women?\\nCandidate Answer: First for Women was started first.. Is this candidate answer supported by the provided knowledge?\",\n",
    "        \"choices\": {\n",
    "            \"A\": \"Not Hallucinated\",\n",
    "            \"B\": \"Hallucinated\"\n",
    "        },\n",
    "        \"metadata\": {\n",
    "            \"correct_answer\": \"B\"\n",
    "        }\n",
    "    }\n",
    "    qa_result = run_hallucination_detection(**qa_example)\n",
    "    print(f\"\\nQA Hallucination Check:\")\n",
    "    print(f\"Query: {qa_example['query']}\")\n",
    "    print(f\"Result: {qa_result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5cfb02-2837-43db-aee2-d434b41f41ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main Evaluation Logic\n",
    "import pandas as pd\n",
    "halu_df = pd.DataFrame(columns=['query','judgement','correct_answer'])\n",
    "\n",
    "\n",
    "# 9) Let's do the same for HaluEval:\n",
    "halu_info: Optional[DatasetInfo] = metadata_registry.get(\"halueval\")\n",
    "if not halu_info:\n",
    "    raise ValueError(\"HaluEval dataset not properly registered.\")\n",
    "\n",
    "halu_prepper_class = loader_factory.get_prepper_class(\"halueval\")\n",
    "if not halu_prepper_class:\n",
    "    raise ValueError(\"No HaluEval prepper found. Make sure it's registered.\")\n",
    "\n",
    "# Create config & prepper, defaulting to config_name=\"qa\", split=\"data\"\n",
    "halu_config = HaluEvalConfig()\n",
    "halu_prepper: IDatasetPrepper = halu_prepper_class(config=halu_config)\n",
    "\n",
    "logger.info(f\"Loading and preparing dataset: {halu_info.name}\")\n",
    "try:\n",
    "    halu_dataset_entries: List[DatasetEntry] = dataset_service.load_and_prepare(\n",
    "        dataset_info=halu_info,\n",
    "        prepper=halu_prepper,\n",
    "        config=halu_config,\n",
    "        num_samples=3\n",
    "    )\n",
    "    logger.info(f\"Received {len(halu_dataset_entries)} prepared entries for '{halu_info.name}'.\")\n",
    "    for i, entry in enumerate(halu_dataset_entries):\n",
    "        data_entry = entry.model_dump()\n",
    "        result = run_hallucination_detection(**data_entry)\n",
    "        print(f\"\\nQA Hallucination:\")\n",
    "        print(f\"[HaluEval] Entry #{i+1}:\\n{data_entry}\")\n",
    "        print(f\"Result: {result}\")\n",
    "        new_row = {\"query\": data_entry['query'], \"judgement\": result.judgement, \"correct_answer\": data_entry['metadata']['correct_answer']} \n",
    "        halu_df = pd.concat([halu_df, pd.DataFrame([new_row])], ignore_index=True)\n",
    "except Exception as e:\n",
    "    logger.error(f\"Error during HaluEval dataset preparation: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c263865-2485-4477-b5e8-e924098ba016",
   "metadata": {},
   "outputs": [],
   "source": [
    "halu_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e565f4f4-dd75-41ea-910a-217411d95fdb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7e4041-2ba4-4be2-8298-75a99e2ab2a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
