{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb8b2ff3-710f-400e-a7b4-5c62bc2f8d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from typing import List, Dict, Any, Optional\n",
    "\n",
    "# 1) Import our dataset registry tools:\n",
    "from src.avior.registry.dataset.registry.metadata_registry import DatasetMetadataRegistry\n",
    "from src.avior.registry.dataset.registry.loader_factory import DatasetLoaderFactory\n",
    "from src.avior.registry.dataset.registry.initialization import initialize_dataset_registry\n",
    "\n",
    "# 2) Import or define dataset loader/validator/sampler:\n",
    "# If you have existing ones, import them. For now, we'll assume defaults or mocks.\n",
    "from src.avior.registry.dataset.base.loaders import HuggingFaceDatasetLoader, IDatasetLoader\n",
    "from src.avior.registry.dataset.base.validators import IDatasetValidator\n",
    "from src.avior.registry.dataset.base.samplers import IDatasetSampler\n",
    "from src.avior.registry.dataset.base.models import DatasetInfo, DatasetEntry, TaskType\n",
    "from src.avior.registry.dataset.base.preppers import IDatasetPrepper\n",
    "from src.avior.registry.dataset.datasets.mmlu import MMLUConfig\n",
    "from src.avior.registry.dataset.base.validators import DatasetValidator\n",
    "from src.avior.registry.dataset.base.samplers import DatasetSampler\n",
    "from src.avior.registry.dataset.datasets.halueval import HaluEvalConfig\n",
    "\n",
    "# 3) Import the DatasetService to actually use the pipeline:\n",
    "from src.avior.registry.dataset.registry.service import DatasetService"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22ef07e3-857c-44cf-b4f5-a0ab1752249a",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d553c03-57f2-4481-b347-9d162e9e96ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Create a metadata registry and loader factory:\n",
    "metadata_registry = DatasetMetadataRegistry()\n",
    "loader_factory = DatasetLoaderFactory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f392f48-2d84-42f1-8035-bcb3beb75059",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.avior.registry.dataset.registry.loader_factory:Registered loader prepper for dataset: truthful_qa\n",
      "INFO:src.avior.registry.dataset.registry.loader_factory:Registered loader prepper for dataset: mmlu\n",
      "INFO:src.avior.registry.dataset.registry.loader_factory:Registered loader prepper for dataset: commonsense_qa\n",
      "INFO:src.avior.registry.dataset.registry.loader_factory:Registered loader prepper for dataset: halueval\n",
      "INFO:src.avior.registry.dataset.registry.loader_factory:Registered loader prepper for dataset: my_shortanswer_ds\n",
      "INFO:src.avior.registry.dataset.registry.loader_factory:Registered loader prepper for dataset: my_code_ds\n",
      "INFO:src.avior.registry.dataset.registry.initialization:Initialized dataset registry with known datasets.\n"
     ]
    }
   ],
   "source": [
    "# 2) Initialize the registry with known “built-in” datasets:\n",
    "initialize_dataset_registry(metadata_registry, loader_factory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1339a867-eac7-450d-a777-d223431a6984",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.avior.registry.dataset.registry.loader_factory:Registered loader prepper for dataset: commonsense_qa\n",
      "INFO:src.avior.registry.dataset.registry.loader_factory:Registered loader prepper for dataset: halueval\n",
      "INFO:src.avior.registry.dataset.registry.loader_factory:Registered loader prepper for dataset: mmlu\n",
      "INFO:src.avior.registry.dataset.registry.loader_factory:Registered loader prepper for dataset: short_answer\n",
      "INFO:src.avior.registry.dataset.registry.loader_factory:Registered loader prepper for dataset: truthful_qa\n",
      "INFO:src.avior.registry.dataset.registry.loader_factory:Auto-registered plugin preppers: ['commonsense_qa', 'halueval', 'mmlu', 'short_answer', 'truthful_qa']\n"
     ]
    }
   ],
   "source": [
    "# 3) Optionally, discover any additional plugin-based preppers from pyproject.toml:\n",
    "loader_factory.discover_and_register_plugins()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a336c3c6-66bc-47b6-a3e3-9c1732fd64d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) Retrieve dataset info from our registry (for example, \"mmlu\"):\n",
    "mmlu_info: Optional[DatasetInfo] = metadata_registry.get(\"mmlu\")\n",
    "if not mmlu_info:\n",
    "    raise ValueError(\"MMLU dataset not properly registered.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1560338f-2f74-44c4-ae0e-6370f3e2547d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) Obtain a prepper class from loader_factory:\n",
    "#    This is the class that knows how to format MMLU data into DatasetEntry objects.\n",
    "mmlu_prepper_class = loader_factory.get_prepper_class(\"mmlu\")\n",
    "if not mmlu_prepper_class:\n",
    "    raise ValueError(\"No MMLU prepper found. Make sure it's registered.\")\n",
    "\n",
    "# 5a) Create an MMLUConfig specifying which sub-config and split you want:\n",
    "mmlu_config = MMLUConfig(config_name=\"abstract_algebra\", split=\"dev\")\n",
    "\n",
    "# 5b) Pass it into the MMLUPrepper constructor:\n",
    "mmlu_prepper: IDatasetPrepper = mmlu_prepper_class(config=mmlu_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c6805fe2-79fd-4fb2-95ff-3cf5b4783347",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6) Construct a dataset loader, validator, and sampler:\n",
    "#    (Replace HuggingFaceDatasetLoader with your real loader if you have a custom approach.)\n",
    "loader: IDatasetLoader = HuggingFaceDatasetLoader()\n",
    "validator: IDatasetValidator = DatasetValidator()\n",
    "sampler: IDatasetSampler = DatasetSampler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "42e4850b-2ead-4c6c-8fbf-6b8eb3bbab3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7) Instantiate a DatasetService to handle load, validation, transform, sampling, and prep:\n",
    "dataset_service = DatasetService(\n",
    "    loader=loader,\n",
    "    validator=validator,\n",
    "    sampler=sampler,\n",
    "    transformers=[]  # Insert any specialized transformers if needed\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8db2aa66-89c9-413d-b399-e121ccb29400",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Loading and preparing dataset: mmlu\n",
      "INFO:root:[load_and_prepare] Starting process for dataset 'mmlu' with source='cais/mmlu', config='config_name='abstract_algebra' split='dev'', num_samples='5'.\n",
      "INFO:root:[load_and_prepare] Converting config -> a string (or None) that _load_data expects.\n",
      "INFO:root:[load_and_prepare] Resolved config is: 'abstract_algebra'.\n",
      "INFO:root:[load_and_prepare] Loading data from source='cais/mmlu' using resolved_config='abstract_algebra'.\n",
      "INFO:src.avior.registry.dataset.base.loaders:Checking dataset existence on the Hub: cais/mmlu\n",
      "INFO:src.avior.registry.dataset.base.loaders:Loading dataset: cais/mmlu (config: abstract_algebra)\n",
      "Python(34983) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "INFO:src.avior.registry.dataset.base.loaders:Successfully loaded dataset: cais/mmlu (config: abstract_algebra)\n",
      "INFO:src.avior.registry.dataset.registry.service:Dataset columns: DatasetDict({\n",
      "    test: Dataset({\n",
      "        features: ['question', 'subject', 'choices', 'answer'],\n",
      "        num_rows: 100\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['question', 'subject', 'choices', 'answer'],\n",
      "        num_rows: 11\n",
      "    })\n",
      "    dev: Dataset({\n",
      "        features: ['question', 'subject', 'choices', 'answer'],\n",
      "        num_rows: 5\n",
      "    })\n",
      "})\n",
      "DEBUG:src.avior.registry.dataset.registry.service:Split 'test' columns: ['question', 'subject', 'choices', 'answer']\n",
      "DEBUG:src.avior.registry.dataset.registry.service:Split 'validation' columns: ['question', 'subject', 'choices', 'answer']\n",
      "DEBUG:src.avior.registry.dataset.registry.service:Split 'dev' columns: ['question', 'subject', 'choices', 'answer']\n",
      "INFO:root:[load_and_prepare] Data loaded successfully.\n",
      "INFO:root:[load_and_prepare] Loaded dataset details: type=<class 'datasets.dataset_dict.DatasetDict'>, size=3\n",
      "INFO:root:[load_and_prepare] Example record from loaded dataset: DatasetDict({\n",
      "    test: Dataset({\n",
      "        features: ['question', 'subject', 'choices', 'answer'],\n",
      "        num_rows: 100\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['question', 'subject', 'choices', 'answer'],\n",
      "        num_rows: 11\n",
      "    })\n",
      "    dev: Dataset({\n",
      "        features: ['question', 'subject', 'choices', 'answer'],\n",
      "        num_rows: 5\n",
      "    })\n",
      "})\n",
      "INFO:root:[load_and_prepare] Determined that 'config_obj' is a BaseDatasetConfig subclass.\n",
      "INFO:root:[load_and_prepare] Selecting appropriate split, if requested.\n",
      "INFO:root:[load_and_prepare] Split selection completed.\n",
      "INFO:root:[load_and_prepare] Validating dataset structure.\n",
      "INFO:root:[load_and_prepare] Dataset structure validated successfully.\n",
      "INFO:root:[load_and_prepare] Validated data details: type=<class 'datasets.arrow_dataset.Dataset'>, size=5\n",
      "INFO:root:[load_and_prepare] Example record from validated data: {'question': 'Find all c in Z_3 such that Z_3[x]/(x^2 + c) is a field.', 'subject': 'abstract_algebra', 'choices': ['0', '1', '2', '3'], 'answer': 1}\n",
      "INFO:root:[load_and_prepare] Applying transformations to the validated data.\n",
      "INFO:root:[load_and_prepare] Data transformations applied.\n",
      "INFO:root:[load_and_prepare] Transformed data details: type=<class 'datasets.arrow_dataset.Dataset'>, size=5\n",
      "INFO:root:[load_and_prepare] Example record from transformed data: {'question': 'Find all c in Z_3 such that Z_3[x]/(x^2 + c) is a field.', 'subject': 'abstract_algebra', 'choices': ['0', '1', '2', '3'], 'answer': 1}\n",
      "INFO:root:[load_and_prepare] Validating required keys in the transformed data.\n",
      "INFO:root:[load_and_prepare] Required keys validation completed.\n",
      "INFO:root:[load_and_prepare] Sampling the data if num_samples is provided.\n",
      "INFO:root:[load_and_prepare] Transformed data: Dataset({\n",
      "    features: ['question', 'subject', 'choices', 'answer'],\n",
      "    num_rows: 5\n",
      "})\n",
      "INFO:root:[load_and_prepare] Sampled data: Dataset({\n",
      "    features: ['question', 'subject', 'choices', 'answer'],\n",
      "    num_rows: 5\n",
      "})\n",
      "INFO:root:[load_and_prepare] Data sampling complete. Number of records after sampling: 5.\n",
      "INFO:root:[load_and_prepare] Example record from sampled data: Dataset({\n",
      "    features: ['question', 'subject', 'choices', 'answer'],\n",
      "    num_rows: 5\n",
      "})\n",
      "INFO:root:[load_and_prepare] Preparing final DatasetEntry objects.\n",
      "INFO:root:[load_and_prepare] Final preparation complete. Generated 5 DatasetEntry objects.\n",
      "INFO:__main__:Received 5 prepared entries for 'mmlu'.\n",
      "INFO:__main__:Entry #1:\n",
      "{\n",
      "  \"query\": \"Find all c in Z_3 such that Z_3[x]/(x^2 + c) is a field.\",\n",
      "  \"choices\": {\n",
      "    \"A\": \"0\",\n",
      "    \"B\": \"1\",\n",
      "    \"C\": \"2\",\n",
      "    \"D\": \"3\"\n",
      "  },\n",
      "  \"metadata\": {\n",
      "    \"correct_answer\": \"B\",\n",
      "    \"subject\": \"abstract_algebra\",\n",
      "    \"config_name\": \"abstract_algebra\"\n",
      "  }\n",
      "}\n",
      "INFO:__main__:Entry #2:\n",
      "{\n",
      "  \"query\": \"Statement 1 | If aH is an element of a factor group, then |aH| divides |a|. Statement 2 | If H and K are subgroups of G then HK is a subgroup of G.\",\n",
      "  \"choices\": {\n",
      "    \"A\": \"True, True\",\n",
      "    \"B\": \"False, False\",\n",
      "    \"C\": \"True, False\",\n",
      "    \"D\": \"False, True\"\n",
      "  },\n",
      "  \"metadata\": {\n",
      "    \"correct_answer\": \"B\",\n",
      "    \"subject\": \"abstract_algebra\",\n",
      "    \"config_name\": \"abstract_algebra\"\n",
      "  }\n",
      "}\n",
      "INFO:__main__:Entry #3:\n",
      "{\n",
      "  \"query\": \"Statement 1 | Every element of a group generates a cyclic subgroup of the group. Statement 2 | The symmetric group S_10 has 10 elements.\",\n",
      "  \"choices\": {\n",
      "    \"A\": \"True, True\",\n",
      "    \"B\": \"False, False\",\n",
      "    \"C\": \"True, False\",\n",
      "    \"D\": \"False, True\"\n",
      "  },\n",
      "  \"metadata\": {\n",
      "    \"correct_answer\": \"C\",\n",
      "    \"subject\": \"abstract_algebra\",\n",
      "    \"config_name\": \"abstract_algebra\"\n",
      "  }\n",
      "}\n",
      "INFO:__main__:Entry #4:\n",
      "{\n",
      "  \"query\": \"Statement 1| Every function from a finite set onto itself must be one to one. Statement 2 | Every subgroup of an abelian group is abelian.\",\n",
      "  \"choices\": {\n",
      "    \"A\": \"True, True\",\n",
      "    \"B\": \"False, False\",\n",
      "    \"C\": \"True, False\",\n",
      "    \"D\": \"False, True\"\n",
      "  },\n",
      "  \"metadata\": {\n",
      "    \"correct_answer\": \"A\",\n",
      "    \"subject\": \"abstract_algebra\",\n",
      "    \"config_name\": \"abstract_algebra\"\n",
      "  }\n",
      "}\n",
      "INFO:__main__:Entry #5:\n",
      "{\n",
      "  \"query\": \"Find the characteristic of the ring 2Z.\",\n",
      "  \"choices\": {\n",
      "    \"A\": \"0\",\n",
      "    \"B\": \"3\",\n",
      "    \"C\": \"12\",\n",
      "    \"D\": \"30\"\n",
      "  },\n",
      "  \"metadata\": {\n",
      "    \"correct_answer\": \"A\",\n",
      "    \"subject\": \"abstract_algebra\",\n",
      "    \"config_name\": \"abstract_algebra\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# 8) Load and prepare the dataset:\n",
    "#    \"mmlu\" is a Hugging Face dataset name in the code snippet, but you’d use a real ID.\n",
    "logger.info(f\"Loading and preparing dataset: {mmlu_info.name}\")\n",
    "try:\n",
    "    # Pass the full MMLUConfig object so both config_name and split are handled:\n",
    "    dataset_entries: List[DatasetEntry] = dataset_service.load_and_prepare(\n",
    "        dataset_info=mmlu_info,\n",
    "        prepper=mmlu_prepper,\n",
    "        config=mmlu_config,\n",
    "        num_samples=5\n",
    "    )\n",
    "    \n",
    "    # 9) Print or process these dataset entries:\n",
    "    logger.info(f\"Received {len(dataset_entries)} prepared entries for '{mmlu_info.name}'.\")\n",
    "    for i, entry in enumerate(dataset_entries):\n",
    "        logger.info(f\"Entry #{i+1}:\\n{entry.model_dump_json(indent=2)}\")\n",
    "\n",
    "except Exception as e:\n",
    "    logger.error(f\"Error during dataset preparation: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7db1f560-cbc5-4374-9a3d-49dc49b678d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Loading and preparing dataset: halueval\n",
      "INFO:root:[load_and_prepare] Starting process for dataset 'halueval' with source='pminervini/HaluEval', config='config_name='qa' split='data'', num_samples='3'.\n",
      "INFO:root:[load_and_prepare] Converting config -> a string (or None) that _load_data expects.\n",
      "INFO:root:[load_and_prepare] Resolved config is: 'qa'.\n",
      "INFO:root:[load_and_prepare] Loading data from source='pminervini/HaluEval' using resolved_config='qa'.\n",
      "INFO:src.avior.registry.dataset.base.loaders:Checking dataset existence on the Hub: pminervini/HaluEval\n",
      "INFO:src.avior.registry.dataset.base.loaders:Loading dataset: pminervini/HaluEval (config: qa)\n",
      "INFO:src.avior.registry.dataset.base.loaders:Successfully loaded dataset: pminervini/HaluEval (config: qa)\n",
      "INFO:src.avior.registry.dataset.registry.service:Dataset columns: DatasetDict({\n",
      "    data: Dataset({\n",
      "        features: ['knowledge', 'question', 'right_answer', 'hallucinated_answer'],\n",
      "        num_rows: 10000\n",
      "    })\n",
      "})\n",
      "DEBUG:src.avior.registry.dataset.registry.service:Split 'data' columns: ['knowledge', 'question', 'right_answer', 'hallucinated_answer']\n",
      "INFO:root:[load_and_prepare] Data loaded successfully.\n",
      "INFO:root:[load_and_prepare] Loaded dataset details: type=<class 'datasets.dataset_dict.DatasetDict'>, size=1\n",
      "INFO:root:[load_and_prepare] Example record from loaded dataset: DatasetDict({\n",
      "    data: Dataset({\n",
      "        features: ['knowledge', 'question', 'right_answer', 'hallucinated_answer'],\n",
      "        num_rows: 10000\n",
      "    })\n",
      "})\n",
      "INFO:root:[load_and_prepare] Determined that 'config_obj' is a BaseDatasetConfig subclass.\n",
      "INFO:root:[load_and_prepare] Selecting appropriate split, if requested.\n",
      "INFO:root:[load_and_prepare] Split selection completed.\n",
      "INFO:root:[load_and_prepare] Validating dataset structure.\n",
      "INFO:root:[load_and_prepare] Dataset structure validated successfully.\n",
      "INFO:root:[load_and_prepare] Validated data details: type=<class 'datasets.arrow_dataset.Dataset'>, size=10000\n",
      "INFO:root:[load_and_prepare] Example record from validated data: {'knowledge': \"Arthur's Magazine (1844–1846) was an American literary periodical published in Philadelphia in the 19th century.First for Women is a woman's magazine published by Bauer Media Group in the USA.\", 'question': \"Which magazine was started first Arthur's Magazine or First for Women?\", 'right_answer': \"Arthur's Magazine\", 'hallucinated_answer': 'First for Women was started first.'}\n",
      "INFO:root:[load_and_prepare] Applying transformations to the validated data.\n",
      "INFO:root:[load_and_prepare] Data transformations applied.\n",
      "INFO:root:[load_and_prepare] Transformed data details: type=<class 'datasets.arrow_dataset.Dataset'>, size=10000\n",
      "INFO:root:[load_and_prepare] Example record from transformed data: {'knowledge': \"Arthur's Magazine (1844–1846) was an American literary periodical published in Philadelphia in the 19th century.First for Women is a woman's magazine published by Bauer Media Group in the USA.\", 'question': \"Which magazine was started first Arthur's Magazine or First for Women?\", 'right_answer': \"Arthur's Magazine\", 'hallucinated_answer': 'First for Women was started first.'}\n",
      "INFO:root:[load_and_prepare] Validating required keys in the transformed data.\n",
      "INFO:root:[load_and_prepare] Required keys validation completed.\n",
      "INFO:root:[load_and_prepare] Sampling the data if num_samples is provided.\n",
      "INFO:root:[load_and_prepare] Transformed data: Dataset({\n",
      "    features: ['knowledge', 'question', 'right_answer', 'hallucinated_answer'],\n",
      "    num_rows: 10000\n",
      "})\n",
      "INFO:root:[load_and_prepare] Sampled data: Dataset({\n",
      "    features: ['knowledge', 'question', 'right_answer', 'hallucinated_answer'],\n",
      "    num_rows: 3\n",
      "})\n",
      "INFO:root:[load_and_prepare] Data sampling complete. Number of records after sampling: 3.\n",
      "INFO:root:[load_and_prepare] Example record from sampled data: Dataset({\n",
      "    features: ['knowledge', 'question', 'right_answer', 'hallucinated_answer'],\n",
      "    num_rows: 3\n",
      "})\n",
      "INFO:root:[load_and_prepare] Preparing final DatasetEntry objects.\n",
      "INFO:root:[load_and_prepare] Final preparation complete. Generated 6 DatasetEntry objects.\n",
      "INFO:__main__:Received 6 prepared entries for 'halueval'.\n",
      "INFO:__main__:[HaluEval] Entry #1:\n",
      "{\n",
      "  \"query\": \"Knowledge: Arthur's Magazine (1844–1846) was an American literary periodical published in Philadelphia in the 19th century.First for Women is a woman's magazine published by Bauer Media Group in the USA.\\nQuestion: Which magazine was started first Arthur's Magazine or First for Women?\\nCandidate Answer: Arthur's Magazine. Is this candidate answer supported by the provided knowledge?\",\n",
      "  \"choices\": {\n",
      "    \"A\": \"Not Hallucinated\",\n",
      "    \"B\": \"Hallucinated\"\n",
      "  },\n",
      "  \"metadata\": {\n",
      "    \"correct_answer\": \"A\"\n",
      "  }\n",
      "}\n",
      "INFO:__main__:[HaluEval] Entry #2:\n",
      "{\n",
      "  \"query\": \"Knowledge: Arthur's Magazine (1844–1846) was an American literary periodical published in Philadelphia in the 19th century.First for Women is a woman's magazine published by Bauer Media Group in the USA.\\nQuestion: Which magazine was started first Arthur's Magazine or First for Women?\\nCandidate Answer: First for Women was started first.. Is this candidate answer supported by the provided knowledge?\",\n",
      "  \"choices\": {\n",
      "    \"A\": \"Not Hallucinated\",\n",
      "    \"B\": \"Hallucinated\"\n",
      "  },\n",
      "  \"metadata\": {\n",
      "    \"correct_answer\": \"B\"\n",
      "  }\n",
      "}\n",
      "INFO:__main__:[HaluEval] Entry #3:\n",
      "{\n",
      "  \"query\": \"Knowledge: The Oberoi family is an Indian family that is famous for its involvement in hotels, namely through The Oberoi Group.The Oberoi Group is a hotel company with its head office in Delhi.\\nQuestion: The Oberoi family is part of a hotel company that has a head office in what city?\\nCandidate Answer: Delhi. Is this candidate answer supported by the provided knowledge?\",\n",
      "  \"choices\": {\n",
      "    \"A\": \"Not Hallucinated\",\n",
      "    \"B\": \"Hallucinated\"\n",
      "  },\n",
      "  \"metadata\": {\n",
      "    \"correct_answer\": \"A\"\n",
      "  }\n",
      "}\n",
      "INFO:__main__:[HaluEval] Entry #4:\n",
      "{\n",
      "  \"query\": \"Knowledge: The Oberoi family is an Indian family that is famous for its involvement in hotels, namely through The Oberoi Group.The Oberoi Group is a hotel company with its head office in Delhi.\\nQuestion: The Oberoi family is part of a hotel company that has a head office in what city?\\nCandidate Answer: The Oberoi family's hotel company is based in Mumbai.. Is this candidate answer supported by the provided knowledge?\",\n",
      "  \"choices\": {\n",
      "    \"A\": \"Not Hallucinated\",\n",
      "    \"B\": \"Hallucinated\"\n",
      "  },\n",
      "  \"metadata\": {\n",
      "    \"correct_answer\": \"B\"\n",
      "  }\n",
      "}\n",
      "INFO:__main__:[HaluEval] Entry #5:\n",
      "{\n",
      "  \"query\": \"Knowledge: Allison Beth \\\"Allie\\\" Goertz (born March 2, 1991) is an American musician. Goertz is known for her satirical songs based on various pop culture topics. Her videos are posted on YouTube under the name of Cossbysweater.Milhouse Mussolini van Houten is a fictional character featured in the animated television series \\\"The Simpsons\\\", voiced by Pamela Hayden, and created by Matt Groening who named the character after President Richard Nixon's middle name.\\nQuestion: Musician and satirist Allie Goertz wrote a song about the \\\"The Simpsons\\\" character Milhouse, who Matt Groening named after who?\\nCandidate Answer: President Richard Nixon. Is this candidate answer supported by the provided knowledge?\",\n",
      "  \"choices\": {\n",
      "    \"A\": \"Not Hallucinated\",\n",
      "    \"B\": \"Hallucinated\"\n",
      "  },\n",
      "  \"metadata\": {\n",
      "    \"correct_answer\": \"A\"\n",
      "  }\n",
      "}\n",
      "INFO:__main__:[HaluEval] Entry #6:\n",
      "{\n",
      "  \"query\": \"Knowledge: Allison Beth \\\"Allie\\\" Goertz (born March 2, 1991) is an American musician. Goertz is known for her satirical songs based on various pop culture topics. Her videos are posted on YouTube under the name of Cossbysweater.Milhouse Mussolini van Houten is a fictional character featured in the animated television series \\\"The Simpsons\\\", voiced by Pamela Hayden, and created by Matt Groening who named the character after President Richard Nixon's middle name.\\nQuestion: Musician and satirist Allie Goertz wrote a song about the \\\"The Simpsons\\\" character Milhouse, who Matt Groening named after who?\\nCandidate Answer: Allie Goertz wrote a song about Milhouse, a popular TV character, named after an influential political figure.. Is this candidate answer supported by the provided knowledge?\",\n",
      "  \"choices\": {\n",
      "    \"A\": \"Not Hallucinated\",\n",
      "    \"B\": \"Hallucinated\"\n",
      "  },\n",
      "  \"metadata\": {\n",
      "    \"correct_answer\": \"B\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# 9) Let's do the same for HaluEval:\n",
    "halu_info: Optional[DatasetInfo] = metadata_registry.get(\"halueval\")\n",
    "if not halu_info:\n",
    "    raise ValueError(\"HaluEval dataset not properly registered.\")\n",
    "\n",
    "halu_prepper_class = loader_factory.get_prepper_class(\"halueval\")\n",
    "if not halu_prepper_class:\n",
    "    raise ValueError(\"No HaluEval prepper found. Make sure it's registered.\")\n",
    "\n",
    "# Create config & prepper, defaulting to config_name=\"qa\", split=\"data\"\n",
    "halu_config = HaluEvalConfig()\n",
    "halu_prepper: IDatasetPrepper = halu_prepper_class(config=halu_config)\n",
    "\n",
    "logger.info(f\"Loading and preparing dataset: {halu_info.name}\")\n",
    "try:\n",
    "    halu_dataset_entries: List[DatasetEntry] = dataset_service.load_and_prepare(\n",
    "        dataset_info=halu_info,\n",
    "        prepper=halu_prepper,\n",
    "        config=halu_config,\n",
    "        num_samples=3\n",
    "    )\n",
    "    logger.info(f\"Received {len(halu_dataset_entries)} prepared entries for '{halu_info.name}'.\")\n",
    "    for i, entry in enumerate(halu_dataset_entries):\n",
    "        logger.info(f\"[HaluEval] Entry #{i+1}:\\n{entry.model_dump_json(indent=2)}\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Error during HaluEval dataset preparation: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dea3b51-b7a4-4461-b39f-81b296951adc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
